<!doctype html>
<html>
<head>
    <meta charset="utf-8">
    <style>html, body {
  margin: 0;
  padding: 0;
}

.app {
  margin: 10px;
  padding: 0;
}

.files-list {
  margin: 10px 0 0;
  width: 100%;
  border-collapse: collapse;
}
.files-list__head {
  border: 1px solid #999;
}
.files-list__head > tr > th {
  padding: 10px;
  border: 1px solid #999;
  text-align: left;
  font-weight: normal;
  background: #ddd;
}
.files-list__body {
}
.files-list__file {
  cursor: pointer;
}
.files-list__file:hover {
  background: #ccf;
}
.files-list__file > td {
  padding: 10px;
  border: 1px solid #999;
}
.files-list__file > td:first-child::before {
  content: '\01F4C4';
  margin-right: 1em;
}
.files-list__file_low {
  background: #fcc;
}
.files-list__file_medium {
  background: #ffc;
}
.files-list__file_high {
  background: #cfc;
}
.files-list__file_folder > td:first-child::before {
  content: '\01F4C1';
  margin-right: 1em;
}

.file-header {
  border: 1px solid #999;
  display: flex;
  justify-content: space-between;
  align-items: center;
  position: sticky;
  top: 0;
  background: white;
}

.file-header__back {
  margin: 10px;
  cursor: pointer;
  flex-shrink: 0;
  flex-grow: 0;
  text-decoration: underline;
  color: #338;
}

.file-header__name {
  margin: 10px;
  flex-shrink: 2;
  flex-grow: 2;
}

.file-header__stat {
  margin: 10px;
  flex-shrink: 0;
  flex-grow: 0;
}

.file-content {
  margin: 10px 0 0;
  border: 1px solid #999;
  padding: 10px;
  counter-reset: line;
  display: flex;
  flex-direction: column;
}

.code-line::before {
    content: counter(line);
    margin-right: 10px;
}
.code-line {
  margin: 0;
  padding: 0.3em;
  height: 1em;
  counter-increment: line;
}
.code-line_covered {
  background: #cfc;
}
.code-line_uncovered {
  background: #fcc;
}
</style>
</head>
<body>
    <div id="root"></div>
    <script>
        var data = {"files":[{"path":["/","Users","alexc","code","capp-rs","capp","src","lib.rs"],"content":"//! # CAPP - \"Comprehensive Asynchronous Parallel Processing\" or just \"Crawler APP\"\n//!\n//! `capp` is a Rust library designed to provide powerful and flexible tools for building efficient web crawlers and other asynchronous, parallel processing applications. It offers a robust framework for managing concurrent tasks, handling network requests, and processing large amounts of data in a scalable manner.\n//!\n//! ## Features\n//!\n//! - **Asynchronous Task Management**: Utilize tokio-based asynchronous processing for efficient, non-blocking execution of tasks.\n//! - **Flexible Task Queue**: Implement various backend storage options for task queues, including in-memory and Redis-based solutions.\n//! - **Round-Robin Task Distribution**: Ensure fair distribution of tasks across different domains or categories.\n//! - **Configurable Workers**: Set up and manage multiple worker instances to process tasks concurrently.\n//! - **Error Handling and Retry Mechanisms**: Robust error handling with configurable retry policies for failed tasks.\n//! - **Dead Letter Queue (DLQ)**: Automatically move problematic tasks to a separate queue for later analysis or reprocessing.\n//! - **Health Checks**: Built-in health check functionality to ensure the stability of your crawling or processing system.\n//! - **Extensible Architecture**: Easily extend the library with custom task types, processing logic, and storage backends.\n//!\n//! ## Use Cases\n//!\n//! While `capp` is primarily designed for building web crawlers, its architecture makes it suitable for a variety of parallel processing tasks, including:\n//!\n//! - Web scraping and data extraction\n//! - Distributed task processing\n//! - Batch job management\n//! - Asynchronous API clients\n//! - Large-scale data processing pipelines\n//!\n//! ## Getting Started\n//!\n//! To use `capp` in your project, add it to your `Cargo.toml`:\n//!\n//! ```toml\n//! [dependencies]\n//! capp = \"0.4\"\n//! ```\n//!\n//! Check examples!\n//!\n//! ## Modules\n//!\n//! - `config`: Configuration management for your application.\n//! - `healthcheck`: Functions for performing health checks on your system.\n//! - `http`: Utilities for making HTTP requests and handling responses.\n//! - `manager`: Task and worker management structures.\n//! - `queue`: Task queue implementations and traits.\n//! - `task`: Definitions and utilities for working with tasks.\npub mod manager;\npub mod prelude;\n\n// re-export\npub use async_trait;\n#[cfg(feature = \"http\")]\npub use derive_builder;\n#[cfg(feature = \"http\")]\npub use reqwest;\n#[cfg(feature = \"redis\")]\npub use rustis;\npub use serde;\npub use serde_json;\npub use serde_yaml;\npub use thiserror;\npub use tracing;\npub use tracing_subscriber;\npub use uuid;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","capp","src","manager","computation.rs"],"content":"use async_trait::async_trait;\nuse capp_queue::queue::AbstractTaskQueue;\nuse capp_queue::task::Task;\nuse serde::{de::DeserializeOwned, Serialize};\nuse std::sync::Arc;\nuse thiserror::Error;\n\nuse super::worker::WorkerId;\n\n#[derive(Error, Debug)]\npub enum ComputationError {\n    #[error(\"I/O error: {0}\")]\n    Io(#[from] std::io::Error),\n    #[error(\"Database error: {0}\")]\n    Db(String),\n    #[error(\"Task storage error: {0}\")]\n    Storage(String),\n    #[error(\"Task error: {0}\")]\n    Task(String),\n    #[error(\"Computation execution error: {0}\")]\n    Function(String),\n    #[error(\"Max retries: {0}\")]\n    MaxRetries(String),\n}\n\n/// A trait defining the interface for processing a task. This trait is\n/// intended to be implemented by a worker that will process tasks\n/// of a specific type.\n#[async_trait]\npub trait Computation\u003cData, Ctx\u003e\nwhere\n    Data: Clone + Serialize + DeserializeOwned + Send + Sync + 'static,\n    Ctx: Send + Sync + 'static,\n{\n    /// Do computation The worker_id is passed for logging or\n    /// debugging purposes. The task is a mutable reference,\n    /// allowing the processor to modify the task data as part of the processing.\n    async fn call(\n        \u0026self,\n        worker_id: WorkerId,\n        ctx: Arc\u003cCtx\u003e,\n        // NOTE: i used type alias instead of this\n        // is something put this line back and remove next one!\n        // storage: Arc\u003cdyn TaskStorage\u003cData\u003e + Send + Sync\u003e,\n        queue: AbstractTaskQueue\u003cData\u003e,\n        task: \u0026mut Task\u003cData\u003e,\n    ) -\u003e Result\u003c(), ComputationError\u003e;\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","capp","src","manager","handler.rs"],"content":"//! This module defines the `TaskHandler` trait, which provides a generic interface\n//! for asynchronous task processing. It allows for flexible implementation of\n//! request handling with associated types for requests, responses, and errors.\n\nuse crate::prelude::WorkerId;\nuse async_trait::async_trait;\nuse capp_queue::queue::AbstractTaskQueue;\nuse capp_queue::task::Task;\nuse std::sync::Arc;\n\n/// A trait for handling asynchronous tasks or requests.\n///\n/// This trait uses associated types to allow for flexible implementations\n/// with different request, response, and error types.\n///\n/// # Type Parameters\n///\n/// * `Req`: The type of the request or task to be handled.\n/// * `Res`: The type of the response returned after handling the request.\n/// * `Error`: The type of error that can occur during request handling.\n///\n/// # Examples\n///\n/// ```no_run\n/// use async_trait::async_trait;\n///\n/// struct MyHandler;\n///\n/// #[async_trait]\n/// impl TaskHandler for MyHandler {\n///     type Req = String;\n///     type Res = usize;\n///     type Error = std::io::Error;\n///\n///     async fn handle(\u0026self, req: \u0026Self::Req) -\u003e Result\u003cSelf::Res, Self::Error\u003e {\n///         Ok(req.len())\n///     }\n/// }\n/// ```\n#[async_trait]\npub trait TaskHandler {\n    type Req;\n    type Res;\n    type Error;\n\n    /// Handles a request asynchronously.\n    ///\n    /// This method takes a reference to a request of type `Req` and returns\n    /// a `Result` containing either a response of type `Res` or an error of type `Error`.\n    ///\n    /// # Arguments\n    ///\n    /// * `req`: A reference to the request to be handled.\n    ///\n    /// # Returns\n    ///\n    /// Returns a `Result\u003cSelf::Res, Self::Error\u003e` which is:\n    /// - `Ok(res)` containing the response if the request was handled successfully.\n    /// - `Err(error)` if an error occurred during request handling.\n    async fn handle(\u0026self, req: \u0026Self::Req) -\u003e Result\u003cSelf::Res, Self::Error\u003e;\n}\n\n#[async_trait::async_trait]\npub trait RequestBuilder\u003cD, Ctx, Req\u003e\nwhere\n    D: std::fmt::Debug + Clone,\n{\n    async fn build_request(\n        worker_id: WorkerId,\n        ctx: Arc\u003cCtx\u003e,\n        queue: AbstractTaskQueue\u003cD\u003e,\n        task: \u0026Task\u003cD\u003e,\n    ) -\u003e Req;\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::io;\n\n    struct MyTaskHandler;\n\n    #[derive(Debug, PartialEq)]\n    struct MyRequest {\n        content: String,\n    }\n\n    #[async_trait]\n    impl TaskHandler for MyTaskHandler {\n        type Req = MyRequest;\n        type Res = String;\n        type Error = io::Error;\n\n        async fn handle(\u0026self, req: \u0026Self::Req) -\u003e Result\u003cSelf::Res, Self::Error\u003e {\n            if req.content == \"error\" {\n                Err(io::Error::new(io::ErrorKind::Other, \"Error triggered\"))\n            } else {\n                Ok(format!(\"Processed: {}\", req.content))\n            }\n        }\n    }\n\n    #[tokio::test]\n    async fn test_successful_handle() {\n        let handler = MyTaskHandler;\n        let request = MyRequest {\n            content: \"test content\".to_string(),\n        };\n\n        let result = handler.handle(\u0026request).await;\n        assert!(result.is_ok());\n        assert_eq!(result.unwrap(), \"Processed: test content\");\n    }\n\n    #[tokio::test]\n    async fn test_error_handle() {\n        let handler = MyTaskHandler;\n        let request = MyRequest {\n            content: \"error\".to_string(),\n        };\n\n        let result = handler.handle(\u0026request).await;\n        assert!(result.is_err());\n        assert_eq!(result.unwrap_err().kind(), io::ErrorKind::Other);\n    }\n\n    #[tokio::test]\n    async fn test_multiple_requests() {\n        let handler = MyTaskHandler;\n        let requests = vec![\n            MyRequest {\n                content: \"first\".to_string(),\n            },\n            MyRequest {\n                content: \"second\".to_string(),\n            },\n            MyRequest {\n                content: \"third\".to_string(),\n            },\n        ];\n\n        for request in requests {\n            let result = handler.handle(\u0026request).await;\n            assert!(result.is_ok());\n            assert_eq!(result.unwrap(), format!(\"Processed: {}\", request.content));\n        }\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","capp","src","manager","stats.rs"],"content":"use serde::Serialize;\n\n#[derive(Debug, Serialize)]\npub struct SharedStats\u003c'a\u003e {\n    workers_stats: Vec\u003c\u0026'a WorkerStats\u003e,\n}\n\n#[derive(Clone, Debug, Serialize)]\npub struct WorkerStats {\n    pub total_execution_time: std::time::Duration,\n    pub tasks_processed: usize,\n    pub tasks_succeeded: usize,\n    pub tasks_failed: usize,\n}\n\nimpl Default for WorkerStats {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\nimpl WorkerStats {\n    pub fn new() -\u003e Self {\n        Self {\n            total_execution_time: std::time::Duration::new(0, 0),\n            tasks_processed: 0,\n            tasks_succeeded: 0,\n            tasks_failed: 0,\n        }\n    }\n\n    pub fn record_execution_time(\u0026mut self, duration: std::time::Duration) {\n        self.total_execution_time += duration;\n        self.tasks_processed += 1;\n    }\n\n    pub fn record_success(\u0026mut self) {\n        self.tasks_succeeded += 1;\n    }\n\n    pub fn record_failure(\u0026mut self) {\n        self.tasks_failed += 1;\n    }\n\n    pub fn average_execution_time(\u0026self) -\u003e std::time::Duration {\n        if self.tasks_processed == 0 {\n            return std::time::Duration::new(0, 0);\n        }\n        self.total_execution_time / self.tasks_processed as u32\n    }\n}\n\nimpl\u003c'a\u003e SharedStats\u003c'a\u003e {\n    pub fn new() -\u003e Self {\n        Self {\n            workers_stats: Vec::new(),\n        }\n    }\n\n    pub fn add_worker_stats(\u0026mut self, stats: \u0026'a WorkerStats) {\n        self.workers_stats.push(stats);\n    }\n}\n\nimpl\u003c'a\u003e Default for SharedStats\u003c'a\u003e {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n","traces":[{"line":17,"address":[],"length":0,"stats":{"Line":0}},{"line":18,"address":[],"length":0,"stats":{"Line":0}},{"line":23,"address":[],"length":0,"stats":{"Line":0}},{"line":25,"address":[],"length":0,"stats":{"Line":0}},{"line":32,"address":[],"length":0,"stats":{"Line":0}},{"line":33,"address":[],"length":0,"stats":{"Line":0}},{"line":34,"address":[],"length":0,"stats":{"Line":0}},{"line":37,"address":[],"length":0,"stats":{"Line":0}},{"line":38,"address":[],"length":0,"stats":{"Line":0}},{"line":41,"address":[],"length":0,"stats":{"Line":0}},{"line":42,"address":[],"length":0,"stats":{"Line":0}},{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":46,"address":[],"length":0,"stats":{"Line":0}},{"line":47,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":54,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":21},{"path":["/","Users","alexc","code","capp-rs","capp","src","manager","worker.rs"],"content":"use crate::manager::{Computation, WorkerStats};\nuse capp_config::config::Configurable;\nuse capp_queue::queue::{AbstractTaskQueue, TaskQueue, TaskQueueError};\nuse derive_builder::Builder;\nuse serde::{de::DeserializeOwned, Serialize};\nuse std::{sync::Arc, time::Duration};\nuse tokio::sync::{\n    broadcast,\n    mpsc::{self, error::TryRecvError},\n};\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]\npub struct WorkerId(usize);\n\n#[derive(Builder, Default, Clone, Debug)]\n#[builder(public, setter(into))]\npub struct WorkerOptions {\n    #[builder(default = \"3\")]\n    pub max_retries: u32,\n    #[builder(default = \"None\")]\n    pub task_limit: Option\u003cusize\u003e,\n    #[builder(default = \"std::time::Duration::from_secs(5)\")]\n    pub no_task_found_delay: Duration,\n}\n\npub enum WorkerCommand {\n    Shutdown, // Gracefully shut down worker\n}\n\npub struct Worker\u003cData, Comp, Ctx\u003e {\n    worker_id: WorkerId,\n    ctx: Arc\u003cCtx\u003e,\n    queue: AbstractTaskQueue\u003cData\u003e,\n    computation: Arc\u003cComp\u003e,\n    pub stats: WorkerStats,\n    pub options: WorkerOptions,\n}\n\n/// A worker implementation that fetches a task from the storage, processes it,\n/// and then updates the task status. If the processing fails,\n/// the task is retried up to N times.\nimpl\u003cData, Comp, Ctx\u003e Worker\u003cData, Comp, Ctx\u003e\nwhere\n    Data: std::fmt::Debug\n        + Clone\n        + Serialize\n        + DeserializeOwned\n        + Send\n        + Sync\n        + 'static,\n    Comp: Computation\u003cData, Ctx\u003e + Send + Sync + 'static,\n    Ctx: Configurable + Send + Sync + 'static,\n{\n    pub fn new(\n        worker_id: WorkerId,\n        ctx: Arc\u003cCtx\u003e,\n        queue: Arc\u003cdyn TaskQueue\u003cData\u003e + Send + Sync\u003e,\n        computation: Arc\u003cComp\u003e,\n        options: WorkerOptions,\n    ) -\u003e Self {\n        Self {\n            worker_id,\n            ctx,\n            queue,\n            computation,\n            options,\n            stats: WorkerStats::new(),\n        }\n    }\n\n    pub fn get_stats(\u0026self) -\u003e \u0026WorkerStats {\n        \u0026self.stats\n    }\n\n    /// Worker run lify-cycle\n    /// 1) pop task from queue (or wait a bit)\n    /// 2) run computation over task\n    /// 3) update task according to computation result\n    ///\n    /// Return true if should continue or false otherwise\n    pub async fn run(\u0026mut self) -\u003e anyhow::Result\u003cbool\u003e {\n        // Implement limiting amount of tasks per worker\n        if let Some(limit) = self.options.task_limit {\n            if self.stats.tasks_processed \u003e= limit {\n                tracing::info!(\n                    \"[{}] task_limit reached: {}\",\n                    self.worker_id,\n                    limit\n                );\n                return Ok(false);\n            }\n        };\n\n        let start_time = std::time::Instant::now();\n        match self.queue.pop().await {\n            Ok(mut task) =\u003e {\n                task.set_in_progress();\n                let result = {\n                    self.computation\n                        .call(\n                            self.worker_id,\n                            self.ctx.clone(),\n                            self.queue.clone(),\n                            \u0026mut task,\n                        )\n                        .await\n                };\n                match result {\n                    Ok(_) =\u003e {\n                        task.set_succeed();\n                        self.queue.set(\u0026task).await.unwrap();\n                        self.queue.ack(\u0026task.task_id).await.unwrap();\n                        tracing::info!(\n                            \"[{}] Task {} succeed: {:?}\",\n                            self.worker_id,\n                            \u0026task.task_id,\n                            \u0026task.payload\n                        );\n\n                        // record stats on success\n                        self.stats.record_execution_time(start_time.elapsed());\n                        self.stats.record_success();\n                    }\n                    Err(err) =\u003e {\n                        task.set_retry(\u0026err.to_string());\n                        if task.retries \u003c self.options.max_retries {\n                            self.queue.push(\u0026task).await.unwrap();\n                            tracing::error!(\n                                \"[{}] Task {} failed, retrying ({}): {:?}\",\n                                self.worker_id,\n                                \u0026task.task_id,\n                                \u0026task.retries,\n                                \u0026err\n                            );\n                        } else {\n                            task.set_dlq(\"Max retries\");\n                            self.queue.nack(\u0026task).await.unwrap();\n                            tracing::error!(\n                                \"[{}] Task {} failed, max reties ({}): {:?}\",\n                                self.worker_id,\n                                \u0026task.task_id,\n                                \u0026task.retries,\n                                \u0026err\n                            );\n                        }\n\n                        self.stats.record_execution_time(start_time.elapsed());\n                        self.stats.record_failure();\n                    }\n                }\n            }\n            Err(TaskQueueError::QueueEmpty) =\u003e {\n                tracing::warn!(\"[{}] No tasks found, waiting...\", self.worker_id);\n                // wait for a while till try to fetch task\n                tokio::time::sleep(self.options.no_task_found_delay).await;\n            }\n            Err(_err) =\u003e {}\n        };\n        Ok(true)\n    }\n}\n\nimpl\u003cData, Comp, Ctx\u003e std::fmt::Debug for Worker\u003cData, Comp, Ctx\u003e {\n    fn fmt(\u0026self, f: \u0026mut std::fmt::Formatter\u003c'_\u003e) -\u003e std::fmt::Result {\n        f.debug_struct(\"Worker\")\n            .field(\"worker_id\", \u0026self.worker_id)\n            .field(\"options\", \u0026self.options)\n            .field(\"stats\", \u0026self.stats)\n            // Optionally, you can add other fields here\n            .finish()\n    }\n}\n\nimpl WorkerId {\n    pub fn new(id: usize) -\u003e Self {\n        Self(id)\n    }\n\n    pub fn get(\u0026self) -\u003e usize {\n        self.0\n    }\n}\n\nimpl std::fmt::Display for WorkerId {\n    fn fmt(\u0026self, f: \u0026mut std::fmt::Formatter\u003c'_\u003e) -\u003e std::fmt::Result {\n        write!(f, \"{}\", self.0)\n    }\n}\n\n/// This wrapper used to create new Worker setup internal logging\n/// and handle comminications with worker\npub async fn worker_wrapper\u003cData, Comp, Ctx\u003e(\n    worker_id: WorkerId,\n    ctx: Arc\u003cCtx\u003e,\n    storage: Arc\u003cdyn TaskQueue\u003cData\u003e + Send + Sync\u003e,\n    computation: Arc\u003cComp\u003e,\n    mut commands: mpsc::Receiver\u003cWorkerCommand\u003e,\n    mut terminate: broadcast::Receiver\u003c()\u003e,\n    worker_options: WorkerOptions,\n) where\n    Data: std::fmt::Debug\n        + Clone\n        + Serialize\n        + DeserializeOwned\n        + Send\n        + Sync\n        + 'static,\n    Comp: Computation\u003cData, Ctx\u003e + Send + Sync + 'static,\n    Ctx: Configurable + Send + Sync + 'static,\n{\n    let mut worker = Worker::new(\n        worker_id,\n        ctx.clone(),\n        storage.clone(),\n        computation.clone(),\n        worker_options,\n    );\n    let mut should_stop = false;\n\n    'worker: loop {\n        tokio::select! {\n            _ = terminate.recv() =\u003e {\n                tracing::info!(\"Terminating immediately\");\n                return;\n            },\n            run_result = worker.run(), if !should_stop =\u003e {\n                match commands.try_recv() {\n                    Ok(WorkerCommand::Shutdown) =\u003e {\n                        tracing::error!(\"[{}] Shutdown received\", worker_id);\n                        should_stop = true;\n                    }\n                    Err(TryRecvError::Disconnected) =\u003e break 'worker,\n                    _ =\u003e {}\n\n                }\n                // If worker ask to shutdown for some reason\n                // i.e some amount of tasks finished\n                if let Ok(re) = run_result {\n                    if !re {\n                        return;\n                    }\n                }\n            }\n        };\n\n        // If a stop command was received, finish any ongoing work and then exit.\n        if should_stop {\n            tracing::info!(\n                \"[{}] Completing current task before stopping.\",\n                worker_id\n            );\n            break;\n        }\n    }\n\n    tracing::info!(\"completed\");\n}\n\n/// This wrapper used to create new Worker setup internal logging\n/// and handle comminications with worker\npub async fn worker_wrapper_old\u003cData, Comp, Ctx\u003e(\n    worker_id: WorkerId,\n    ctx: Arc\u003cCtx\u003e,\n    storage: Arc\u003cdyn TaskQueue\u003cData\u003e + Send + Sync\u003e,\n    computation: Arc\u003cComp\u003e,\n    mut commands: mpsc::Receiver\u003cWorkerCommand\u003e,\n    mut terminate: broadcast::Receiver\u003c()\u003e,\n    worker_options: WorkerOptions,\n) where\n    Data: std::fmt::Debug\n        + Clone\n        + Serialize\n        + DeserializeOwned\n        + Send\n        + Sync\n        + 'static,\n    Comp: Computation\u003cData, Ctx\u003e + Send + Sync + 'static,\n    Ctx: Configurable + Send + Sync + 'static,\n{\n    let mut worker = Worker::new(\n        worker_id,\n        ctx.clone(),\n        storage.clone(),\n        computation.clone(),\n        worker_options,\n    );\n    let mut should_stop = false;\n\n    // setup spans\n    let span = tracing::info_span!(\"worker\", _id = %worker_id);\n    let _enter = span.enter();\n\n    'worker: loop {\n        tokio::select! {\n            _ = terminate.recv() =\u003e {\n                tracing::info!(\"Terminating immediately\");\n                return;\n            },\n            run_result = worker.run(), if !should_stop =\u003e {\n                match commands.try_recv() {\n                    Ok(WorkerCommand::Shutdown) =\u003e {\n                        tracing::error!(\"Shutdown received\");\n                        should_stop = true;\n                    }\n                    Err(TryRecvError::Disconnected) =\u003e break 'worker,\n                    _ =\u003e {}\n\n                }\n                // If worker ask to shutdown for some reason\n                // i.e some amount of tasks finished\n                if let Ok(re) = run_result {\n                    if !re {\n                        return;\n                    }\n                }\n            }\n        };\n\n        // If a stop command was received, finish any ongoing work and then exit.\n        if should_stop {\n            tracing::info!(\"Completing current task before stopping.\",);\n            break;\n        }\n    }\n\n    tracing::info!(\"completed\");\n}\n\n#[cfg(test)]\nmod tests {\n    use std::assert_eq;\n\n    use super::*;\n\n    #[test]\n    fn worker_options() {\n        let options = WorkerOptionsBuilder::default().build().unwrap();\n        assert_eq!(options.max_retries, 3);\n        assert_eq!(options.task_limit, None);\n        assert_eq!(options.no_task_found_delay, Duration::from_millis(5000));\n    }\n}\n","traces":[{"line":54,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":147,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":0}},{"line":152,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":165,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":0}},{"line":176,"address":[],"length":0,"stats":{"Line":0}},{"line":179,"address":[],"length":0,"stats":{"Line":0}},{"line":180,"address":[],"length":0,"stats":{"Line":0}},{"line":185,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":192,"address":[],"length":0,"stats":{"Line":0}},{"line":212,"address":[],"length":0,"stats":{"Line":0}},{"line":213,"address":[],"length":0,"stats":{"Line":0}},{"line":214,"address":[],"length":0,"stats":{"Line":0}},{"line":215,"address":[],"length":0,"stats":{"Line":0}},{"line":216,"address":[],"length":0,"stats":{"Line":0}},{"line":218,"address":[],"length":0,"stats":{"Line":0}},{"line":220,"address":[],"length":0,"stats":{"Line":0}},{"line":221,"address":[],"length":0,"stats":{"Line":0}},{"line":222,"address":[],"length":0,"stats":{"Line":0}},{"line":223,"address":[],"length":0,"stats":{"Line":0}},{"line":224,"address":[],"length":0,"stats":{"Line":0}},{"line":226,"address":[],"length":0,"stats":{"Line":0}},{"line":227,"address":[],"length":0,"stats":{"Line":0}},{"line":228,"address":[],"length":0,"stats":{"Line":0}},{"line":229,"address":[],"length":0,"stats":{"Line":0}},{"line":230,"address":[],"length":0,"stats":{"Line":0}},{"line":232,"address":[],"length":0,"stats":{"Line":0}},{"line":233,"address":[],"length":0,"stats":{"Line":0}},{"line":238,"address":[],"length":0,"stats":{"Line":0}},{"line":239,"address":[],"length":0,"stats":{"Line":0}},{"line":240,"address":[],"length":0,"stats":{"Line":0}},{"line":247,"address":[],"length":0,"stats":{"Line":0}},{"line":248,"address":[],"length":0,"stats":{"Line":0}},{"line":249,"address":[],"length":0,"stats":{"Line":0}},{"line":250,"address":[],"length":0,"stats":{"Line":0}},{"line":252,"address":[],"length":0,"stats":{"Line":0}},{"line":256,"address":[],"length":0,"stats":{"Line":0}},{"line":261,"address":[],"length":0,"stats":{"Line":0}},{"line":281,"address":[],"length":0,"stats":{"Line":0}},{"line":282,"address":[],"length":0,"stats":{"Line":0}},{"line":283,"address":[],"length":0,"stats":{"Line":0}},{"line":284,"address":[],"length":0,"stats":{"Line":0}},{"line":285,"address":[],"length":0,"stats":{"Line":0}},{"line":287,"address":[],"length":0,"stats":{"Line":0}},{"line":290,"address":[],"length":0,"stats":{"Line":0}},{"line":291,"address":[],"length":0,"stats":{"Line":0}},{"line":293,"address":[],"length":0,"stats":{"Line":0}},{"line":294,"address":[],"length":0,"stats":{"Line":0}},{"line":295,"address":[],"length":0,"stats":{"Line":0}},{"line":296,"address":[],"length":0,"stats":{"Line":0}},{"line":297,"address":[],"length":0,"stats":{"Line":0}},{"line":299,"address":[],"length":0,"stats":{"Line":0}},{"line":300,"address":[],"length":0,"stats":{"Line":0}},{"line":301,"address":[],"length":0,"stats":{"Line":0}},{"line":302,"address":[],"length":0,"stats":{"Line":0}},{"line":303,"address":[],"length":0,"stats":{"Line":0}},{"line":305,"address":[],"length":0,"stats":{"Line":0}},{"line":306,"address":[],"length":0,"stats":{"Line":0}},{"line":311,"address":[],"length":0,"stats":{"Line":0}},{"line":312,"address":[],"length":0,"stats":{"Line":0}},{"line":313,"address":[],"length":0,"stats":{"Line":0}},{"line":320,"address":[],"length":0,"stats":{"Line":0}},{"line":321,"address":[],"length":0,"stats":{"Line":0}},{"line":322,"address":[],"length":0,"stats":{"Line":0}},{"line":326,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":127},{"path":["/","Users","alexc","code","capp-rs","capp","src","manager","workers_manager.rs"],"content":"use super::WorkerId;\nuse crate::manager::{\n    worker_wrapper, Computation, WorkerCommand, WorkerOptions, WorkerOptionsBuilder,\n};\nuse capp_config::config::Configurable;\nuse capp_queue::queue::TaskQueue;\nuse derive_builder::Builder;\nuse serde::{de::DeserializeOwned, Serialize};\nuse std::{\n    collections::HashMap,\n    sync::{\n        atomic::{AtomicUsize, Ordering},\n        Arc, Mutex,\n    },\n};\nuse tokio::{\n    signal,\n    sync::{broadcast, mpsc},\n};\nuse tracing::Instrument;\n\ntype WorkerCommandSenders =\n    Arc\u003cMutex\u003cHashMap\u003cWorkerId, mpsc::Sender\u003cWorkerCommand\u003e\u003e\u003e\u003e;\n\n#[derive(Builder, Default, Clone, Debug)]\n#[builder(public, setter(into))]\npub struct WorkersManagerOptions {\n    #[builder(default = \"WorkerOptionsBuilder::default().build().unwrap()\")]\n    pub worker_options: WorkerOptions,\n    #[builder(default = \"None\")]\n    pub task_limit: Option\u003cu32\u003e,\n    #[builder(default = \"4\")]\n    pub concurrency_limit: usize,\n    #[builder(default = \"10\")]\n    pub no_task_found_delay_sec: usize,\n}\n\n// New WorkersManager struct\npub struct WorkersManager\u003cData, Comp, Ctx\u003e {\n    pub ctx: Arc\u003cCtx\u003e,\n    pub computation: Arc\u003cComp\u003e,\n    pub queue: Arc\u003cdyn TaskQueue\u003cData\u003e + Send + Sync\u003e,\n    pub options: WorkersManagerOptions,\n}\n\nimpl\u003cData, Comp, Ctx\u003e WorkersManager\u003cData, Comp, Ctx\u003e\nwhere\n    Data: Clone\n        + Serialize\n        + DeserializeOwned\n        + Send\n        + Sync\n        + 'static\n        + std::fmt::Debug,\n    Comp: Computation\u003cData, Ctx\u003e + Send + Sync + 'static,\n    Ctx: Configurable + Send + Sync + 'static,\n{\n    pub fn new(\n        ctx: Ctx,\n        computation: Comp,\n        queue: impl TaskQueue\u003cData\u003e + Send + Sync + 'static,\n        options: WorkersManagerOptions,\n    ) -\u003e Self {\n        Self {\n            ctx: Arc::new(ctx),\n            computation: Arc::new(computation),\n            queue: Arc::new(queue),\n            options,\n        }\n    }\n\n    pub fn new_from_arcs(\n        ctx: Arc\u003cCtx\u003e,\n        computation: Arc\u003cComp\u003e,\n        queue: Arc\u003cdyn TaskQueue\u003cData\u003e + Send + Sync\u003e,\n        options: WorkersManagerOptions,\n    ) -\u003e Self {\n        Self {\n            ctx,\n            computation,\n            queue,\n            options,\n        }\n    }\n\n    pub async fn run_workers(\u0026mut self) {\n        // This will start the workers and handle the shutdown signals\n        let mut worker_handlers = Vec::new();\n        let command_senders: WorkerCommandSenders =\n            Arc::new(Mutex::new(HashMap::new()));\n        let (terminate_sender, _) = broadcast::channel::\u003c()\u003e(10);\n\n        for i in 1..=self.options.concurrency_limit {\n            let worker_id = WorkerId::new(i);\n            let (command_sender, command_receiver) =\n                mpsc::channel::\u003cWorkerCommand\u003e(100);\n\n            command_senders\n                .lock()\n                .unwrap()\n                .insert(worker_id, command_sender);\n            let terminate_receiver = terminate_sender.subscribe();\n\n            let worker_span = tracing::info_span!(\"worker\", worker_id = %i);\n            let worker = tokio::spawn(worker_wrapper::\u003cData, Comp, Ctx\u003e(\n                WorkerId::new(i),\n                Arc::clone(\u0026self.ctx),\n                Arc::clone(\u0026self.queue),\n                Arc::clone(\u0026self.computation),\n                command_receiver,\n                terminate_receiver,\n                self.options.worker_options.clone(),\n            ))\n            .instrument(worker_span.clone());\n            worker_handlers.push(worker);\n        }\n\n        // Following part setup separate thread to catch ctrl+c\n        // signal. Single press will send Shutdown signal to all workers.\n        // next ctrl-c will terminate workers immediately.\n        self.ctrl_c_handler(command_senders, terminate_sender).await;\n\n        for (worker_id, handler) in worker_handlers.into_iter().enumerate() {\n            let worker_id = worker_id + 1;\n            match handler.await {\n                Ok(res) =\u003e {\n                    tracing::info!(\"[{}] Worker stopped: {:?}\", worker_id, res);\n                }\n                Err(err) =\u003e {\n                    tracing::error!(\n                        \"[{}] Fatal error in one of the workers: {:?}\",\n                        worker_id,\n                        err\n                    );\n                }\n            }\n        }\n\n        tracing::info!(\"All workers stopped\")\n    }\n\n    async fn ctrl_c_handler(\n        \u0026mut self,\n        command_senders: WorkerCommandSenders,\n        terminate_sender: tokio::sync::broadcast::Sender\u003c()\u003e,\n    ) {\n        let ctrl_c_counter = Arc::new(AtomicUsize::new(0));\n\n        // Setup signal handling\n        let signal_counter = ctrl_c_counter.clone();\n        let command_senders = command_senders.clone();\n\n        tokio::spawn(async move {\n            loop {\n                signal::ctrl_c()\n                    .await\n                    .expect(\"Failed to listen for ctrl+c event\");\n                let count = signal_counter.fetch_add(1, Ordering::SeqCst);\n\n                match count {\n                    0 =\u003e {\n                        // First Ctrl+C: Attempt to gracefully stop all workers.\n                        tracing::warn!(\n                        \"Ctrl+C received, sending stop command to all workers...\"\n                    );\n                        let senders: Vec\u003c_\u003e = {\n                            let lock = command_senders.lock().unwrap();\n                            lock.values().cloned().collect()\n                        };\n                        for sender in senders {\n                            let _ = sender.send(WorkerCommand::Shutdown).await;\n                        }\n                    }\n                    _ =\u003e {\n                        // Second Ctrl+C: Force terminate all workers.\n                        tracing::warn!(\n                            \"Ctrl+C received again, terminating all workers...\"\n                        );\n                        terminate_sender.send(()).unwrap();\n                        break;\n                    }\n                }\n            }\n        });\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn excutor_options_builder() {\n        let options = WorkersManagerOptionsBuilder::default().build().unwrap();\n        assert_eq!(options.concurrency_limit, 4);\n    }\n}\n","traces":[{"line":58,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":147,"address":[],"length":0,"stats":{"Line":0}},{"line":150,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":160,"address":[],"length":0,"stats":{"Line":0}},{"line":161,"address":[],"length":0,"stats":{"Line":0}},{"line":163,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":170,"address":[],"length":0,"stats":{"Line":0}},{"line":171,"address":[],"length":0,"stats":{"Line":0}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":176,"address":[],"length":0,"stats":{"Line":0}},{"line":177,"address":[],"length":0,"stats":{"Line":0}},{"line":179,"address":[],"length":0,"stats":{"Line":0}},{"line":180,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":64},{"path":["/","Users","alexc","code","capp-rs","capp","src","manager.rs"],"content":"pub mod computation;\npub mod handler;\npub mod stats;\npub mod worker;\npub mod workers_manager;\n\npub use computation::{Computation, ComputationError};\npub use handler::TaskHandler;\npub use stats::{SharedStats, WorkerStats};\npub use worker::{\n    worker_wrapper, Worker, WorkerCommand, WorkerId, WorkerOptions,\n    WorkerOptionsBuilder, WorkerOptionsBuilderError,\n};\npub use workers_manager::{\n    WorkersManager, WorkersManagerOptions, WorkersManagerOptionsBuilder,\n    WorkersManagerOptionsBuilderError,\n};\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","capp","src","prelude.rs"],"content":"pub use crate::manager::*;\n#[cfg(feature = \"http\")]\npub use capp_config::http::*;\n#[cfg(feature = \"http\")]\npub use capp_config::proxy::*;\npub use capp_config::router::*;\npub use capp_config::*;\npub use capp_queue::queue::*;\npub use capp_queue::task::*;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","capp-config","src","config.rs"],"content":"use std::{\n    fs,\n    io::{self, BufRead},\n    path,\n};\n\n#[derive(thiserror::Error, Debug)]\npub enum ConfigError {\n    #[error(\"IO error: {0}\")]\n    Io(#[from] std::io::Error),\n    #[error(\"YAML parsing error: {0}\")]\n    YamlParse(#[from] serde_yaml::Error),\n    #[error(\"Line parsing error: {0}\")]\n    LineParse(String),\n}\n\npub trait Configurable {\n    fn config(\u0026self) -\u003e \u0026serde_yaml::Value;\n\n    // read configuration from yaml config\n    fn load_config(\n        config_file_path: impl AsRef\u003cpath::Path\u003e,\n    ) -\u003e Result\u003cserde_yaml::Value, ConfigError\u003e {\n        let content: String = fs::read_to_string(config_file_path)?;\n        let config: serde_yaml::Value = serde_yaml::from_str(\u0026content)?;\n        Ok(config)\n    }\n\n    /// Load Vec\u003cString\u003e from file with path `file path`\n    fn load_text_file_lines(\n        file_path: impl AsRef\u003cpath::Path\u003e,\n    ) -\u003e Result\u003cVec\u003cString\u003e, ConfigError\u003e {\n        let file = fs::File::open(file_path)?;\n        let lines = io::BufReader::new(file)\n            .lines()\n            .map(|l| l.map_err(|e| ConfigError::LineParse(e.to_string())))\n            .collect::\u003cResult\u003cVec\u003c_\u003e, _\u003e\u003e()?;\n        Ok(lines)\n    }\n\n    fn load_text_file_content(\n        file_path: impl AsRef\u003cpath::Path\u003e,\n    ) -\u003e Result\u003cString, io::Error\u003e {\n        fs::read_to_string(file_path)\n    }\n\n    /// Extract Value from config using dot notation i.e. \"app.concurrency\"\n    fn get_config_value(\u0026self, key: \u0026str) -\u003e Option\u003c\u0026serde_yaml::Value\u003e {\n        let keys: Vec\u003c\u0026str\u003e = key.split('.').collect();\n        Self::get_value_recursive(self.config(), \u0026keys)\n    }\n\n    fn get_value_recursive\u003c'a\u003e(\n        config: \u0026'a serde_yaml::Value,\n        keys: \u0026[\u0026str],\n    ) -\u003e Option\u003c\u0026'a serde_yaml::Value\u003e {\n        if keys.is_empty() {\n            return None;\n        };\n\n        match config {\n            serde_yaml::Value::Mapping(map) =\u003e {\n                let key = keys[0];\n                let remaining_keys = \u0026keys[1..];\n\n                if let Some(value) =\n                    map.get(serde_yaml::Value::String(key.to_string()))\n                {\n                    if remaining_keys.is_empty() {\n                        Some(value)\n                    } else {\n                        Self::get_value_recursive(value, remaining_keys)\n                    }\n                } else {\n                    None\n                }\n            }\n            _ =\u003e None,\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::fs::File;\n    use std::io::Write;\n    use tempfile::tempdir;\n\n    pub struct TestApp {\n        config: serde_yaml::Value,\n        user_agents: Option\u003cVec\u003cString\u003e\u003e,\n    }\n\n    impl Configurable for TestApp {\n        fn config(\u0026self) -\u003e \u0026serde_yaml::Value {\n            \u0026self.config\n        }\n    }\n\n    impl TestApp {\n        fn from_config(config_file_path: impl AsRef\u003cpath::Path\u003e) -\u003e Self {\n            let config = Self::load_config(config_file_path);\n            Self {\n                config: config.unwrap(),\n                user_agents: None,\n            }\n        }\n\n        fn load_uas(\u0026mut self, uas_file_path: impl AsRef\u003cpath::Path\u003e) {\n            self.user_agents = Self::load_text_file_lines(uas_file_path).ok();\n        }\n    }\n\n    #[test]\n    fn test_load_config() {\n        let config_path = \"../tests/simple_config.yml\";\n        let app = TestApp::from_config(config_path);\n\n        assert_eq!(app.config[\"app\"][\"threads\"].as_u64(), Some(4));\n        assert_eq!(app.config()[\"app\"][\"max_queue\"].as_u64(), Some(500));\n        assert_eq!(app.user_agents, None);\n    }\n\n    #[test]\n    fn test_load_config_valid_yaml() {\n        let dir = tempdir().unwrap();\n        let config_path = dir.path().join(\"config.yml\");\n        let mut file = File::create(\u0026config_path).unwrap();\n        writeln!(file, \"key: value\\napp:\\n  setting: 42\").unwrap();\n\n        let config = TestApp::load_config(\u0026config_path);\n        assert!(config.is_ok());\n        let config = config.unwrap();\n        assert_eq!(config[\"key\"].as_str(), Some(\"value\"));\n        assert_eq!(config[\"app\"][\"setting\"].as_i64(), Some(42));\n    }\n\n    #[test]\n    fn test_load_config_invalid_yaml() {\n        let dir = tempdir().unwrap();\n        let config_path = dir.path().join(\"config.yml\");\n        let mut file = File::create(\u0026config_path).unwrap();\n        writeln!(file, \"invalid: : yaml: content\").unwrap();\n\n        let config = TestApp::load_config(\u0026config_path);\n        assert!(matches!(config, Err(ConfigError::YamlParse(_))));\n    }\n\n    #[test]\n    fn test_load_text_file_lines() {\n        let dir = tempdir().unwrap();\n        let file_path = dir.path().join(\"test.txt\");\n        let mut file = File::create(\u0026file_path).unwrap();\n        writeln!(file, \"line1\\nline2\\nline3\").unwrap();\n\n        let lines = TestApp::load_text_file_lines(\u0026file_path);\n        assert!(lines.is_ok());\n        let lines = lines.unwrap();\n        assert_eq!(lines, vec![\"line1\", \"line2\", \"line3\"]);\n    }\n\n    #[test]\n    fn test_get_config_value_empty_keys() {\n        let config_path = \"../tests/simple_config.yml\";\n        let app = TestApp::from_config(config_path);\n        assert_eq!(app.get_config_value(\"\"), None);\n    }\n\n    #[test]\n    fn test_get_config_value() {\n        let config_path = \"../tests/simple_config.yml\";\n        let app = TestApp::from_config(config_path);\n\n        assert_eq!(\n            app.get_config_value(\"logging.log_to_redis\")\n                .unwrap()\n                .as_bool(),\n            Some(true)\n        )\n    }\n\n    #[test]\n    fn test_get_config_value_recursive() {\n        let yaml = r#\"\n        app:\n          nested:\n            value: 42\n        \"#;\n        let config: serde_yaml::Value = serde_yaml::from_str(yaml).unwrap();\n        let app = TestApp {\n            config,\n            user_agents: None,\n        };\n\n        assert_eq!(\n            app.get_config_value(\"app.nested.value\")\n                .and_then(|v| v.as_i64()),\n            Some(42)\n        );\n        assert_eq!(app.get_config_value(\"app.missing.value\"), None);\n        assert_eq!(app.get_config_value(\"missing\"), None);\n    }\n\n    #[test]\n    fn test_load_lines() {\n        let config_path = \"../tests/simple_config.yml\";\n        let mut app = TestApp::from_config(config_path);\n        let uas_file_path = {\n            app.get_config_value(\"app.user_agents_file\")\n                .unwrap()\n                .as_str()\n                .unwrap()\n                .to_owned()\n        };\n        app.load_uas(\u0026uas_file_path);\n    }\n}\n","traces":[{"line":21,"address":[],"length":0,"stats":{"Line":6}},{"line":24,"address":[],"length":0,"stats":{"Line":12}},{"line":25,"address":[],"length":0,"stats":{"Line":6}},{"line":26,"address":[],"length":0,"stats":{"Line":5}},{"line":30,"address":[],"length":0,"stats":{"Line":2}},{"line":33,"address":[],"length":0,"stats":{"Line":4}},{"line":34,"address":[],"length":0,"stats":{"Line":1}},{"line":36,"address":[],"length":0,"stats":{"Line":6}},{"line":38,"address":[],"length":0,"stats":{"Line":1}},{"line":41,"address":[],"length":0,"stats":{"Line":0}},{"line":44,"address":[],"length":0,"stats":{"Line":0}},{"line":48,"address":[],"length":0,"stats":{"Line":6}},{"line":49,"address":[],"length":0,"stats":{"Line":6}},{"line":50,"address":[],"length":0,"stats":{"Line":6}},{"line":53,"address":[],"length":0,"stats":{"Line":11}},{"line":57,"address":[],"length":0,"stats":{"Line":11}},{"line":58,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":11}},{"line":62,"address":[],"length":0,"stats":{"Line":11}},{"line":63,"address":[],"length":0,"stats":{"Line":11}},{"line":64,"address":[],"length":0,"stats":{"Line":11}},{"line":66,"address":[],"length":0,"stats":{"Line":8}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":3}},{"line":72,"address":[],"length":0,"stats":{"Line":5}},{"line":75,"address":[],"length":0,"stats":{"Line":3}},{"line":78,"address":[],"length":0,"stats":{"Line":0}}],"covered":22,"coverable":28},{"path":["/","Users","alexc","code","capp-rs","capp-config","src","healthcheck.rs"],"content":"use reqwest::{Client, StatusCode};\nuse serde_json::Value;\nuse tokio::time::{timeout, Duration};\n\n// const GOOGLE: \u0026str = \"http://www.google.com\";\n\n/// Check if internet is available.\n/// There are a few hosts that are commonly used to check it\n/// because they are typically reliable and have high uptime. i\n/// Examples:\n///     - Google's primary domain: https://www.google.com\n///     - Cloudflare's DNS resolver: https://1.1.1.1\n///     - Quad9's DNS resolver: https://9.9.9.9\npub async fn internet(http_url: \u0026str) -\u003e bool {\n    let client = Client::new();\n    let request_future = client.get(http_url).send();\n\n    let response = match timeout(Duration::from_secs(1), request_future).await {\n        Ok(response) =\u003e response.unwrap(),\n        Err(_) =\u003e {\n            tracing::error!(\n                \"Internet healthcheck request timed out: {}\",\n                StatusCode::REQUEST_TIMEOUT\n            );\n            return false;\n        }\n    };\n\n    if response.status() == StatusCode::NOT_FOUND\n        \u0026\u0026 response.content_length() == Some(9)\n    {\n        return true;\n    }\n\n    tracing::error!(\n        \"Internet healthcheck unexpected response status or content length: {:?}\",\n        response\n    );\n    false\n}\n\npub async fn test_proxy(proxy_url: \u0026str) -\u003e bool {\n    let client = Client::new();\n    let proxy_client = Client::builder()\n        .proxy(reqwest::Proxy::all(proxy_url).unwrap())\n        .build()\n        .unwrap();\n\n    let ip_check_url = \"https://httpbin.org/ip\";\n\n    // Get local IP\n    let local_ip = match get_ip(\u0026client, ip_check_url).await {\n        Ok(ip) =\u003e ip,\n        Err(_) =\u003e return false,\n    };\n\n    // Get IP through proxy\n    let proxy_ip = match get_ip(\u0026proxy_client, ip_check_url).await {\n        Ok(ip) =\u003e ip,\n        Err(_) =\u003e return false,\n    };\n\n    // Compare IPs\n    local_ip != proxy_ip\n}\n\nasync fn get_ip(client: \u0026Client, url: \u0026str) -\u003e Result\u003cString, reqwest::Error\u003e {\n    let response = client.get(url).send().await?;\n    let body: Value = response.json().await?;\n    Ok(body[\"origin\"].as_str().unwrap_or(\"\").to_string())\n}\n","traces":[{"line":14,"address":[],"length":0,"stats":{"Line":0}},{"line":15,"address":[],"length":0,"stats":{"Line":0}},{"line":16,"address":[],"length":0,"stats":{"Line":0}},{"line":18,"address":[],"length":0,"stats":{"Line":0}},{"line":19,"address":[],"length":0,"stats":{"Line":0}},{"line":21,"address":[],"length":0,"stats":{"Line":0}},{"line":22,"address":[],"length":0,"stats":{"Line":0}},{"line":25,"address":[],"length":0,"stats":{"Line":0}},{"line":29,"address":[],"length":0,"stats":{"Line":0}},{"line":30,"address":[],"length":0,"stats":{"Line":0}},{"line":32,"address":[],"length":0,"stats":{"Line":0}},{"line":35,"address":[],"length":0,"stats":{"Line":0}},{"line":36,"address":[],"length":0,"stats":{"Line":0}},{"line":39,"address":[],"length":0,"stats":{"Line":0}},{"line":42,"address":[],"length":0,"stats":{"Line":0}},{"line":43,"address":[],"length":0,"stats":{"Line":0}},{"line":44,"address":[],"length":0,"stats":{"Line":0}},{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":52,"address":[],"length":0,"stats":{"Line":0}},{"line":53,"address":[],"length":0,"stats":{"Line":0}},{"line":54,"address":[],"length":0,"stats":{"Line":0}},{"line":58,"address":[],"length":0,"stats":{"Line":0}},{"line":59,"address":[],"length":0,"stats":{"Line":0}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":64,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":30},{"path":["/","Users","alexc","code","capp-rs","capp-config","src","http.rs"],"content":"//! HTTP client module for making web requests with configurable proxy support.\n//!\n//! This module provides functionality for building and configuring HTTP clients with\n//! features such as:\n//! - Configurable proxy support with port range expansion\n//! - Timeout settings\n//! - User agent customization\n//! - Retry mechanisms with exponential backoff\n//!\n//! # Example\n//! ```no_run\n//! use capp_config::http::{HttpClientParams, build_http_client};\n//! use serde_yaml::Value;\n//!\n//! let config: Value = serde_yaml::from_str(r#\"\n//! http:\n//!     proxy:\n//!         use: true\n//!         uri: http://proxy.example.com:{8080-8082}\n//!     timeout: 30\n//!     connect_timeout: 10\n//! \"#).unwrap();\n//!\n//! let params = HttpClientParams::from_config(\u0026config[\"http\"], \"my-crawler/1.0\");\n//! let client = build_http_client(params).unwrap();\n//! ```\nuse crate::proxy::{ProxyProvider, RandomProxyProvider};\nuse backoff::ExponentialBackoffBuilder;\n\n/// Parameters for configuring an HTTP client.\n///\n/// This struct holds all configuration needed to build a customized HTTP client,\n/// including timeout settings, proxy configuration, and user agent string.\n#[derive(Debug)]\npub struct HttpClientParams\u003c'a\u003e {\n    pub timeout: u64,\n    pub connect_timeout: u64,\n    pub proxy_provider: Option\u003cBox\u003cdyn ProxyProvider + Send + Sync\u003e\u003e,\n    pub user_agent: \u0026'a str,\n}\n\nimpl\u003c'a\u003e HttpClientParams\u003c'a\u003e {\n    /// Creates an HttpClientParams instance from a YAML configuration.\n    ///\n    /// The configuration should follow this structure:\n    /// ```yaml\n    /// http:\n    ///     proxy:\n    ///         use: true\n    ///         uri: http://user:pass@proxy.example.com:8080\n    ///     timeout: 30\n    ///     connect_timeout: 10\n    /// ```\n    ///\n    /// The proxy URI can include a port range using the format:\n    /// `http://proxy.example.com:{8080-8090}`\n    ///\n    /// # Arguments\n    /// * `http_config` - YAML configuration containing HTTP settings\n    /// * `user_agent` - User agent string to be used in requests\n    ///\n    /// # Panics\n    /// Panics if required configuration fields are missing (timeout, connect_timeout)\n    pub fn from_config(\n        http_config: \u0026serde_yaml::Value,\n        user_agent: \u0026'a str,\n    ) -\u003e Self {\n        let timeout = http_config[\"timeout\"]\n            .as_u64()\n            .expect(\"No timeout field in config\");\n        let connect_timeout = http_config[\"connect_timeout\"]\n            .as_u64()\n            .expect(\"No connect_timeout field in config\");\n\n        let proxy_provider =\n            if http_config[\"proxy\"][\"use\"].as_bool().unwrap_or(false) {\n                Some(Box::new(\n                    RandomProxyProvider::from_config(\u0026http_config[\"proxy\"])\n                        .expect(\"Failed to create proxy provider\"),\n                ) as Box\u003cdyn ProxyProvider + Send + Sync\u003e)\n            } else {\n                None\n            };\n\n        Self {\n            timeout,\n            connect_timeout,\n            proxy_provider,\n            user_agent,\n        }\n    }\n}\n\n/// Builds an HTTP client with the specified parameters.\n///\n/// Creates a reqwest::Client configured with:\n/// - TLS settings\n/// - Timeout configurations\n/// - User agent\n/// - Optional proxy support\n///\n/// # Arguments\n/// * `params` - Configuration parameters for the client\n///\n/// # Returns\n/// A Result containing either the configured client or an error\npub fn build_http_client(\n    params: HttpClientParams,\n) -\u003e Result\u003creqwest::Client, reqwest::Error\u003e {\n    let mut client_builder = reqwest::ClientBuilder::new()\n        .use_rustls_tls()\n        .danger_accept_invalid_certs(true)\n        .timeout(std::time::Duration::from_secs(params.timeout))\n        .connect_timeout(std::time::Duration::from_secs(params.connect_timeout))\n        .user_agent(params.user_agent);\n\n    if let Some(proxy_provider) = params.proxy_provider {\n        if let Some(proxy_uri) = proxy_provider.get_proxy() {\n            client_builder = client_builder.proxy(\n                reqwest::Proxy::all(\u0026proxy_uri).expect(\"Failed to create proxy\"),\n            );\n        }\n    }\n\n    client_builder.build()\n}\n\n/// Fetches a URL with automatic retries.\n///\n/// Makes a GET request to the specified URL, automatically retrying on failure\n/// using exponential backoff. This method only retrieves headers and status,\n/// not the response body.\n///\n/// # Arguments\n/// * `client` - The HTTP client to use for the request\n/// * `url` - The URL to fetch\n///\n/// # Returns\n/// A Result containing either the response or an error\npub async fn fetch_url(\n    client: reqwest::Client,\n    url: \u0026str,\n) -\u003e Result\u003creqwest::Response, reqwest::Error\u003e {\n    let backoff = ExponentialBackoffBuilder::new()\n        .with_max_interval(std::time::Duration::from_secs(10))\n        .build();\n    backoff::future::retry(backoff, || async { Ok(client.get(url).send().await?) })\n        .await\n}\n\n/// Fetches content from a URL with automatic retries.\n///\n/// Makes a GET request to the specified URL and retrieves the full response body,\n/// automatically retrying on failure using exponential backoff.\n///\n/// # Arguments\n/// * `client` - The HTTP client to use for the request\n/// * `url` - The URL to fetch\n///\n/// # Returns\n/// A Result containing either a tuple of (StatusCode, response_body) or an error\npub async fn fetch_url_content(\n    client: reqwest::Client,\n    url: \u0026str,\n) -\u003e Result\u003c(reqwest::StatusCode, String), reqwest::Error\u003e {\n    let backoff = ExponentialBackoffBuilder::new()\n        .with_max_interval(std::time::Duration::from_secs(10))\n        .with_max_elapsed_time(Some(std::time::Duration::from_secs(30)))\n        .build();\n\n    let fetch_content = || async {\n        let response = client.get(url).send().await?;\n        let status = response.status();\n        let text = response.text().await?;\n        Ok((status, text))\n    };\n\n    backoff::future::retry(backoff, fetch_content).await\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use serde_yaml::Value;\n    use std::collections::HashSet;\n    use std::time::Duration;\n\n    const YAML_CONF_SINGLE_PORT: \u0026str = r#\"\n    http:\n        proxy:\n            use: true\n            uri: http://proxy1.example.com:8080\n        timeout: 30\n        connect_timeout: 10\n    \"#;\n\n    const YAML_CONF_PORT_RANGE: \u0026str = r#\"\n    http:\n        proxy:\n            use: true\n            uri: http://proxy1.example.com:{8080-8082}\n        timeout: 30\n        connect_timeout: 10\n    \"#;\n\n    const YAML_CONF_MULTIPLE_PORT_RANGES: \u0026str = r#\"\n    http:\n        proxy:\n            use: true\n            uris:\n                - http://proxy1.example.com:{8080-8082}\n                - http://proxy2.example.com:9090\n                - http://proxy3.example.com:{9000-9001}\n        timeout: 30\n        connect_timeout: 10\n    \"#;\n\n    const YAML_CONF_TEXT: \u0026str = r#\"\n    http:\n      proxy:\n        use: true\n        uri: http://bro:admin@proxygate1.com:42042\n      timeout: 30\n      connect_timeout: 10\n    \"#;\n\n    const WRONG_YAML_CONF_TEXT: \u0026str = r#\"\n    http:\n      proxy:\n        use: true\n        uri: http://bro:admin@proxygate1.com:42042\n      connect_timeout: 10\n    \"#;\n\n    #[test]\n    fn test_build_client() {\n        let client = build_http_client(HttpClientParams {\n            timeout: 10,\n            connect_timeout: 5,\n            proxy_provider: None,\n            user_agent: \"hello\",\n        });\n\n        assert!(client.is_ok());\n    }\n\n    #[test]\n    fn test_build_client_from_config() {\n        let config: serde_yaml::Value =\n            serde_yaml::from_str(YAML_CONF_TEXT).unwrap();\n        let client = build_http_client(HttpClientParams::from_config(\n            config.get(\"http\").unwrap(),\n            \"hellobot\",\n        ));\n        assert!(client.is_ok());\n    }\n\n    #[test]\n    #[should_panic(expected = \"No timeout field in config\")]\n    fn test_build_client_bad_config() {\n        let config: serde_yaml::Value =\n            serde_yaml::from_str(WRONG_YAML_CONF_TEXT).unwrap();\n        let _ = build_http_client(HttpClientParams::from_config(\n            config.get(\"http\").unwrap(),\n            \"hellobot\",\n        ));\n    }\n\n    #[test]\n    fn test_http_client_single_port() {\n        let config: Value = serde_yaml::from_str(YAML_CONF_SINGLE_PORT).unwrap();\n        let client_params =\n            HttpClientParams::from_config(\u0026config[\"http\"], \"test-agent/1.0\");\n\n        assert_eq!(client_params.timeout, 30);\n        assert_eq!(client_params.connect_timeout, 10);\n\n        if let Some(provider) = client_params.proxy_provider {\n            let proxy = provider.get_proxy().unwrap();\n            assert_eq!(proxy, \"http://proxy1.example.com:8080\");\n        } else {\n            panic!(\"Expected proxy provider to be configured\");\n        }\n    }\n\n    #[test]\n    fn test_http_client_port_range() {\n        let config: Value = serde_yaml::from_str(YAML_CONF_PORT_RANGE).unwrap();\n        let client_params =\n            HttpClientParams::from_config(\u0026config[\"http\"], \"test-agent/1.0\");\n\n        let mut seen_ports = HashSet::new();\n        if let Some(provider) = client_params.proxy_provider {\n            // Test multiple calls to verify different ports are used\n            for _ in 0..10 {\n                let proxy = provider.get_proxy().unwrap();\n                let port = extract_port_from_proxy_url(\u0026proxy);\n                seen_ports.insert(port);\n            }\n        }\n\n        // Should see all three ports from range 8080-8082\n        assert_eq!(seen_ports.len(), 3);\n        assert!(seen_ports.contains(\u00268080));\n        assert!(seen_ports.contains(\u00268081));\n        assert!(seen_ports.contains(\u00268082));\n    }\n\n    #[test]\n    fn test_http_client_multiple_port_ranges() {\n        let config: Value =\n            serde_yaml::from_str(YAML_CONF_MULTIPLE_PORT_RANGES).unwrap();\n        let client_params =\n            HttpClientParams::from_config(\u0026config[\"http\"], \"test-agent/1.0\");\n\n        let mut seen_proxies = HashSet::new();\n        if let Some(provider) = client_params.proxy_provider {\n            // Test multiple calls to verify different proxies are used\n            for _ in 0..20 {\n                let proxy = provider.get_proxy().unwrap();\n                seen_proxies.insert(proxy);\n            }\n        }\n\n        // Should see:\n        // 3 ports from proxy1 (8080-8082)\n        // 1 from proxy2 (9090)\n        // 2 from proxy3 (9000-9001)\n        assert_eq!(seen_proxies.len(), 6);\n\n        // Verify specific proxy patterns\n        assert!(seen_proxies\n            .iter()\n            .any(|p| p == \"http://proxy1.example.com:8080\"));\n        assert!(seen_proxies\n            .iter()\n            .any(|p| p == \"http://proxy1.example.com:8081\"));\n        assert!(seen_proxies\n            .iter()\n            .any(|p| p == \"http://proxy1.example.com:8082\"));\n        assert!(seen_proxies\n            .iter()\n            .any(|p| p == \"http://proxy2.example.com:9090\"));\n        assert!(seen_proxies\n            .iter()\n            .any(|p| p == \"http://proxy3.example.com:9000\"));\n        assert!(seen_proxies\n            .iter()\n            .any(|p| p == \"http://proxy3.example.com:9001\"));\n    }\n\n    #[test]\n    fn test_http_client_builder_timeouts_are_set() {\n        let config: Value = serde_yaml::from_str(YAML_CONF_PORT_RANGE).unwrap();\n        let client_params =\n            HttpClientParams::from_config(\u0026config[\"http\"], \"test-agent/1.0\");\n\n        assert_eq!(client_params.timeout, Duration::from_secs(30).as_secs());\n        assert_eq!(\n            client_params.connect_timeout,\n            Duration::from_secs(10).as_secs()\n        );\n    }\n\n    #[test]\n    fn test_proxy_disabled() {\n        let yaml = r#\"\n        http:\n            proxy:\n                use: false\n                uri: http://proxy1.example.com:8080\n            timeout: 30\n            connect_timeout: 10\n        \"#;\n\n        let config: Value = serde_yaml::from_str(yaml).unwrap();\n        let client_params =\n            HttpClientParams::from_config(\u0026config[\"http\"], \"test-agent/1.0\");\n\n        assert!(\n            client_params.proxy_provider.is_none(),\n            \"Proxy provider should be None when disabled\"\n        );\n    }\n\n    #[test]\n    #[should_panic(expected = \"No timeout field in config\")]\n    fn test_missing_timeout() {\n        let yaml = r#\"\n        http:\n            proxy:\n                use: true\n                uri: http://proxy1.example.com:8080\n            connect_timeout: 10\n        \"#;\n\n        let config: Value = serde_yaml::from_str(yaml).unwrap();\n        let _ = HttpClientParams::from_config(\u0026config[\"http\"], \"test-agent/1.0\");\n    }\n\n    #[test]\n    fn test_invalid_port_range() {\n        let yaml = r#\"\n        http:\n            proxy:\n                use: true\n                uri: http://proxy1.example.com:{8082-8080}\n            timeout: 30\n            connect_timeout: 10\n        \"#;\n\n        let config: Value = serde_yaml::from_str(yaml).unwrap();\n        let client_params =\n            HttpClientParams::from_config(\u0026config[\"http\"], \"test-agent/1.0\");\n\n        if let Some(provider) = client_params.proxy_provider {\n            let proxy = provider.get_proxy().unwrap();\n            // Should treat invalid range as literal string\n            assert_eq!(proxy, \"http://proxy1.example.com:{8082-8080}\");\n        }\n    }\n\n    // Helper function to extract port number from proxy URL\n    fn extract_port_from_proxy_url(url: \u0026str) -\u003e u16 {\n        let parts: Vec\u003c\u0026str\u003e = url.split(':').collect();\n        parts.last().unwrap().parse().unwrap()\n    }\n}\n","traces":[{"line":64,"address":[],"length":0,"stats":{"Line":9}},{"line":68,"address":[],"length":0,"stats":{"Line":9}},{"line":71,"address":[],"length":0,"stats":{"Line":9}},{"line":75,"address":[],"length":0,"stats":{"Line":9}},{"line":76,"address":[],"length":0,"stats":{"Line":9}},{"line":77,"address":[],"length":0,"stats":{"Line":6}},{"line":78,"address":[],"length":0,"stats":{"Line":6}},{"line":79,"address":[],"length":0,"stats":{"Line":6}},{"line":80,"address":[],"length":0,"stats":{"Line":6}},{"line":82,"address":[],"length":0,"stats":{"Line":3}},{"line":107,"address":[],"length":0,"stats":{"Line":2}},{"line":110,"address":[],"length":0,"stats":{"Line":2}},{"line":113,"address":[],"length":0,"stats":{"Line":2}},{"line":114,"address":[],"length":0,"stats":{"Line":2}},{"line":115,"address":[],"length":0,"stats":{"Line":2}},{"line":117,"address":[],"length":0,"stats":{"Line":3}},{"line":118,"address":[],"length":0,"stats":{"Line":2}},{"line":119,"address":[],"length":0,"stats":{"Line":1}},{"line":120,"address":[],"length":0,"stats":{"Line":1}},{"line":125,"address":[],"length":0,"stats":{"Line":2}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":147,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":0}},{"line":162,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":171,"address":[],"length":0,"stats":{"Line":0}},{"line":172,"address":[],"length":0,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":0}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":0}},{"line":178,"address":[],"length":0,"stats":{"Line":0}}],"covered":20,"coverable":35},{"path":["/","Users","alexc","code","capp-rs","capp-config","src","lib.rs"],"content":"pub mod config;\n#[cfg(feature = \"http\")]\npub mod healthcheck;\npub mod http;\npub mod proxy;\npub mod router;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","capp-config","src","proxy.rs"],"content":"use rand::seq::SliceRandom;\nuse rand::thread_rng;\nuse regex::Regex;\nuse serde::{Deserialize, Serialize};\nuse std::fmt;\nuse std::sync::{LazyLock, Mutex};\n\n// Add Debug to the trait bounds\npub trait ProxyProvider: Send + Sync + fmt::Debug {\n    fn get_proxy(\u0026self) -\u003e Option\u003cString\u003e;\n}\n\nstatic PORT_RANGE_RE: LazyLock\u003cRegex\u003e = LazyLock::new(|| {\n    Regex::new(r\"\\{(\\d+)-(\\d+)\\}\").expect(\"Failed to compile port range regex\")\n});\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ProxyConfig {\n    pub use_proxy: bool,\n    pub uris: Vec\u003cString\u003e,\n}\n\nimpl ProxyConfig {\n    fn expand_uri(uri: \u0026str) -\u003e Vec\u003cString\u003e {\n        if let Some(captures) = PORT_RANGE_RE.captures(uri) {\n            if let (Some(start), Some(end)) = (\n                captures.get(1).and_then(|m| m.as_str().parse::\u003cu16\u003e().ok()),\n                captures.get(2).and_then(|m| m.as_str().parse::\u003cu16\u003e().ok()),\n            ) {\n                if start \u003c= end {\n                    return (start..=end)\n                        .map(|port| uri.replace(\u0026captures[0], \u0026port.to_string()))\n                        .collect();\n                }\n            }\n        }\n        vec![uri.to_string()]\n    }\n\n    pub fn from_config(config: \u0026serde_yaml::Value) -\u003e Option\u003cSelf\u003e {\n        let use_proxy = config[\"use\"].as_bool()?;\n        let uris = if use_proxy {\n            match config[\"uris\"].as_sequence() {\n                Some(seq) =\u003e seq\n                    .iter()\n                    .filter_map(|v| v.as_str())\n                    .flat_map(Self::expand_uri)\n                    .collect(),\n                None =\u003e {\n                    if let Some(uri) = config[\"uri\"].as_str() {\n                        Self::expand_uri(uri)\n                    } else {\n                        vec![]\n                    }\n                }\n            }\n        } else {\n            vec![]\n        };\n\n        Some(ProxyConfig { use_proxy, uris })\n    }\n}\n\n#[derive(Debug)]\npub struct RandomProxyProvider {\n    config: ProxyConfig,\n}\n\nimpl RandomProxyProvider {\n    pub fn new(config: ProxyConfig) -\u003e Self {\n        Self { config }\n    }\n\n    pub fn from_config(config: \u0026serde_yaml::Value) -\u003e Option\u003cSelf\u003e {\n        let config = ProxyConfig::from_config(config)?;\n        Some(Self::new(config))\n    }\n}\n\nimpl ProxyProvider for RandomProxyProvider {\n    fn get_proxy(\u0026self) -\u003e Option\u003cString\u003e {\n        if !self.config.use_proxy || self.config.uris.is_empty() {\n            return None;\n        }\n\n        // Create a new thread_rng for each call\n        let mut rng = thread_rng();\n        self.config.uris.choose(\u0026mut rng).cloned()\n    }\n}\n\n// Round robin implementation\n#[derive(Debug)]\npub struct RoundRobinProxyProvider {\n    config: ProxyConfig,\n    current: Mutex\u003cusize\u003e,\n}\n\nimpl RoundRobinProxyProvider {\n    pub fn new(config: ProxyConfig) -\u003e Self {\n        Self {\n            config,\n            current: Mutex::new(0),\n        }\n    }\n\n    pub fn from_config(config: \u0026serde_yaml::Value) -\u003e Option\u003cSelf\u003e {\n        let config = ProxyConfig::from_config(config)?;\n        Some(Self::new(config))\n    }\n}\n\nimpl ProxyProvider for RoundRobinProxyProvider {\n    fn get_proxy(\u0026self) -\u003e Option\u003cString\u003e {\n        if !self.config.use_proxy || self.config.uris.is_empty() {\n            return None;\n        }\n\n        let mut current = self.current.lock().ok()?;\n        let proxy = self.config.uris[*current].clone();\n        *current = (*current + 1) % self.config.uris.len();\n        Some(proxy)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use serde_yaml::Value;\n\n    const YAML_CONF_SINGLE: \u0026str = r#\"\n    proxy:\n        use: true\n        uri: http://proxy1.example.com:8080\n        timeout: 30\n        connect_timeout: 10\n    \"#;\n\n    const YAML_CONF_MULTIPLE: \u0026str = r#\"\n    proxy:\n        use: true\n        uris:\n            - http://proxy1.example.com:8080\n            - http://proxy2.example.com:8080\n            - http://proxy3.example.com:8080\n        timeout: 30\n        connect_timeout: 10\n    \"#;\n\n    #[test]\n    fn test_proxy_provider() {\n        let config: Value = serde_yaml::from_str(YAML_CONF_SINGLE).unwrap();\n        let provider = RandomProxyProvider::from_config(\u0026config[\"proxy\"]).unwrap();\n\n        let proxy_url = provider.get_proxy().unwrap();\n        assert!(proxy_url.as_str() == \"http://proxy1.example.com:8080\");\n    }\n\n    #[test]\n    fn test_random_proxy_provider() {\n        let config: Value = serde_yaml::from_str(YAML_CONF_MULTIPLE).unwrap();\n        let provider = RandomProxyProvider::from_config(\u0026config[\"proxy\"]).unwrap();\n\n        // Test multiple calls return different proxies\n        let mut seen = std::collections::HashSet::new();\n        for _ in 0..10 {\n            if let Some(proxy) = provider.get_proxy() {\n                seen.insert(proxy);\n            }\n        }\n        assert!(seen.len() \u003e 1); // Should see multiple different proxies\n    }\n\n    #[test]\n    fn test_round_robin_proxy_provider() {\n        let config: Value = serde_yaml::from_str(YAML_CONF_MULTIPLE).unwrap();\n        let provider =\n            RoundRobinProxyProvider::from_config(\u0026config[\"proxy\"]).unwrap();\n\n        // Test round robin behavior\n        let first = provider.get_proxy();\n        let second = provider.get_proxy();\n        let third = provider.get_proxy();\n        let fourth = provider.get_proxy(); // Should wrap around to first\n\n        assert_ne!(first, second);\n        assert_ne!(second, third);\n        assert_eq!(first, fourth);\n    }\n\n    #[test]\n    fn test_proxy_provider_disabled() {\n        let config: Value = serde_yaml::from_str(\n            r#\"\n        proxy:\n            use: false\n            uri: http://proxy1.example.com:8080\n        \"#,\n        )\n        .unwrap();\n\n        let provider = RandomProxyProvider::from_config(\u0026config[\"proxy\"]).unwrap();\n        assert_eq!(provider.get_proxy(), None);\n    }\n\n    #[test]\n    fn test_proxy_config_port_range() {\n        let yaml = r#\"\n        proxy:\n            use: true\n            uri: http://proxy1.example.com:{8080-8082}\n        \"#;\n\n        let config: Value = serde_yaml::from_str(yaml).unwrap();\n        let proxy_config = ProxyConfig::from_config(\u0026config[\"proxy\"]).unwrap();\n\n        assert_eq!(proxy_config.uris.len(), 3);\n        assert!(proxy_config\n            .uris\n            .contains(\u0026\"http://proxy1.example.com:8080\".to_string()));\n        assert!(proxy_config\n            .uris\n            .contains(\u0026\"http://proxy1.example.com:8081\".to_string()));\n        assert!(proxy_config\n            .uris\n            .contains(\u0026\"http://proxy1.example.com:8082\".to_string()));\n    }\n\n    #[test]\n    fn test_proxy_config_multiple_uris_with_ranges() {\n        let yaml = r#\"\n        proxy:\n            use: true\n            uris:\n                - http://proxy1.example.com:{8080-8082}\n                - http://proxy2.example.com:8090\n                - http://proxy3.example.com:{9000-9001}\n        \"#;\n\n        let config: Value = serde_yaml::from_str(yaml).unwrap();\n        let proxy_config = ProxyConfig::from_config(\u0026config[\"proxy\"]).unwrap();\n\n        assert_eq!(proxy_config.uris.len(), 6); // 3 from first range + 1 single + 2 from last range\n        assert!(proxy_config\n            .uris\n            .contains(\u0026\"http://proxy2.example.com:8090\".to_string()));\n    }\n\n    #[test]\n    fn test_invalid_port_range() {\n        let yaml = r#\"\n        proxy:\n            use: true\n            uri: http://proxy1.example.com:{8082-8080}\n        \"#;\n\n        let config: Value = serde_yaml::from_str(yaml).unwrap();\n        let proxy_config = ProxyConfig::from_config(\u0026config[\"proxy\"]).unwrap();\n\n        // Should treat invalid range as literal string\n        assert_eq!(proxy_config.uris.len(), 1);\n        assert_eq!(\n            proxy_config.uris[0],\n            \"http://proxy1.example.com:{8082-8080}\".to_string()\n        );\n    }\n\n    #[test]\n    fn test_no_port_range() {\n        let yaml = r#\"\n        proxy:\n            use: true\n            uri: http://proxy1.example.com:8080\n        \"#;\n\n        let config: Value = serde_yaml::from_str(yaml).unwrap();\n        let proxy_config = ProxyConfig::from_config(\u0026config[\"proxy\"]).unwrap();\n\n        assert_eq!(proxy_config.uris.len(), 1);\n        assert_eq!(\n            proxy_config.uris[0],\n            \"http://proxy1.example.com:8080\".to_string()\n        );\n    }\n}\n","traces":[{"line":13,"address":[],"length":0,"stats":{"Line":1}},{"line":14,"address":[],"length":0,"stats":{"Line":1}},{"line":24,"address":[],"length":0,"stats":{"Line":21}},{"line":25,"address":[],"length":0,"stats":{"Line":30}},{"line":26,"address":[],"length":0,"stats":{"Line":9}},{"line":27,"address":[],"length":0,"stats":{"Line":9}},{"line":28,"address":[],"length":0,"stats":{"Line":9}},{"line":30,"address":[],"length":0,"stats":{"Line":9}},{"line":31,"address":[],"length":0,"stats":{"Line":7}},{"line":32,"address":[],"length":0,"stats":{"Line":33}},{"line":33,"address":[],"length":0,"stats":{"Line":7}},{"line":37,"address":[],"length":0,"stats":{"Line":14}},{"line":40,"address":[],"length":0,"stats":{"Line":14}},{"line":41,"address":[],"length":0,"stats":{"Line":28}},{"line":42,"address":[],"length":0,"stats":{"Line":14}},{"line":43,"address":[],"length":0,"stats":{"Line":13}},{"line":44,"address":[],"length":0,"stats":{"Line":4}},{"line":46,"address":[],"length":0,"stats":{"Line":20}},{"line":47,"address":[],"length":0,"stats":{"Line":4}},{"line":50,"address":[],"length":0,"stats":{"Line":18}},{"line":51,"address":[],"length":0,"stats":{"Line":9}},{"line":53,"address":[],"length":0,"stats":{"Line":0}},{"line":58,"address":[],"length":0,"stats":{"Line":1}},{"line":71,"address":[],"length":0,"stats":{"Line":9}},{"line":75,"address":[],"length":0,"stats":{"Line":9}},{"line":76,"address":[],"length":0,"stats":{"Line":18}},{"line":82,"address":[],"length":0,"stats":{"Line":45}},{"line":83,"address":[],"length":0,"stats":{"Line":89}},{"line":84,"address":[],"length":0,"stats":{"Line":1}},{"line":88,"address":[],"length":0,"stats":{"Line":44}},{"line":89,"address":[],"length":0,"stats":{"Line":44}},{"line":101,"address":[],"length":0,"stats":{"Line":1}},{"line":104,"address":[],"length":0,"stats":{"Line":1}},{"line":108,"address":[],"length":0,"stats":{"Line":1}},{"line":109,"address":[],"length":0,"stats":{"Line":2}},{"line":115,"address":[],"length":0,"stats":{"Line":4}},{"line":116,"address":[],"length":0,"stats":{"Line":8}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":4}},{"line":121,"address":[],"length":0,"stats":{"Line":4}},{"line":122,"address":[],"length":0,"stats":{"Line":4}},{"line":123,"address":[],"length":0,"stats":{"Line":4}}],"covered":40,"coverable":42},{"path":["/","Users","alexc","code","capp-rs","capp-config","src","router.rs"],"content":"//! URL classification and routing module.\n//!\n//! This module provides functionality for classifying URLs based on predefined rules\n//! and grouping them into categories. It is designed to be flexible and extensible,\n//! allowing for various classification strategies.\n//!\n//! The main components of this module are:\n//!\n//! - `Router`: The primary struct for URL classification and routing.\n//! - `URLClassifier`: An internal struct used by `Router` for URL classification.\n//! - `ClassificationRule`: A trait for implementing custom classification rules.\n//! - `RegexRule`: A concrete implementation of `ClassificationRule` using regular expressions.\n//!\n//! # Examples\n//!\n//! ```\n//! use capp_config::router::Router;\n//! use url::Url;\n//!\n//! let mut router = Router::new();\n//! router.add_regex_rule(\"example\", vec![\"example\\\\.com\"], vec![\"subdomain\\\\.example\\\\.com\"]).unwrap();\n//!\n//! let url = Url::parse(\"https://example.com/page\").unwrap();\n//! assert_eq!(router.classify_url(\u0026url), Some(\"example\".to_string()));\n//! ```\n//!\n//! This module is designed to be used optionally within a larger application context,\n//! providing URL classification capabilities when needed without being a mandatory component.\n#![warn(clippy::unwrap_used)]\nuse indexmap::IndexMap;\nuse regex::Regex;\nuse url::Url;\n\n// ClassifiedURLs as a type alias using IndexMap\npub type ClassifiedURLs = IndexMap\u003cString, Vec\u003cUrl\u003e\u003e;\n\n/// A URL classifier and router.\n///\n/// This struct provides functionality to classify URLs based on predefined rules\n/// and group them into categories.\n#[derive(Debug)]\npub struct Router {\n    classifier: URLClassifier,\n}\n\n// Define a trait for classification rules\ntrait ClassificationRule: Send + Sync {\n    fn classify(\u0026self, url: \u0026Url) -\u003e Option\u003cString\u003e;\n}\n\n// Implement the regex-based rule\nstruct RegexRule {\n    name: String,\n    allow: Vec\u003cRegex\u003e,\n    except: Vec\u003cRegex\u003e,\n}\n\nimpl Router {\n    /// Creates a new Router instance.\n    ///\n    /// # Returns\n    ///\n    /// A new `Router` with an empty set of classification rules.\n    pub fn new() -\u003e Self {\n        Router {\n            classifier: URLClassifier::new(),\n        }\n    }\n\n    /// Adds a new regex-based rule to the router.\n    ///\n    /// # Arguments\n    ///\n    /// * `name` - The name of the category this rule defines.\n    /// * `allow` - A vector of regex patterns that URLs must match to be included.\n    /// * `except` - A vector of regex patterns that, if matched, will exclude a URL.\n    ///\n    /// # Returns\n    ///\n    /// A `Result` which is `Ok(())` if the rule was added successfully, or an\n    /// `Err` containing a `regex::Error` if there was an issue compiling the regexes.\n    pub fn add_regex_rule(\n        \u0026mut self,\n        name: \u0026str,\n        allow: Vec\u003c\u0026str\u003e,\n        except: Vec\u003c\u0026str\u003e,\n    ) -\u003e Result\u003c(), regex::Error\u003e {\n        let rule = RegexRule {\n            name: name.to_string(),\n            allow: allow\n                .into_iter()\n                .map(Regex::new)\n                .collect::\u003cResult\u003c_, _\u003e\u003e()?,\n            except: except\n                .into_iter()\n                .map(Regex::new)\n                .collect::\u003cResult\u003c_, _\u003e\u003e()?,\n        };\n        self.classifier.add_rule(Box::new(rule));\n        Ok(())\n    }\n\n    /// Classifies a list of URLs into categories.\n    ///\n    /// # Arguments\n    ///\n    /// * `urls` - A vector of `Url`s to classify.\n    ///\n    /// # Returns\n    ///\n    /// An `IndexMap` where keys are category names and values are vectors of URLs\n    /// that belong to that category.\n    pub fn classify_urls(\u0026self, urls: Vec\u003cUrl\u003e) -\u003e ClassifiedURLs {\n        let mut classified = ClassifiedURLs::new();\n        for url in urls {\n            if let Some(category) = self.classifier.classify(\u0026url) {\n                classified.entry(category).or_default().push(url);\n            }\n        }\n        classified\n    }\n\n    /// Classifies a single URL.\n    ///\n    /// # Arguments\n    ///\n    /// * `url` - The `Url` to classify.\n    ///\n    /// # Returns\n    ///\n    /// An `Option\u003cString\u003e` containing the category name if the URL was classified,\n    /// or `None` if no matching rule was found.\n    pub fn classify_url(\u0026self, url: \u0026Url) -\u003e Option\u003cString\u003e {\n        self.classifier.classify(url)\n    }\n}\n\nimpl Default for Router {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\nimpl ClassificationRule for RegexRule {\n    fn classify(\u0026self, url: \u0026Url) -\u003e Option\u003cString\u003e {\n        let domain = url.domain()?;\n        let path = url.path();\n        let test_str = format!(\"{}{}\", domain, path);\n\n        #[allow(clippy::collapsible_if)]\n        if self.allow.iter().any(|r| r.is_match(\u0026test_str)) {\n            if self.except.iter().all(|r| !r.is_match(\u0026test_str)) {\n                return Some(self.name.clone());\n            }\n        }\n        None\n    }\n}\n\n// URLClassifier struct\npub struct URLClassifier {\n    rules: Vec\u003cBox\u003cdyn ClassificationRule\u003e\u003e,\n}\n\nimpl std::fmt::Debug for URLClassifier {\n    fn fmt(\u0026self, f: \u0026mut std::fmt::Formatter\u003c'_\u003e) -\u003e std::fmt::Result {\n        f.debug_struct(\"URLClassifier\")\n            .field(\"rules_count\", \u0026self.rules.len())\n            .finish()\n    }\n}\n\nimpl URLClassifier {\n    fn new() -\u003e Self {\n        URLClassifier { rules: Vec::new() }\n    }\n\n    fn add_rule(\u0026mut self, rule: Box\u003cdyn ClassificationRule\u003e) {\n        self.rules.push(rule);\n    }\n\n    fn classify(\u0026self, url: \u0026Url) -\u003e Option\u003cString\u003e {\n        for rule in \u0026self.rules {\n            if let Some(classification) = rule.classify(url) {\n                return Some(classification);\n            }\n        }\n        None\n    }\n}\n\n#[cfg(test)]\n#[allow(clippy::unwrap_used)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_add_regex_rule() {\n        let mut router = Router::new();\n        let result = router.add_regex_rule(\n            \"example\",\n            vec![\"example\\\\.com\"],\n            vec![\"subdomain\\\\.example\\\\.com\"],\n        );\n        assert!(result.is_ok());\n    }\n\n    #[test]\n    fn test_classify_url() {\n        let mut router = Router::new();\n        router\n            .add_regex_rule(\n                \"example\",\n                vec![\"example\\\\.com\"],\n                vec![\"subdomain\\\\.example\\\\.com\"],\n            )\n            .unwrap();\n\n        let url = Url::parse(\"https://example.com/page\").unwrap();\n        assert_eq!(router.classify_url(\u0026url), Some(\"example\".to_string()));\n\n        let url = Url::parse(\"https://subdomain.example.com/page\").unwrap();\n        assert_eq!(router.classify_url(\u0026url), None);\n    }\n\n    #[test]\n    fn test_classify_urls() {\n        let mut router = Router::new();\n        router\n            .add_regex_rule(\n                \"example\",\n                vec![\"example\\\\.com\"],\n                vec![\"subdomain\\\\.example\\\\.com\"],\n            )\n            .unwrap();\n\n        let urls = vec![\n            Url::parse(\"https://example.com/page1\").unwrap(),\n            Url::parse(\"https://subdomain.example.com/page\").unwrap(),\n            Url::parse(\"https://example.com/page2\").unwrap(),\n        ];\n\n        let classified = router.classify_urls(urls);\n        assert_eq!(classified.len(), 1);\n        assert_eq!(classified[\"example\"].len(), 2);\n    }\n}\n","traces":[{"line":64,"address":[],"length":0,"stats":{"Line":3}},{"line":66,"address":[],"length":0,"stats":{"Line":3}},{"line":82,"address":[],"length":0,"stats":{"Line":3}},{"line":89,"address":[],"length":0,"stats":{"Line":3}},{"line":90,"address":[],"length":0,"stats":{"Line":3}},{"line":94,"address":[],"length":0,"stats":{"Line":3}},{"line":99,"address":[],"length":0,"stats":{"Line":3}},{"line":100,"address":[],"length":0,"stats":{"Line":3}},{"line":113,"address":[],"length":0,"stats":{"Line":1}},{"line":114,"address":[],"length":0,"stats":{"Line":1}},{"line":115,"address":[],"length":0,"stats":{"Line":7}},{"line":116,"address":[],"length":0,"stats":{"Line":4}},{"line":117,"address":[],"length":0,"stats":{"Line":2}},{"line":120,"address":[],"length":0,"stats":{"Line":1}},{"line":133,"address":[],"length":0,"stats":{"Line":2}},{"line":134,"address":[],"length":0,"stats":{"Line":2}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":5}},{"line":146,"address":[],"length":0,"stats":{"Line":10}},{"line":151,"address":[],"length":0,"stats":{"Line":5}},{"line":152,"address":[],"length":0,"stats":{"Line":10}},{"line":153,"address":[],"length":0,"stats":{"Line":3}},{"line":156,"address":[],"length":0,"stats":{"Line":2}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":174,"address":[],"length":0,"stats":{"Line":3}},{"line":175,"address":[],"length":0,"stats":{"Line":3}},{"line":178,"address":[],"length":0,"stats":{"Line":3}},{"line":179,"address":[],"length":0,"stats":{"Line":3}},{"line":182,"address":[],"length":0,"stats":{"Line":5}},{"line":183,"address":[],"length":0,"stats":{"Line":12}},{"line":184,"address":[],"length":0,"stats":{"Line":3}},{"line":185,"address":[],"length":0,"stats":{"Line":3}},{"line":188,"address":[],"length":0,"stats":{"Line":2}}],"covered":31,"coverable":36},{"path":["/","Users","alexc","code","capp-rs","capp-queue","src","backend","memory.rs"],"content":"//! In-memory implementation of TaskStorage trait. The storage allows tasks to be\n//! pushed to and popped from a queue, and also allows tasks to be set and\n//! retrieved by their UUID.\n\nuse crate::queue::{TaskQueue, TaskQueueError};\nuse crate::task::{Task, TaskId};\nuse async_trait::async_trait;\nuse serde::de::DeserializeOwned;\nuse serde::Serialize;\nuse std::collections::{HashMap, VecDeque};\nuse std::marker::PhantomData;\nuse std::sync::Mutex;\n\npub struct InMemoryTaskQueue\u003cD\u003e {\n    pub hashmap: Mutex\u003cHashMap\u003cTaskId, String\u003e\u003e,\n    pub list: Mutex\u003cVecDeque\u003cTaskId\u003e\u003e,\n    pub dlq: Mutex\u003cHashMap\u003cTaskId, String\u003e\u003e,\n    _marker: PhantomData\u003cD\u003e,\n}\n\nimpl\u003cD\u003e InMemoryTaskQueue\u003cD\u003e {\n    pub fn new() -\u003e Self {\n        Self {\n            hashmap: Mutex::new(HashMap::new()),\n            list: Mutex::new(VecDeque::new()),\n            dlq: Mutex::new(HashMap::new()),\n            _marker: PhantomData,\n        }\n    }\n}\n\nimpl\u003cD\u003e Default for InMemoryTaskQueue\u003cD\u003e {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\n#[async_trait]\nimpl\u003cD\u003e TaskQueue\u003cD\u003e for InMemoryTaskQueue\u003cD\u003e\nwhere\n    D: std::fmt::Debug\n        + Clone\n        + Serialize\n        + DeserializeOwned\n        + Send\n        + Sync\n        + 'static,\n{\n    async fn push(\u0026self, task: \u0026Task\u003cD\u003e) -\u003e Result\u003c(), TaskQueueError\u003e {\n        let mut list = self\n            .list\n            .lock()\n            .map_err(|e| TaskQueueError::QueueError(e.to_string()))?;\n        let mut hashmap = self\n            .hashmap\n            .lock()\n            .map_err(|e| TaskQueueError::QueueError(e.to_string()))?;\n\n        let task_value = serde_json::to_string(task)\n            .map_err(|e| TaskQueueError::SerdeError(e.to_string()))?;\n        hashmap.insert(task.task_id, task_value);\n        list.push_back(task.task_id);\n        Ok(())\n    }\n\n    async fn pop(\u0026self) -\u003e Result\u003cTask\u003cD\u003e, TaskQueueError\u003e {\n        let mut list = self\n            .list\n            .lock()\n            .map_err(|e| TaskQueueError::QueueError(e.to_string()))?;\n        let hashmap = self\n            .hashmap\n            .lock()\n            .map_err(|e| TaskQueueError::QueueError(e.to_string()))?;\n\n        if let Some(task_id) = list.pop_front() {\n            let task_value = hashmap\n                .get(\u0026task_id)\n                .ok_or(TaskQueueError::TaskNotFound(task_id))?;\n            let task: Task\u003cD\u003e = serde_json::from_str(task_value)\n                .map_err(|e| TaskQueueError::SerdeError(e.to_string()))?;\n            Ok(task)\n        } else {\n            Err(TaskQueueError::QueueEmpty)\n        }\n    }\n\n    async fn ack(\u0026self, task_id: \u0026TaskId) -\u003e Result\u003c(), TaskQueueError\u003e {\n        let mut hashmap = self\n            .hashmap\n            .lock()\n            .map_err(|e| TaskQueueError::QueueError(e.to_string()))?;\n        hashmap\n            .remove(task_id)\n            .ok_or(TaskQueueError::TaskNotFound(*task_id))?;\n        Ok(())\n    }\n\n    async fn nack(\u0026self, task: \u0026Task\u003cD\u003e) -\u003e Result\u003c(), TaskQueueError\u003e {\n        let mut dlq = self\n            .dlq\n            .lock()\n            .map_err(|e| TaskQueueError::QueueError(e.to_string()))?;\n        let task_value = serde_json::to_string(task)\n            .map_err(|e| TaskQueueError::SerdeError(e.to_string()))?;\n        dlq.insert(task.task_id, task_value);\n\n        let mut hashmap = self\n            .hashmap\n            .lock()\n            .map_err(|e| TaskQueueError::QueueError(e.to_string()))?;\n        hashmap\n            .remove(\u0026task.task_id)\n            .ok_or(TaskQueueError::TaskNotFound(task.task_id))?;\n\n        Ok(())\n    }\n\n    async fn set(\u0026self, task: \u0026Task\u003cD\u003e) -\u003e Result\u003c(), TaskQueueError\u003e {\n        let mut hashmap = self\n            .hashmap\n            .lock()\n            .map_err(|e| TaskQueueError::QueueError(e.to_string()))?;\n        let task_value = serde_json::to_string(task)\n            .map_err(|e| TaskQueueError::SerdeError(e.to_string()))?;\n        hashmap.insert(task.task_id, task_value);\n        Ok(())\n    }\n}\n\nimpl\u003cD\u003e std::fmt::Debug for InMemoryTaskQueue\u003cD\u003e {\n    fn fmt(\u0026self, f: \u0026mut std::fmt::Formatter\u003c'_\u003e) -\u003e std::fmt::Result {\n        let hashmap = self.hashmap.lock().unwrap();\n        let list = self.list.lock().unwrap();\n        let dlq = self.dlq.lock().unwrap();\n\n        f.debug_struct(\"InMemoryTaskQueue\")\n            .field(\"hashmap\", \u0026*hashmap)\n            .field(\"list\", \u0026*list)\n            .field(\"dlq\", \u0026*dlq)\n            .finish()\n    }\n}\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use serde::{Deserialize, Serialize};\n\n    #[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n    struct TestData {\n        value: u32,\n    }\n\n    #[tokio::test]\n    async fn test_push_and_pop() {\n        let queue = InMemoryTaskQueue::\u003cTestData\u003e::new();\n        let task = Task::new(TestData { value: 42 });\n\n        queue.push(\u0026task).await.unwrap();\n        let popped_task = queue.pop().await.unwrap();\n\n        assert_eq!(popped_task.payload, TestData { value: 42 });\n    }\n\n    #[tokio::test]\n    async fn test_queue_empty() {\n        let queue = InMemoryTaskQueue::\u003cTestData\u003e::new();\n\n        match queue.pop().await {\n            Err(TaskQueueError::QueueEmpty) =\u003e (),\n            _ =\u003e panic!(\"Expected QueueEmpty error\"),\n        }\n    }\n\n    #[tokio::test]\n    async fn test_ack() {\n        let queue = InMemoryTaskQueue::\u003cTestData\u003e::new();\n        let task = Task::new(TestData { value: 42 });\n\n        queue.push(\u0026task).await.unwrap();\n        let popped_task = queue.pop().await.unwrap();\n        queue.ack(\u0026popped_task.task_id).await.unwrap();\n\n        // The queue should be empty after ack\n        assert!(matches!(queue.pop().await, Err(TaskQueueError::QueueEmpty)));\n    }\n\n    #[tokio::test]\n    async fn test_nack() {\n        let queue = InMemoryTaskQueue::\u003cTestData\u003e::new();\n        let task = Task::new(TestData { value: 42 });\n\n        queue.push(\u0026task).await.unwrap();\n        let popped_task = queue.pop().await.unwrap();\n        queue.nack(\u0026popped_task).await.unwrap();\n\n        // The queue should be empty after nack\n        assert!(matches!(queue.pop().await, Err(TaskQueueError::QueueEmpty)));\n\n        // The task should be in the DLQ\n        let dlq = queue.dlq.lock().unwrap();\n        assert_eq!(dlq.len(), 1);\n    }\n\n    #[tokio::test]\n    async fn test_set() {\n        let queue = InMemoryTaskQueue::\u003cTestData\u003e::new();\n        let mut task = Task::new(TestData { value: 42 });\n\n        queue.push(\u0026task).await.unwrap();\n\n        // Modify the task\n        task.payload.value = 43;\n        queue.set(\u0026task).await.unwrap();\n\n        let updated_task = queue.pop().await.unwrap();\n        assert_eq!(updated_task.payload, TestData { value: 43 });\n    }\n\n    #[tokio::test]\n    async fn test_multiple_tasks() {\n        let queue = InMemoryTaskQueue::\u003cTestData\u003e::new();\n        let tasks = vec![\n            Task::new(TestData { value: 1 }),\n            Task::new(TestData { value: 2 }),\n            Task::new(TestData { value: 3 }),\n        ];\n\n        for task in \u0026tasks {\n            queue.push(task).await.unwrap();\n        }\n\n        for expected_task in tasks {\n            let popped_task = queue.pop().await.unwrap();\n            assert_eq!(popped_task.payload, expected_task.payload);\n        }\n\n        // Queue should be empty now\n        assert!(matches!(queue.pop().await, Err(TaskQueueError::QueueEmpty)));\n    }\n\n    #[tokio::test]\n    async fn test_task_not_found() {\n        let queue = InMemoryTaskQueue::\u003cTestData\u003e::new();\n        let non_existent_task_id = TaskId::new();\n\n        match queue.ack(\u0026non_existent_task_id).await {\n            Err(TaskQueueError::TaskNotFound(_)) =\u003e (),\n            _ =\u003e panic!(\"Expected TaskNotFound error\"),\n        }\n    }\n}\n","traces":[{"line":22,"address":[],"length":0,"stats":{"Line":7}},{"line":24,"address":[],"length":0,"stats":{"Line":7}},{"line":25,"address":[],"length":0,"stats":{"Line":7}},{"line":26,"address":[],"length":0,"stats":{"Line":7}},{"line":33,"address":[],"length":0,"stats":{"Line":0}},{"line":34,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":7}},{"line":50,"address":[],"length":0,"stats":{"Line":14}},{"line":51,"address":[],"length":0,"stats":{"Line":7}},{"line":53,"address":[],"length":0,"stats":{"Line":14}},{"line":54,"address":[],"length":0,"stats":{"Line":7}},{"line":55,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":59,"address":[],"length":0,"stats":{"Line":7}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":7}},{"line":62,"address":[],"length":0,"stats":{"Line":7}},{"line":63,"address":[],"length":0,"stats":{"Line":7}},{"line":66,"address":[],"length":0,"stats":{"Line":11}},{"line":67,"address":[],"length":0,"stats":{"Line":22}},{"line":68,"address":[],"length":0,"stats":{"Line":11}},{"line":70,"address":[],"length":0,"stats":{"Line":22}},{"line":71,"address":[],"length":0,"stats":{"Line":11}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":7}},{"line":77,"address":[],"length":0,"stats":{"Line":7}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":7}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":7}},{"line":84,"address":[],"length":0,"stats":{"Line":4}},{"line":88,"address":[],"length":0,"stats":{"Line":2}},{"line":89,"address":[],"length":0,"stats":{"Line":4}},{"line":90,"address":[],"length":0,"stats":{"Line":2}},{"line":92,"address":[],"length":0,"stats":{"Line":4}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":1}},{"line":96,"address":[],"length":0,"stats":{"Line":1}},{"line":99,"address":[],"length":0,"stats":{"Line":1}},{"line":100,"address":[],"length":0,"stats":{"Line":2}},{"line":101,"address":[],"length":0,"stats":{"Line":1}},{"line":103,"address":[],"length":0,"stats":{"Line":2}},{"line":104,"address":[],"length":0,"stats":{"Line":1}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":1}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":1}},{"line":119,"address":[],"length":0,"stats":{"Line":1}},{"line":120,"address":[],"length":0,"stats":{"Line":2}},{"line":121,"address":[],"length":0,"stats":{"Line":1}},{"line":123,"address":[],"length":0,"stats":{"Line":2}},{"line":124,"address":[],"length":0,"stats":{"Line":1}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":1}},{"line":127,"address":[],"length":0,"stats":{"Line":1}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}}],"covered":43,"coverable":71},{"path":["/","Users","alexc","code","capp-rs","capp-queue","src","backend","redis.rs"],"content":"//! Provides implementation of trait to store task into redis\nuse async_trait::async_trait;\nuse rustis::client::{BatchPreparedCommand, Client, Pipeline};\nuse rustis::commands::{HashCommands, ListCommands};\nuse serde::{de::DeserializeOwned, Serialize};\nuse std::marker::PhantomData;\n\nuse crate::queue::{TaskQueue, TaskQueueError};\nuse crate::task::{Task, TaskId};\n\npub struct RedisTaskQueue\u003cD\u003e {\n    pub client: Client,\n    pub list_key: String,\n    pub hashmap_key: String,\n    pub dlq_key: String,\n    _marker: PhantomData\u003cD\u003e,\n}\n\nimpl\u003cD\u003e RedisTaskQueue\u003cD\u003e {\n    pub async fn new(\n        client: Client,\n        queue_name: \u0026str,\n    ) -\u003e Result\u003cSelf, TaskQueueError\u003e {\n        Ok(Self {\n            client,\n            list_key: format!(\"{}:{}\", queue_name, \"ls\"),\n            hashmap_key: format!(\"{}:{}\", queue_name, \"hm\"),\n            dlq_key: format!(\"{}:{}\", queue_name, \"dlq\"),\n            _marker: PhantomData,\n        })\n    }\n\n    async fn execute_pipeline(\n        \u0026self,\n        pipeline: Pipeline\u003c'_\u003e,\n    ) -\u003e Result\u003c(), TaskQueueError\u003e {\n        // NOTE: this strange construction .map(|_: ()| ())\n        // This change explicitly specifies that we're expecting a () (unit type) as the successful\n        // result of execute(). By doing this, we're no longer relying on the never type fallback,\n        // which resolves the warning.\n        pipeline\n            .execute()\n            .await\n            .map(|_: ()| ())\n            .map_err(|e| TaskQueueError::QueueError(e.to_string()))?;\n        Ok(())\n    }\n}\n\n#[async_trait]\nimpl\u003cD\u003e TaskQueue\u003cD\u003e for RedisTaskQueue\u003cD\u003e\nwhere\n    D: std::fmt::Debug\n        + Clone\n        + Serialize\n        + DeserializeOwned\n        + Send\n        + Sync\n        + 'static,\n{\n    async fn push(\u0026self, task: \u0026Task\u003cD\u003e) -\u003e Result\u003c(), TaskQueueError\u003e {\n        let task_json = serde_json::to_string(task)\n            .map_err(|e| TaskQueueError::SerdeError(e.to_string()))?;\n\n        let mut pipeline = self.client.create_pipeline();\n        pipeline\n            .rpush(\u0026self.list_key, \u0026task.task_id.to_string())\n            .forget();\n        pipeline\n            .hset(\u0026self.hashmap_key, [(\u0026task.task_id.to_string(), \u0026task_json)])\n            .forget();\n        self.execute_pipeline(pipeline).await\n    }\n\n    async fn pop(\u0026self) -\u003e Result\u003cTask\u003cD\u003e, TaskQueueError\u003e {\n        let task_ids: Vec\u003cString\u003e = self\n            .client\n            .lpop(\u0026self.list_key, 1)\n            .await\n            .map_err(|e| TaskQueueError::QueueError(e.to_string()))?;\n\n        if !task_ids.is_empty() {\n            let task_id = task_ids.first().unwrap();\n            let task_value: String =\n                self.client.hget(\u0026self.hashmap_key, task_id).await?;\n\n            let task: Task\u003cD\u003e = serde_json::from_str(\u0026task_value)\n                .map_err(|err| TaskQueueError::SerdeError(err.to_string()))?;\n            return Ok(task);\n        }\n\n        Err(TaskQueueError::QueueEmpty)\n    }\n\n    async fn ack(\u0026self, task_id: \u0026TaskId) -\u003e Result\u003c(), TaskQueueError\u003e {\n        let uuid_as_str = task_id.to_string();\n        let _ = self.client.hdel(\u0026self.hashmap_key, \u0026uuid_as_str).await?;\n        Ok(())\n    }\n\n    async fn nack(\u0026self, task: \u0026Task\u003cD\u003e) -\u003e Result\u003c(), TaskQueueError\u003e {\n        let uuid_as_str = task.task_id.to_string();\n        let task_json = serde_json::to_string(task)\n            .map_err(|e| TaskQueueError::SerdeError(e.to_string()))?;\n\n        let mut pipeline = self.client.create_pipeline();\n        pipeline.rpush(\u0026self.dlq_key, \u0026task_json).forget();\n        pipeline.hdel(\u0026self.hashmap_key, \u0026uuid_as_str).forget();\n        self.execute_pipeline(pipeline).await\n    }\n\n    async fn set(\u0026self, task: \u0026Task\u003cD\u003e) -\u003e Result\u003c(), TaskQueueError\u003e {\n        let task_json = serde_json::to_string(task)\n            .map_err(|e| TaskQueueError::SerdeError(e.to_string()))?;\n\n        self.client\n            .hset(\u0026self.hashmap_key, [(\u0026task.task_id.to_string(), \u0026task_json)])\n            .await\n            .map_err(|e| TaskQueueError::QueueError(e.to_string()))?;\n        Ok(())\n    }\n}\n","traces":[{"line":20,"address":[],"length":0,"stats":{"Line":0}},{"line":24,"address":[],"length":0,"stats":{"Line":0}},{"line":25,"address":[],"length":0,"stats":{"Line":0}},{"line":26,"address":[],"length":0,"stats":{"Line":0}},{"line":27,"address":[],"length":0,"stats":{"Line":0}},{"line":28,"address":[],"length":0,"stats":{"Line":0}},{"line":29,"address":[],"length":0,"stats":{"Line":0}},{"line":33,"address":[],"length":0,"stats":{"Line":0}},{"line":41,"address":[],"length":0,"stats":{"Line":0}},{"line":43,"address":[],"length":0,"stats":{"Line":0}},{"line":44,"address":[],"length":0,"stats":{"Line":0}},{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":46,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":0}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":63,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":56},{"path":["/","Users","alexc","code","capp-rs","capp-queue","src","backend","redis_rr.rs"],"content":"//! `RedisRoundRobinTaskStorage` provides an asynchronous task storage mechanism\n//! built on top of Redis, with a round-robin approach to accessing tasks across\n//! different queues.\n//!\n//! This storage structure maintains domain-specific queues, allowing for tasks\n//! to be categorized and processed based on their associated key. The round-robin\n//! mechanism ensures that tasks from one domain do not dominate the queue, allowing\n//! for balanced task processing across all domains.\n//!\n//! Note: The exact tag key for each task is determined from the `TaskData`\n//! field, and can be configured during the storage initialization.\n\nuse crate::queue::{HasTagKey, TaskQueue, TaskQueueError};\nuse crate::task::{Task, TaskId};\nuse async_trait::async_trait;\nuse rustis::client::{BatchPreparedCommand, Client, Pipeline};\nuse rustis::commands::{\n    GenericCommands, HashCommands, ListCommands, StringCommands,\n};\nuse serde::{de::DeserializeOwned, Serialize};\nuse std::collections::HashSet;\nuse std::marker::PhantomData;\nuse std::sync::Arc;\n\npub struct RedisRoundRobinTaskQueue\u003cD\u003e {\n    pub client: Client,\n    pub key: String,\n    pub tags: Arc\u003cHashSet\u003cString\u003e\u003e,\n    _marker: PhantomData\u003cD\u003e,\n}\n\nimpl\u003cD\u003e RedisRoundRobinTaskQueue\u003cD\u003e {\n    pub async fn new(\n        client: Client,\n        key: \u0026str,\n        tags: HashSet\u003cString\u003e,\n    ) -\u003e Result\u003cSelf, TaskQueueError\u003e {\n        let queue = Self {\n            client,\n            key: key.to_string(),\n            tags: Arc::new(tags),\n            _marker: PhantomData,\n        };\n\n        // Initialize counters for each tag\n        for tag in queue.tags.iter() {\n            queue.client.set(queue.get_counter_key(tag), 0).await?;\n        }\n\n        Ok(queue)\n    }\n\n    pub fn get_hashmap_key(\u0026self) -\u003e String {\n        format!(\"{}:hm\", self.key)\n    }\n\n    pub fn get_list_key(\u0026self, tag: \u0026str) -\u003e String {\n        format!(\"{}:{}:ls\", self.key, tag)\n    }\n\n    pub fn get_counter_key(\u0026self, tag: \u0026str) -\u003e String {\n        format!(\"{}:{}:counter\", self.key, tag)\n    }\n\n    pub fn get_counter_keys(\u0026self) -\u003e Vec\u003cString\u003e {\n        let mut result = vec![];\n        for tag in self.tags.iter() {\n            let key = self.get_counter_key(tag);\n            result.push(key);\n        }\n        result\n    }\n\n    pub fn get_dlq_key(\u0026self) -\u003e String {\n        format!(\"{}:dlq\", self.key)\n    }\n\n    async fn execute_pipeline(\n        \u0026self,\n        pipeline: Pipeline\u003c'_\u003e,\n    ) -\u003e Result\u003c(), TaskQueueError\u003e {\n        pipeline\n            .execute()\n            .await\n            .map(|_: ()| ())\n            .map_err(|e| TaskQueueError::QueueError(e.to_string()))?;\n        Ok(())\n    }\n\n    pub async fn get_next_non_empty_tag(\n        \u0026self,\n    ) -\u003e Result\u003cOption\u003cString\u003e, TaskQueueError\u003e {\n        for tag in self.tags.iter() {\n            let count: i64 = self.client.get(self.get_counter_key(tag)).await?;\n            if count \u003e 0 {\n                return Ok(Some(tag.clone()));\n            }\n        }\n        Ok(None)\n    }\n\n    pub async fn purge(\u0026self) -\u003e Result\u003cusize, TaskQueueError\u003e {\n        let mut keys_to_delete = vec![self.get_hashmap_key(), self.get_dlq_key()];\n        // Add list keys for all tags\n        for tag in self.tags.iter() {\n            keys_to_delete.push(self.get_list_key(tag));\n        }\n        // Add counter keys to the list of keys to delete\n        keys_to_delete.extend(self.get_counter_keys());\n        self.client\n            .del(keys_to_delete)\n            .await\n            .map_err(|e| TaskQueueError::QueueError(e.to_string()))\n    }\n}\n\n#[async_trait]\nimpl\u003cD\u003e TaskQueue\u003cD\u003e for RedisRoundRobinTaskQueue\u003cD\u003e\nwhere\n    D: std::fmt::Debug\n        + Clone\n        + Serialize\n        + DeserializeOwned\n        + Send\n        + Sync\n        + 'static\n        + HasTagKey,\n{\n    async fn push(\u0026self, task: \u0026Task\u003cD\u003e) -\u003e Result\u003c(), TaskQueueError\u003e {\n        let task_json = serde_json::to_string(task)\n            .map_err(|e| TaskQueueError::SerdeError(e.to_string()))?;\n        let tag = task.payload.get_tag_value().to_string();\n        let list_key = self.get_list_key(\u0026tag);\n        let hashmap_key = self.get_hashmap_key();\n        let counter_key = self.get_counter_key(\u0026tag);\n\n        let mut pipeline = self.client.create_pipeline();\n        pipeline\n            .lpush(\u0026list_key, \u0026task.task_id.to_string())\n            .forget();\n        pipeline\n            .hset(\u0026hashmap_key, [(\u0026task.task_id.to_string(), \u0026task_json)])\n            .forget();\n        pipeline.incr(counter_key).forget();\n        self.execute_pipeline(pipeline).await\n    }\n\n    async fn pop(\u0026self) -\u003e Result\u003cTask\u003cD\u003e, TaskQueueError\u003e {\n        let tag = self\n            .get_next_non_empty_tag()\n            .await?\n            .ok_or(TaskQueueError::QueueEmpty)?;\n\n        let list_key = self.get_list_key(\u0026tag);\n        let hashmap_key = self.get_hashmap_key();\n        let counter_key = self.get_counter_key(\u0026tag);\n\n        let task_ids: Vec\u003cString\u003e = self\n            .client\n            .rpop(\u0026list_key, 1)\n            .await\n            .map_err(|e| TaskQueueError::QueueError(e.to_string()))?;\n\n        if let Some(task_id) = task_ids.first() {\n            let task_value: String =\n                self.client.hget(\u0026hashmap_key, task_id).await?;\n            let task: Task\u003cD\u003e = serde_json::from_str(\u0026task_value)\n                .map_err(|err| TaskQueueError::SerdeError(err.to_string()))?;\n\n            // Decrement the counter\n            self.client.decr(counter_key).await?;\n\n            Ok(task)\n        } else {\n            Err(TaskQueueError::QueueEmpty)\n        }\n    }\n\n    async fn ack(\u0026self, task_id: \u0026TaskId) -\u003e Result\u003c(), TaskQueueError\u003e {\n        let uuid_as_str = task_id.to_string();\n        let _ = self\n            .client\n            .hdel(self.get_hashmap_key(), \u0026uuid_as_str)\n            .await?;\n        Ok(())\n    }\n\n    async fn nack(\u0026self, task: \u0026Task\u003cD\u003e) -\u003e Result\u003c(), TaskQueueError\u003e {\n        let uuid_as_str = task.task_id.to_string();\n        let task_json = serde_json::to_string(task)\n            .map_err(|e| TaskQueueError::SerdeError(e.to_string()))?;\n\n        let mut pipeline = self.client.create_pipeline();\n        pipeline.rpush(self.get_dlq_key(), \u0026task_json).forget();\n        pipeline.hdel(self.get_hashmap_key(), \u0026uuid_as_str).forget();\n        self.execute_pipeline(pipeline).await\n    }\n\n    async fn set(\u0026self, task: \u0026Task\u003cD\u003e) -\u003e Result\u003c(), TaskQueueError\u003e {\n        let task_json = serde_json::to_string(task)\n            .map_err(|e| TaskQueueError::SerdeError(e.to_string()))?;\n\n        self.client\n            .hset(\n                self.get_hashmap_key(),\n                [(\u0026task.task_id.to_string(), \u0026task_json)],\n            )\n            .await\n            .map_err(|e| TaskQueueError::QueueError(e.to_string()))?;\n        Ok(())\n    }\n}\n\nimpl\u003cD\u003e std::fmt::Debug for RedisRoundRobinTaskQueue\u003cD\u003e {\n    fn fmt(\u0026self, f: \u0026mut std::fmt::Formatter\u003c'_\u003e) -\u003e std::fmt::Result {\n        f.debug_struct(\"RedisRoundRobinTaskQueue\")\n            .field(\"key\", \u0026self.key)\n            .field(\"tags\", \u0026self.tags)\n            .finish()\n    }\n}\n","traces":[{"line":33,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":0}},{"line":41,"address":[],"length":0,"stats":{"Line":0}},{"line":46,"address":[],"length":0,"stats":{"Line":0}},{"line":47,"address":[],"length":0,"stats":{"Line":0}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":53,"address":[],"length":0,"stats":{"Line":0}},{"line":54,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":58,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":0}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":0}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":152,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":0}},{"line":160,"address":[],"length":0,"stats":{"Line":0}},{"line":161,"address":[],"length":0,"stats":{"Line":0}},{"line":162,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":165,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":171,"address":[],"length":0,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":0}},{"line":179,"address":[],"length":0,"stats":{"Line":0}},{"line":180,"address":[],"length":0,"stats":{"Line":0}},{"line":181,"address":[],"length":0,"stats":{"Line":0}},{"line":182,"address":[],"length":0,"stats":{"Line":0}},{"line":183,"address":[],"length":0,"stats":{"Line":0}},{"line":184,"address":[],"length":0,"stats":{"Line":0}},{"line":185,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":189,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[],"length":0,"stats":{"Line":0}},{"line":193,"address":[],"length":0,"stats":{"Line":0}},{"line":194,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":199,"address":[],"length":0,"stats":{"Line":0}},{"line":200,"address":[],"length":0,"stats":{"Line":0}},{"line":201,"address":[],"length":0,"stats":{"Line":0}},{"line":203,"address":[],"length":0,"stats":{"Line":0}},{"line":205,"address":[],"length":0,"stats":{"Line":0}},{"line":206,"address":[],"length":0,"stats":{"Line":0}},{"line":208,"address":[],"length":0,"stats":{"Line":0}},{"line":209,"address":[],"length":0,"stats":{"Line":0}},{"line":210,"address":[],"length":0,"stats":{"Line":0}},{"line":215,"address":[],"length":0,"stats":{"Line":0}},{"line":216,"address":[],"length":0,"stats":{"Line":0}},{"line":217,"address":[],"length":0,"stats":{"Line":0}},{"line":218,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":103},{"path":["/","Users","alexc","code","capp-rs","capp-queue","src","backend.rs"],"content":"pub mod memory;\n#[cfg(feature = \"redis\")]\npub mod redis;\n#[cfg(feature = \"redis\")]\npub mod redis_rr;\n\npub use memory::InMemoryTaskQueue;\n#[cfg(feature = \"redis\")]\npub use redis::RedisTaskQueue;\n#[cfg(feature = \"redis\")]\npub use redis_rr::RedisRoundRobinTaskQueue;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","capp-queue","src","lib.rs"],"content":"pub mod backend;\npub mod queue;\npub mod task;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","capp-queue","src","queue.rs"],"content":"//! This module provides a trait for interacting with task storage.\n//! The storage allows tasks to be pushed to and popped from a queue,\n//! and also allows tasks to be set and retrieved by their UUID.\n\nuse async_trait::async_trait;\nuse serde::{de::DeserializeOwned, Serialize};\nuse std::sync::Arc;\nuse thiserror::Error;\n\npub use crate::backend::InMemoryTaskQueue;\n#[cfg(feature = \"redis\")]\npub use crate::backend::{RedisRoundRobinTaskQueue, RedisTaskQueue};\nuse crate::task::{Task, TaskId};\n\n#[derive(Error, Debug)]\npub enum TaskQueueError {\n    #[error(\"Queue error: {0}\")]\n    QueueError(String),\n\n    #[error(\"Ser/De error: {0}\")]\n    SerdeError(String),\n\n    #[error(\"Task not found: {0}\")]\n    TaskNotFound(TaskId),\n\n    #[error(\"Queue is empty\")]\n    QueueEmpty,\n\n    #[cfg(feature = \"redis\")]\n    #[error(\"Redis error\")]\n    RedisError(#[from] rustis::Error),\n}\n\n#[async_trait]\npub trait TaskQueue\u003cData\u003e\nwhere\n    Data: std::fmt::Debug\n        + Clone\n        + Serialize\n        + DeserializeOwned\n        + Send\n        + Sync\n        + 'static,\n{\n    async fn push(\u0026self, task: \u0026Task\u003cData\u003e) -\u003e Result\u003c(), TaskQueueError\u003e;\n    async fn pop(\u0026self) -\u003e Result\u003cTask\u003cData\u003e, TaskQueueError\u003e;\n    async fn ack(\u0026self, task_id: \u0026TaskId) -\u003e Result\u003c(), TaskQueueError\u003e;\n    async fn nack(\u0026self, task: \u0026Task\u003cData\u003e) -\u003e Result\u003c(), TaskQueueError\u003e;\n    // NOTE: probably need to move into different trait\n    async fn set(\u0026self, task: \u0026Task\u003cData\u003e) -\u003e Result\u003c(), TaskQueueError\u003e;\n}\n\npub type AbstractTaskQueue\u003cD\u003e = Arc\u003cdyn TaskQueue\u003cD\u003e + Send + Sync\u003e;\n\n// Trait used for round-robin queues\npub trait HasTagKey {\n    type TagValue: ToString + PartialEq;\n    fn get_tag_value(\u0026self) -\u003e Self::TagValue;\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","capp-queue","src","task.rs"],"content":"// use chrono::{DateTime, Utc};\nuse serde::{Deserialize, Serialize};\nuse std::time::SystemTime;\nuse uuid::Uuid;\n\n#[derive(Clone, Debug, Serialize, Deserialize)]\npub enum TaskStatus {\n    Queued,\n    InProgress,\n    Completed,\n    Failed,\n    DeadLetter,\n}\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]\npub struct TaskId(Uuid);\n\n/// A `Task` struct represents a single unit of work that will be processed\n/// by a worker. It contains payload of type `D`, which is used by the worker\n/// during processing. The `Task` struct also includes fields for managing\n/// the task's lifecycle, including the task's UUID, the start and\n/// finish times, the number of retries, and any error messages.\n#[derive(Clone, Debug, Serialize, Deserialize)]\npub struct Task\u003cD: Clone\u003e {\n    pub task_id: TaskId,\n    pub payload: D,\n    pub status: TaskStatus,\n    pub queued_at: SystemTime,\n    pub started_at: Option\u003cSystemTime\u003e,\n    pub finished_at: Option\u003cSystemTime\u003e,\n    pub retries: u32,\n    pub error_msg: Option\u003cString\u003e,\n}\n\nimpl\u003cD: Clone\u003e Task\u003cD\u003e {\n    pub fn new(payload: D) -\u003e Self {\n        Task {\n            task_id: TaskId::new(),\n            payload,\n            status: TaskStatus::Queued,\n            queued_at: SystemTime::now(),\n            started_at: None,\n            finished_at: None,\n            retries: 0,\n            error_msg: None,\n        }\n    }\n\n    pub fn set_in_progress(\u0026mut self) {\n        self.status = TaskStatus::InProgress;\n        self.started_at = Some(SystemTime::now());\n    }\n\n    pub fn set_succeed(\u0026mut self) {\n        self.status = TaskStatus::Completed;\n        self.finished_at = Some(SystemTime::now());\n    }\n\n    pub fn set_retry(\u0026mut self, err_msg: \u0026str) {\n        self.status = TaskStatus::Failed;\n        self.finished_at = Some(SystemTime::now());\n        self.retries += 1;\n        self.error_msg = Some(err_msg.to_string());\n    }\n\n    pub fn set_dlq(\u0026mut self, err_msg: \u0026str) {\n        self.status = TaskStatus::DeadLetter;\n        self.finished_at = Some(SystemTime::now());\n        self.error_msg = Some(err_msg.to_string());\n    }\n\n    pub fn set_status(\u0026mut self, new_status: TaskStatus) {\n        self.status = new_status;\n    }\n\n    pub fn get_payload(\u0026self) -\u003e \u0026D {\n        \u0026self.payload\n    }\n}\n\n//*****************************************************************************\n// TaskId with ser/de traits implemented (to convert underlaying Uuid)\n//*****************************************************************************\n\nimpl TaskId {\n    pub fn new() -\u003e Self {\n        Self(Uuid::new_v4())\n    }\n\n    pub fn get(\u0026self) -\u003e Uuid {\n        self.0\n    }\n}\n\nimpl Default for TaskId {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\n// Custom serialization for TaskId.\nimpl serde::Serialize for TaskId {\n    fn serialize\u003cS\u003e(\u0026self, serializer: S) -\u003e Result\u003cS::Ok, S::Error\u003e\n    where\n        S: serde::Serializer,\n    {\n        // Directly serialize the inner Uuid.\n        self.0.serialize(serializer)\n    }\n}\n\n// Custom deserialization for TaskId.\nimpl\u003c'de\u003e serde::Deserialize\u003c'de\u003e for TaskId {\n    fn deserialize\u003cD\u003e(deserializer: D) -\u003e Result\u003cSelf, D::Error\u003e\n    where\n        D: serde::Deserializer\u003c'de\u003e,\n    {\n        // Deserialize a Uuid and then wrap it in a TaskId.\n        let uuid = Uuid::deserialize(deserializer)?;\n        Ok(TaskId(uuid))\n    }\n}\n\nimpl std::fmt::Display for TaskId {\n    fn fmt(\u0026self, f: \u0026mut std::fmt::Formatter\u003c'_\u003e) -\u003e std::fmt::Result {\n        write!(f, \"TaskId({})\", self.0)\n    }\n}\n\n//*****************************************************************************\n// Tests\n//*****************************************************************************\n\n#[cfg(test)]\nmod tests {\n    use core::panic;\n\n    use super::*;\n    use serde::{Deserialize, Serialize};\n\n    #[derive(Clone, Serialize, Deserialize, Default)]\n    struct TaskData {\n        value: u32,\n    }\n\n    #[test]\n    fn task_id_serde() {\n        let task = Task::new(TaskData { value: 1 });\n        let task_id = task.task_id.clone();\n        let serialized_task_value = serde_json::to_value(task).unwrap();\n        let serialized_task_json = serialized_task_value.to_string();\n        let desrialized_task: Task\u003cTaskData\u003e =\n            serde_json::from_str(\u0026serialized_task_json).unwrap();\n        assert_eq!(task_id, desrialized_task.task_id);\n    }\n\n    #[test]\n    fn test_task_creation() {\n        let task = Task::new(TaskData::default());\n        assert!(task.started_at.is_none());\n        assert!(task.finished_at.is_none());\n        assert_eq!(task.retries, 0);\n        assert_eq!(task.payload.value, 0);\n        match task.status {\n            TaskStatus::Queued =\u003e {}\n            _ =\u003e panic!(\"Wrong status (task.status)\"),\n        };\n    }\n\n    #[test]\n    fn test_in_progress() {\n        let mut task = Task::new(TaskData::default());\n\n        task.set_in_progress();\n        match task.status {\n            TaskStatus::InProgress =\u003e {}\n            _ =\u003e panic!(\"Wrong status (task.status)\"),\n        };\n        assert!(task.started_at.is_some());\n        assert!(task.finished_at.is_none());\n    }\n\n    #[test]\n    fn test_succeed() {\n        let mut task = Task::new(TaskData::default());\n\n        task.set_succeed();\n        match task.status {\n            TaskStatus::Completed =\u003e {}\n            _ =\u003e panic!(\"Wrong status (task.status)\"),\n        };\n        assert!(task.finished_at.is_some());\n        assert!(task.started_at.is_none());\n    }\n\n    #[test]\n    fn test_set_retry() {\n        let mut task = Task::new(TaskData::default());\n\n        task.set_retry(\"Wrong task value\");\n        match task.status {\n            TaskStatus::Failed =\u003e {}\n            _ =\u003e panic!(\"Wrong status (task.status)\"),\n        };\n        assert!(task.finished_at.is_some());\n        assert_eq!(task.retries, 1);\n        assert!(task.error_msg.is_some());\n        assert!(task.started_at.is_none());\n    }\n\n    #[test]\n    fn test_set_dlq() {\n        let mut task = Task::new(TaskData::default());\n\n        task.set_dlq(\"Wrong task value\");\n        match task.status {\n            TaskStatus::DeadLetter =\u003e {}\n            _ =\u003e panic!(\"Wrong status (task.status)\"),\n        };\n        assert!(task.finished_at.is_some());\n        assert!(task.started_at.is_none());\n        assert!(task.error_msg.is_some());\n    }\n\n    #[test]\n    fn task_flow_succeed() {\n        let mut task = Task::new(TaskData::default());\n\n        task.set_in_progress();\n        task.payload.value += 1;\n\n        std::thread::sleep(std::time::Duration::from_millis(5));\n\n        task.set_retry(\"Wrong task value\");\n        task.payload.value += 1;\n\n        task.set_in_progress();\n        std::thread::sleep(std::time::Duration::from_millis(5));\n\n        task.set_succeed();\n\n        match task.status {\n            TaskStatus::Completed =\u003e {}\n            _ =\u003e panic!(\"Wrong status (task.status)\"),\n        };\n        assert_eq!(task.retries, 1);\n        assert_eq!(task.get_payload().value, 2);\n        assert!(task.started_at.is_some());\n        assert!(task.finished_at.is_some());\n\n        // finished_at - started_at\n        assert!(\n            task.finished_at\n                .unwrap()\n                .duration_since(task.started_at.unwrap())\n                .unwrap()\n                \u003c std::time::Duration::from_millis(10)\n        );\n        // finished_at - queue_at\n        assert!(\n            task.finished_at\n                .unwrap()\n                .duration_since(task.queued_at)\n                .unwrap()\n                \u003e= std::time::Duration::from_millis(10)\n        );\n    }\n\n    #[test]\n    fn test_flow() {\n        let mut task = Task::new(TaskData::default());\n\n        task.set_in_progress();\n        task.payload.value += 1;\n\n        std::thread::sleep(std::time::Duration::from_millis(5));\n\n        task.set_retry(\"Wrong task value\");\n        task.payload.value += 1;\n\n        task.set_in_progress();\n        std::thread::sleep(std::time::Duration::from_millis(5));\n\n        task.set_dlq(\"Failed to complete task\");\n\n        match task.status {\n            TaskStatus::DeadLetter =\u003e {}\n            _ =\u003e panic!(\"Wrong status (task.status)\"),\n        };\n        assert_eq!(task.retries, 1);\n        assert_eq!(task.get_payload().value, 2);\n        assert!(task.started_at.is_some());\n        assert!(task.finished_at.is_some());\n\n        // finished_at - started_at\n        assert!(\n            task.finished_at\n                .unwrap()\n                .duration_since(task.started_at.unwrap())\n                .unwrap()\n                \u003c std::time::Duration::from_millis(10)\n        );\n        // finished_at - queue_at\n        assert!(\n            task.finished_at\n                .unwrap()\n                .duration_since(task.queued_at)\n                .unwrap()\n                \u003e= std::time::Duration::from_millis(10)\n        );\n    }\n}\n","traces":[{"line":36,"address":[],"length":0,"stats":{"Line":15}},{"line":38,"address":[],"length":0,"stats":{"Line":15}},{"line":41,"address":[],"length":0,"stats":{"Line":15}},{"line":49,"address":[],"length":0,"stats":{"Line":5}},{"line":50,"address":[],"length":0,"stats":{"Line":5}},{"line":51,"address":[],"length":0,"stats":{"Line":5}},{"line":54,"address":[],"length":0,"stats":{"Line":2}},{"line":55,"address":[],"length":0,"stats":{"Line":2}},{"line":56,"address":[],"length":0,"stats":{"Line":2}},{"line":59,"address":[],"length":0,"stats":{"Line":3}},{"line":60,"address":[],"length":0,"stats":{"Line":3}},{"line":61,"address":[],"length":0,"stats":{"Line":3}},{"line":62,"address":[],"length":0,"stats":{"Line":3}},{"line":63,"address":[],"length":0,"stats":{"Line":3}},{"line":66,"address":[],"length":0,"stats":{"Line":2}},{"line":67,"address":[],"length":0,"stats":{"Line":2}},{"line":68,"address":[],"length":0,"stats":{"Line":2}},{"line":69,"address":[],"length":0,"stats":{"Line":2}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":2}},{"line":77,"address":[],"length":0,"stats":{"Line":2}},{"line":86,"address":[],"length":0,"stats":{"Line":16}},{"line":87,"address":[],"length":0,"stats":{"Line":16}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":10}},{"line":108,"address":[],"length":0,"stats":{"Line":10}},{"line":114,"address":[],"length":0,"stats":{"Line":8}},{"line":119,"address":[],"length":0,"stats":{"Line":16}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}}],"covered":26,"coverable":35},{"path":["/","Users","alexc","code","capp-rs","examples","basic.rs"],"content":"use async_trait::async_trait;\nuse capp::prelude::{\n    Computation, ComputationError, WorkerId, WorkerOptionsBuilder,\n};\nuse capp::{\n    config::Configurable,\n    manager::{WorkersManager, WorkersManagerOptionsBuilder},\n    queue::{AbstractTaskQueue, InMemoryTaskQueue, TaskQueue},\n    task::Task,\n};\nuse serde::{Deserialize, Serialize};\nuse std::{path, sync::Arc};\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct TaskData {\n    pub domain: String,\n    pub value: u32,\n    pub finished: bool,\n}\n\n#[derive(Debug)]\npub struct DivisionComputation;\n\n#[derive(Debug)]\npub struct Context {\n    config: serde_yaml::Value,\n}\n\nimpl Configurable for Context {\n    fn config(\u0026self) -\u003e \u0026serde_yaml::Value {\n        \u0026self.config\n    }\n}\n\nimpl Context {\n    fn from_config(config_file_path: impl AsRef\u003cpath::Path\u003e) -\u003e Self {\n        let config = Self::load_config(config_file_path);\n        Self {\n            config: config.unwrap(),\n        }\n    }\n}\n\n#[async_trait]\nimpl Computation\u003cTaskData, Context\u003e for DivisionComputation {\n    /// TaskRunner will fail tasks which value can't be divided by 3\n    async fn call(\n        \u0026self,\n        worker_id: WorkerId,\n        _ctx: Arc\u003cContext\u003e,\n        _queue: AbstractTaskQueue\u003cTaskData\u003e,\n        task: \u0026mut Task\u003cTaskData\u003e,\n    ) -\u003e Result\u003c(), ComputationError\u003e {\n        tracing::info!(\n            \"[{}] Test division task: {:?}\",\n            worker_id,\n            task.get_payload()\n        );\n\n        let rem = task.payload.value % 3;\n        if rem != 0 {\n            let err_msg =\n                format!(\"[{}] Can't divide {} by 3\", worker_id, task.payload.value);\n            tokio::time::sleep(tokio::time::Duration::from_secs(rem as u64)).await;\n            return Err(ComputationError::Function(err_msg));\n        };\n\n        task.payload.finished = true;\n        tokio::time::sleep(tokio::time::Duration::from_secs(2)).await;\n        Ok(())\n    }\n}\n\n/// Make storage filled with test data.\n/// For current set following conditions should be true:\n/// total tasks = 9\n/// number of failed tasks = 4\nasync fn make_storage() -\u003e impl TaskQueue\u003cTaskData\u003e + Send + Sync {\n    let storage = InMemoryTaskQueue::new();\n\n    for i in 1..=5 {\n        let task: Task\u003cTaskData\u003e = Task::new(TaskData {\n            domain: \"one\".to_string(),\n            value: i,\n            finished: false,\n        });\n        let _ = storage.push(\u0026task).await;\n    }\n\n    for i in 1..=5 {\n        let task: Task\u003cTaskData\u003e = Task::new(TaskData {\n            domain: \"two\".to_string(),\n            value: i * 3,\n            finished: false,\n        });\n        let _ = storage.push(\u0026task).await;\n    }\n\n    for _ in 1..=10 {\n        let task: Task\u003cTaskData\u003e = Task::new(TaskData {\n            domain: \"three\".to_string(),\n            value: 2,\n            finished: false,\n        });\n        let _ = storage.push(\u0026task).await;\n    }\n    storage\n}\n\n#[tokio::main]\nasync fn main() {\n    tracing_subscriber::fmt::init();\n    let config_path = \"tests/simple_config.yml\";\n    let ctx = Context::from_config(config_path);\n    let storage = make_storage().await;\n\n    let computation = DivisionComputation {};\n    let manager_options = WorkersManagerOptionsBuilder::default()\n        .worker_options(\n            WorkerOptionsBuilder::default()\n                .task_limit(10)\n                .build()\n                .unwrap(),\n        )\n        .task_limit(30)\n        .concurrency_limit(4_usize)\n        .build()\n        .unwrap();\n\n    let mut manager =\n        WorkersManager::new(ctx, computation, storage, manager_options);\n    manager.run_workers().await;\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","examples","hackernews","main.rs"],"content":"//! Typical real world example of another one Hackernews crawler!\nuse async_trait::async_trait;\nuse base64::{engine::general_purpose::URL_SAFE, Engine as _};\nuse capp::prelude::{\n    Computation, ComputationError, InMemoryTaskQueue, Task, TaskQueue, WorkerId,\n    WorkerOptionsBuilder, WorkersManager, WorkersManagerOptionsBuilder,\n};\nuse capp::{config::Configurable, http, reqwest};\nuse capp::{tracing, tracing_subscriber};\nuse rand::{seq::SliceRandom, thread_rng};\nuse scraper::{Html, Selector};\nuse serde::{Deserialize, Serialize};\nuse std::io::Write;\nuse std::sync::LazyLock;\nuse std::{\n    collections::HashSet,\n    path,\n    sync::{Arc, Mutex},\n};\nuse url::{ParseError, Url};\n\nconst SEED_URLS: [\u0026str; 1] = [\"https://news.ycombinator.com\"];\n\nstatic URL_SET: LazyLock\u003cMutex\u003cHashSet\u003cString\u003e\u003e\u003e = LazyLock::new(|| {\n    let mut set = HashSet::new();\n    // Add some urls we do not want to add into queue\n    set.insert(\"https://news.ycombinator.com/submit\".into());\n    set.insert(\"https://news.ycombinator.com/jobs\".into());\n    set.insert(\"https://news.ycombinator.com/show\".into());\n    set.insert(\"https://news.ycombinator.com/ask\".into());\n    set.insert(\"https://news.ycombinator.com/newcomments\".into());\n    set.insert(\"https://news.ycombinator.com/front\".into());\n    set.insert(\"https://news.ycombinator.com/newest\".into());\n    Mutex::new(set)\n});\n\n#[derive(Debug)]\npub struct LinkExtractionResult {\n    pub links: Vec\u003cUrl\u003e,\n    pub errors: u32,\n}\n\npub struct CategorizedLinks {\n    general_links: Vec\u003cUrl\u003e,\n}\n\n/// Used to store crawling links\n#[derive(Debug, Clone, Serialize, Deserialize)]\nstruct SiteLink {\n    pub url: String,\n}\n\n#[derive(Debug)]\nstruct HNCrawler {}\n\nstruct Context {\n    config: serde_yaml::Value,\n    pub user_agents: Vec\u003cString\u003e,\n}\n\nimpl Configurable for Context {\n    fn config(\u0026self) -\u003e \u0026serde_yaml::Value {\n        \u0026self.config\n    }\n}\n\nimpl SiteLink {\n    fn new(url: \u0026str) -\u003e Self {\n        Self { url: url.into() }\n    }\n}\n\nimpl Context {\n    async fn from_config(config_file_path: impl AsRef\u003cpath::Path\u003e) -\u003e Self {\n        let config = Self::load_config(config_file_path)\n            .expect(\"Unable to read config file\");\n        let uas_file_path = config[\"app\"][\"user_agents_file\"].as_str().unwrap();\n        let user_agents = Self::load_text_file_lines(uas_file_path)\n            .expect(\"Unable to read user agents file\");\n        Self {\n            config,\n            user_agents,\n        }\n    }\n\n    // Get random user agent\n    pub fn get_random_ua(\u0026self) -\u003e String {\n        self.user_agents\n            .choose(\u0026mut thread_rng())\n            .unwrap()\n            .to_string()\n    }\n}\n\n#[async_trait]\nimpl Computation\u003cSiteLink, Context\u003e for HNCrawler {\n    /// Processor will fail tasks which value can be divided to 3\n    async fn call(\n        \u0026self,\n        worker_id: WorkerId,\n        ctx: Arc\u003cContext\u003e,\n        storage: Arc\u003cdyn TaskQueue\u003cSiteLink\u003e + Send + Sync + 'static\u003e,\n        task: \u0026mut Task\u003cSiteLink\u003e,\n    ) -\u003e Result\u003c(), ComputationError\u003e {\n        tracing::info!(\"[worker-{}] Processing task: {:?}\", worker_id, task);\n\n        let url = task.payload.url.clone();\n        tracing::info!(\"Fetching url: {:?}\", \u0026url);\n\n        let http_client = Self::get_http_client(\u0026ctx.clone());\n        let base_url = Self::extract_base_url(\u0026url).unwrap();\n\n        match Self::fetch_html(http_client, \u0026url).await {\n            Ok((reqwest::StatusCode::OK, text)) =\u003e {\n                tracing::info!(\"[{}] Profile data crawled.\", \u0026url);\n\n                let links = Self::extract_links(\u0026text, \u0026base_url);\n                tracing::info!(\n                    \"Links: {:?} Errors: {:?}\",\n                    links.links.len(),\n                    links.errors\n                );\n                let links = Self::filter_links(links.links);\n                tracing::info!(\"General: {}\", links.general_links.len());\n\n                let links_stored =\n                    Self::store_links_website(links.general_links, storage.clone())\n                        .await\n                        .unwrap();\n                tracing::info!(\"Links stored: {}\", links_stored);\n\n                // If we're on news page store it as file\n                if url.contains(\"item?id=\") {\n                    if let Err(e) =\n                        Self::save_page_to_file(\u0026url, \u0026text, \"target/tmp\")\n                    {\n                        tracing::error!(\"Failed to save page to file: {:?}\", e);\n                    } else {\n                        tracing::info!(\"Page saved successfully.\");\n                    };\n                }\n            }\n            Ok((code, _)) =\u003e {\n                tracing::error!(\"Wrong response code: {}\", code);\n                return Err(ComputationError::Function(\n                    \"Wrong response code\".into(),\n                ));\n            }\n            Err(err) =\u003e {\n                tracing::error!(\"Content fetching error: {}\", err);\n                return Err(ComputationError::Function(\n                    \"Content fetching error\".into(),\n                ));\n            }\n        };\n        Ok(())\n    }\n}\n\nimpl HNCrawler {\n    /// Fetch json content from response received by client\n    pub async fn fetch_html(\n        client: reqwest::Client,\n        url: \u0026str,\n    ) -\u003e reqwest::Result\u003c(reqwest::StatusCode, String)\u003e {\n        let backoff = backoff::ExponentialBackoffBuilder::new()\n            .with_randomization_factor(0.5)\n            .with_max_interval(std::time::Duration::from_secs(10))\n            .with_max_elapsed_time(Some(std::time::Duration::from_secs(30)))\n            .build();\n\n        let fetch_content = || async {\n            let response = client\n                .get(url)\n                .header(\"Accept\", \"text/html,*/*;q=0.8\")\n                .header(\"Accept-Language\", \"en-US,en;q=0.5\")\n                .header(\"Accept-Encoding\", \"gzip, deflate\")\n                .send()\n                .await?;\n            let status = response.status();\n            let text = response.text().await?;\n            Ok((status, text))\n        };\n\n        tracing::info!(\"[{}] retrieving url...\", url);\n        backoff::future::retry(backoff, fetch_content).await\n    }\n\n    // Store links to website for further crawling\n    async fn store_links_website(\n        links: Vec\u003cUrl\u003e,\n        storage: Arc\u003cdyn TaskQueue\u003cSiteLink\u003e + Send + Sync\u003e,\n    ) -\u003e Result\u003cusize, anyhow::Error\u003e {\n        let mut links_stored = 0;\n        tracing::info!(\"Adding {} links to the queue...\", links.len());\n\n        for link in links.iter() {\n            let link_str = link.as_str().to_owned();\n\n            let should_store = {\n                // Scoped lock acquisition\n                let mut url_set_guard = URL_SET.lock().unwrap();\n                url_set_guard.insert(link_str.clone())\n            };\n\n            if should_store {\n                let link_data = SiteLink { url: link_str };\n                storage.push(\u0026Task::new(link_data)).await?;\n                links_stored += 1;\n            }\n        }\n\n        Ok(links_stored)\n    }\n\n    // Extract links using: DOM Tree -\u003e CSS Selector -\u003e links\n    pub fn extract_links(content: \u0026str, base_url: \u0026Url) -\u003e LinkExtractionResult {\n        let document = Html::parse_document(content);\n        let selector = Selector::parse(\"a[href]\").unwrap();\n\n        let mut links = Vec::new();\n        let mut errors = 0;\n\n        for element in document.select(\u0026selector) {\n            if let Some(href) = element.value().attr(\"href\") {\n                let url = base_url.join(href);\n                match url {\n                    Ok(absolute_url) =\u003e links.push(absolute_url),\n                    Err(ParseError::RelativeUrlWithoutBase) =\u003e {\n                        // Attempt to parse it as an absolute URL if it\n                        // fails due to being a relative URL without a base.\n                        match Url::parse(href) {\n                            Ok(absolute_url) =\u003e links.push(absolute_url),\n                            Err(_) =\u003e errors += 1,\n                        }\n                    }\n                    Err(_) =\u003e errors += 1,\n                };\n            }\n        }\n\n        LinkExtractionResult { links, errors }\n    }\n\n    /// Filter links, left general links inside website and links to profiles\n    pub fn filter_links(links: Vec\u003cUrl\u003e) -\u003e CategorizedLinks {\n        let mut general_links = Vec::new();\n\n        for url in links {\n            match url.domain() {\n                Some(domain) if domain == \"news.ycombinator.com\" =\u003e {\n                    tracing::debug!(\"Url path: {}\", url.path());\n                    if url.path().contains(\"/user\")\n                        || url.path().contains(\"/vote\")\n                        || url.path().contains(\"/hide\")\n                    {\n                        continue;\n                    }\n\n                    general_links.push(url);\n                }\n                Some(domain) =\u003e {\n                    tracing::debug!(\"Skipping URL with domain: {}\", domain);\n                    continue;\n                }\n                None =\u003e {\n                    tracing::debug!(\"URL has no domain: {}\", url);\n                    continue;\n                }\n            };\n        }\n\n        CategorizedLinks { general_links }\n    }\n\n    pub fn get_http_client(ctx: \u0026Context) -\u003e reqwest::Client {\n        let proxy_provider = ctx.config()[\"app\"][\"proxy_provider\"]\n            .as_str()\n            .expect(\"Can't find app.proxy_provider settings\");\n        let client: reqwest::Client =\n            http::build_http_client(http::HttpClientParams::from_config(\n                \u0026ctx.config()[proxy_provider],\n                \u0026ctx.get_random_ua(),\n            ))\n            .unwrap();\n        client\n    }\n\n    // save page to file\n    fn save_page_to_file(\n        url: \u0026str,\n        text: \u0026str,\n        base_dir: \u0026str,\n    ) -\u003e Result\u003c(), anyhow::Error\u003e {\n        // Generate the MD5 hash of the URL\n        let md5_hash = md5::compute(url);\n        let hash_prefix = format!(\"{:x}\", \u0026md5_hash)[..4].to_string();\n\n        // Encode the URL to a valid filename using base64\n        let encoded_string = URL_SAFE.encode(url.as_bytes());\n\n        // Create the directory if it doesn't exist\n        let dir_path = std::path::Path::new(base_dir).join(\u0026hash_prefix);\n        std::fs::create_dir_all(\u0026dir_path)?;\n\n        // Construct the file path\n        // let encoded_filename = std::str::from_utf8(encoded_bytes)?.to_string();\n        let file_path = dir_path.join(format!(\"{}.html\", encoded_string));\n\n        // Open the file in write mode\n        let mut file = std::fs::File::create(file_path)?;\n\n        // Write the content to the file\n        file.write_all(text.as_bytes())?;\n\n        Ok(())\n    }\n\n    /// Try to extract base_url from url\n    fn extract_base_url(input_url: \u0026str) -\u003e Option\u003cUrl\u003e {\n        let parsed_url = Url::parse(input_url).ok()?;\n\n        let base_url = format!(\n            \"{}://{}{}\",\n            parsed_url.scheme(),\n            parsed_url.host_str()?, // Returns None if no host present\n            match parsed_url.port() {\n                Some(port) =\u003e format!(\":{}\", port), // Include the port if present\n                None =\u003e String::new(),\n            }\n        );\n\n        Url::parse(\u0026base_url).ok()\n    }\n}\n\n#[tokio::main]\nasync fn main() {\n    tracing_subscriber::fmt::init();\n    let ctx =\n        Arc::new(Context::from_config(\"examples/hackernews/hn_config.yml\").await);\n\n    tracing::info!(\"Starting HN crawler...\");\n\n    let manager_options = WorkersManagerOptionsBuilder::default()\n        .worker_options(\n            WorkerOptionsBuilder::default()\n                .max_retries(10_u32)\n                .build()\n                .unwrap(),\n        )\n        .concurrency_limit(4_usize)\n        .build()\n        .unwrap();\n\n    let storage: InMemoryTaskQueue\u003cSiteLink\u003e = InMemoryTaskQueue::new();\n    let tasks_queue_len = storage.list.lock().unwrap().len();\n\n    tracing::info!(\"Website links tasks in queue: {}\", tasks_queue_len);\n    // Add seed urls\n    if tasks_queue_len == 0 {\n        tracing::warn!(\"Queue is empty! Seeding urls... {}\", SEED_URLS.join(\" \"));\n        for url in SEED_URLS.iter() {\n            let initial_task = Task::new(SiteLink::new(url));\n            let _ = storage.push(\u0026initial_task).await;\n        }\n    }\n\n    let computation = Arc::new(HNCrawler {});\n    let mut manager = WorkersManager::new_from_arcs(\n        ctx.clone(),\n        computation,\n        Arc::new(storage),\n        manager_options,\n    );\n    manager.run_workers().await;\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","tests","common","http_server.rs"],"content":"use bytes::Bytes;\nuse http_body_util::Full;\nuse hyper::server::conn::http1;\nuse hyper::service::Service;\nuse hyper::{body::Incoming as IncomingBody, Request, Response};\nuse tokio::net::TcpListener;\n\nuse std::future::Future;\nuse std::net::SocketAddr;\nuse std::pin::Pin;\n\nmod support;\nuse support::TokioIo;\n\npub trait ServiceFactory {\n    type ServiceType: Service\u003c\n            Request\u003cIncomingBody\u003e,\n            Response = Response\u003cFull\u003cBytes\u003e\u003e,\n            Error = hyper::Error,\n        \u003e + Send\n        + 'static;\n\n    fn create_service(\u0026self) -\u003e Self::ServiceType;\n}\n\npub struct TestService;\npub struct TestServiceFactory;\n\nimpl ServiceFactory for TestServiceFactory {\n    type ServiceType = TestService;\n\n    fn create_service(\u0026self) -\u003e Self::ServiceType {\n        TestService::new()\n    }\n}\n\nimpl Service\u003cRequest\u003cIncomingBody\u003e\u003e for TestService {\n    type Response = Response\u003cFull\u003cBytes\u003e\u003e;\n    type Error = hyper::Error;\n    type Future =\n        Pin\u003cBox\u003cdyn Future\u003cOutput = Result\u003cSelf::Response, Self::Error\u003e\u003e + Send\u003e\u003e;\n\n    fn call(\u0026self, req: Request\u003cIncomingBody\u003e) -\u003e Self::Future {\n        fn ok_response(s: String) -\u003e Result\u003cResponse\u003cFull\u003cBytes\u003e\u003e, hyper::Error\u003e {\n            Ok(Response::builder().body(Full::new(Bytes::from(s))).unwrap())\n        }\n\n        fn fail_response(s: String) -\u003e Result\u003cResponse\u003cFull\u003cBytes\u003e\u003e, hyper::Error\u003e {\n            Ok(Response::builder()\n                .status(hyper::StatusCode::NOT_FOUND)\n                .body(Full::new(Bytes::from(s)))\n                .unwrap())\n        }\n\n        let res = match req.uri().path() {\n            \"/\" =\u003e ok_response(format!(\"here\")),\n            // Return the 404 Not Found for other routes.\n            _ =\u003e return Box::pin(async { fail_response(\"not found\".into()) }),\n        };\n\n        Box::pin(async { res })\n    }\n}\n\nimpl TestService {\n    fn new() -\u003e Self {\n        Self {}\n    }\n}\n\npub async fn run_service\u003cF\u003e(port: u16, service_factory: F) -\u003e anyhow::Result\u003c()\u003e\nwhere\n    F: ServiceFactory + Send + 'static,\n    \u003c\u003cF as ServiceFactory\u003e::ServiceType as Service\u003c\n        hyper::Request\u003chyper::body::Incoming\u003e,\n    \u003e\u003e::Future: Send,\n{\n    let addr: SocketAddr = ([127, 0, 0, 1], port).into();\n\n    let listener = TcpListener::bind(\u0026addr).await?;\n    println!(\"Listening on http://{}\", addr);\n\n    loop {\n        let (stream, _) = listener.accept().await?;\n        let io = TokioIo::new(stream);\n        let service = service_factory.create_service();\n        tokio::task::spawn(async move {\n            if let Err(err) =\n                http1::Builder::new().serve_connection(io, service).await\n            {\n                println!(\"Failed to serve connection: {:?}\", err);\n            }\n        });\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","tests","common","support.rs"],"content":"#![allow(dead_code)]\n//! Various runtimes for hyper\nuse std::{\n    future::Future,\n    pin::Pin,\n    task::{Context, Poll},\n    time::{Duration, Instant},\n};\n\nuse hyper::rt::{Sleep, Timer};\nuse pin_project_lite::pin_project;\n\n#[derive(Clone)]\n/// An Executor that uses the tokio runtime.\npub struct TokioExecutor;\n\nimpl\u003cF\u003e hyper::rt::Executor\u003cF\u003e for TokioExecutor\nwhere\n    F: std::future::Future + Send + 'static,\n    F::Output: Send + 'static,\n{\n    fn execute(\u0026self, fut: F) {\n        tokio::task::spawn(fut);\n    }\n}\n\n/// A Timer that uses the tokio runtime.\n\n#[derive(Clone, Debug)]\npub struct TokioTimer;\n\nimpl Timer for TokioTimer {\n    fn sleep(\u0026self, duration: Duration) -\u003e Pin\u003cBox\u003cdyn Sleep\u003e\u003e {\n        Box::pin(TokioSleep {\n            inner: tokio::time::sleep(duration),\n        })\n    }\n\n    fn sleep_until(\u0026self, deadline: Instant) -\u003e Pin\u003cBox\u003cdyn Sleep\u003e\u003e {\n        Box::pin(TokioSleep {\n            inner: tokio::time::sleep_until(deadline.into()),\n        })\n    }\n\n    fn reset(\u0026self, sleep: \u0026mut Pin\u003cBox\u003cdyn Sleep\u003e\u003e, new_deadline: Instant) {\n        if let Some(sleep) = sleep.as_mut().downcast_mut_pin::\u003cTokioSleep\u003e() {\n            sleep.reset(new_deadline.into())\n        }\n    }\n}\n\nstruct TokioTimeout\u003cT\u003e {\n    inner: Pin\u003cBox\u003ctokio::time::Timeout\u003cT\u003e\u003e\u003e,\n}\n\nimpl\u003cT\u003e Future for TokioTimeout\u003cT\u003e\nwhere\n    T: Future,\n{\n    type Output = Result\u003cT::Output, tokio::time::error::Elapsed\u003e;\n\n    fn poll(\n        mut self: Pin\u003c\u0026mut Self\u003e,\n        context: \u0026mut Context\u003c'_\u003e,\n    ) -\u003e Poll\u003cSelf::Output\u003e {\n        self.inner.as_mut().poll(context)\n    }\n}\n\n// Use TokioSleep to get tokio::time::Sleep to implement Unpin.\n// see https://docs.rs/tokio/latest/tokio/time/struct.Sleep.html\npin_project! {\n    pub(crate) struct TokioSleep {\n        #[pin]\n        pub(crate) inner: tokio::time::Sleep,\n    }\n}\n\nimpl Future for TokioSleep {\n    type Output = ();\n\n    fn poll(self: Pin\u003c\u0026mut Self\u003e, cx: \u0026mut Context\u003c'_\u003e) -\u003e Poll\u003cSelf::Output\u003e {\n        self.project().inner.poll(cx)\n    }\n}\n\nimpl Sleep for TokioSleep {}\n\nimpl TokioSleep {\n    pub fn reset(self: Pin\u003c\u0026mut Self\u003e, deadline: Instant) {\n        self.project().inner.as_mut().reset(deadline.into());\n    }\n}\n\npin_project! {\n    #[derive(Debug)]\n    pub struct TokioIo\u003cT\u003e {\n        #[pin]\n        inner: T,\n    }\n}\n\nimpl\u003cT\u003e TokioIo\u003cT\u003e {\n    pub fn new(inner: T) -\u003e Self {\n        Self { inner }\n    }\n\n    pub fn inner(self) -\u003e T {\n        self.inner\n    }\n}\n\nimpl\u003cT\u003e hyper::rt::Read for TokioIo\u003cT\u003e\nwhere\n    T: tokio::io::AsyncRead,\n{\n    fn poll_read(\n        self: Pin\u003c\u0026mut Self\u003e,\n        cx: \u0026mut Context\u003c'_\u003e,\n        mut buf: hyper::rt::ReadBufCursor\u003c'_\u003e,\n    ) -\u003e Poll\u003cResult\u003c(), std::io::Error\u003e\u003e {\n        let n = unsafe {\n            let mut tbuf = tokio::io::ReadBuf::uninit(buf.as_mut());\n            match tokio::io::AsyncRead::poll_read(\n                self.project().inner,\n                cx,\n                \u0026mut tbuf,\n            ) {\n                Poll::Ready(Ok(())) =\u003e tbuf.filled().len(),\n                other =\u003e return other,\n            }\n        };\n\n        unsafe {\n            buf.advance(n);\n        }\n        Poll::Ready(Ok(()))\n    }\n}\n\nimpl\u003cT\u003e hyper::rt::Write for TokioIo\u003cT\u003e\nwhere\n    T: tokio::io::AsyncWrite,\n{\n    fn poll_write(\n        self: Pin\u003c\u0026mut Self\u003e,\n        cx: \u0026mut Context\u003c'_\u003e,\n        buf: \u0026[u8],\n    ) -\u003e Poll\u003cResult\u003cusize, std::io::Error\u003e\u003e {\n        tokio::io::AsyncWrite::poll_write(self.project().inner, cx, buf)\n    }\n\n    fn poll_flush(\n        self: Pin\u003c\u0026mut Self\u003e,\n        cx: \u0026mut Context\u003c'_\u003e,\n    ) -\u003e Poll\u003cResult\u003c(), std::io::Error\u003e\u003e {\n        tokio::io::AsyncWrite::poll_flush(self.project().inner, cx)\n    }\n\n    fn poll_shutdown(\n        self: Pin\u003c\u0026mut Self\u003e,\n        cx: \u0026mut Context\u003c'_\u003e,\n    ) -\u003e Poll\u003cResult\u003c(), std::io::Error\u003e\u003e {\n        tokio::io::AsyncWrite::poll_shutdown(self.project().inner, cx)\n    }\n\n    fn is_write_vectored(\u0026self) -\u003e bool {\n        tokio::io::AsyncWrite::is_write_vectored(\u0026self.inner)\n    }\n\n    fn poll_write_vectored(\n        self: Pin\u003c\u0026mut Self\u003e,\n        cx: \u0026mut Context\u003c'_\u003e,\n        bufs: \u0026[std::io::IoSlice\u003c'_\u003e],\n    ) -\u003e Poll\u003cResult\u003cusize, std::io::Error\u003e\u003e {\n        tokio::io::AsyncWrite::poll_write_vectored(self.project().inner, cx, bufs)\n    }\n}\n\nimpl\u003cT\u003e tokio::io::AsyncRead for TokioIo\u003cT\u003e\nwhere\n    T: hyper::rt::Read,\n{\n    fn poll_read(\n        self: Pin\u003c\u0026mut Self\u003e,\n        cx: \u0026mut Context\u003c'_\u003e,\n        tbuf: \u0026mut tokio::io::ReadBuf\u003c'_\u003e,\n    ) -\u003e Poll\u003cResult\u003c(), std::io::Error\u003e\u003e {\n        //let init = tbuf.initialized().len();\n        let filled = tbuf.filled().len();\n        let sub_filled = unsafe {\n            let mut buf = hyper::rt::ReadBuf::uninit(tbuf.unfilled_mut());\n\n            match hyper::rt::Read::poll_read(\n                self.project().inner,\n                cx,\n                buf.unfilled(),\n            ) {\n                Poll::Ready(Ok(())) =\u003e buf.filled().len(),\n                other =\u003e return other,\n            }\n        };\n\n        let n_filled = filled + sub_filled;\n        // At least sub_filled bytes had to have been initialized.\n        let n_init = sub_filled;\n        unsafe {\n            tbuf.assume_init(n_init);\n            tbuf.set_filled(n_filled);\n        }\n\n        Poll::Ready(Ok(()))\n    }\n}\n\nimpl\u003cT\u003e tokio::io::AsyncWrite for TokioIo\u003cT\u003e\nwhere\n    T: hyper::rt::Write,\n{\n    fn poll_write(\n        self: Pin\u003c\u0026mut Self\u003e,\n        cx: \u0026mut Context\u003c'_\u003e,\n        buf: \u0026[u8],\n    ) -\u003e Poll\u003cResult\u003cusize, std::io::Error\u003e\u003e {\n        hyper::rt::Write::poll_write(self.project().inner, cx, buf)\n    }\n\n    fn poll_flush(\n        self: Pin\u003c\u0026mut Self\u003e,\n        cx: \u0026mut Context\u003c'_\u003e,\n    ) -\u003e Poll\u003cResult\u003c(), std::io::Error\u003e\u003e {\n        hyper::rt::Write::poll_flush(self.project().inner, cx)\n    }\n\n    fn poll_shutdown(\n        self: Pin\u003c\u0026mut Self\u003e,\n        cx: \u0026mut Context\u003c'_\u003e,\n    ) -\u003e Poll\u003cResult\u003c(), std::io::Error\u003e\u003e {\n        hyper::rt::Write::poll_shutdown(self.project().inner, cx)\n    }\n\n    fn is_write_vectored(\u0026self) -\u003e bool {\n        hyper::rt::Write::is_write_vectored(\u0026self.inner)\n    }\n\n    fn poll_write_vectored(\n        self: Pin\u003c\u0026mut Self\u003e,\n        cx: \u0026mut Context\u003c'_\u003e,\n        bufs: \u0026[std::io::IoSlice\u003c'_\u003e],\n    ) -\u003e Poll\u003cResult\u003cusize, std::io::Error\u003e\u003e {\n        hyper::rt::Write::poll_write_vectored(self.project().inner, cx, bufs)\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","tests","common.rs"],"content":"#[path = \"common/http_server.rs\"]\npub mod http_server;\n\n#[path = \"common/support.rs\"]\npub mod support;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","tests","healthcheck_tests.rs"],"content":"mod common;\n\n#[cfg(test)]\nmod tests {\n    use crate::common::http_server::{run_service, TestServiceFactory};\n    use capp::healthcheck::internet;\n\n    #[test]\n    fn ping_healthcheck_service() {\n        let rt = tokio::runtime::Runtime::new().unwrap();\n        let _server_handle = rt.spawn(run_service(3000, TestServiceFactory));\n\n        // Wait for the test server to start\n        std::thread::sleep(std::time::Duration::from_millis(100));\n\n        let rt = tokio::runtime::Runtime::new().unwrap();\n        let result =\n            rt.block_on(async { internet(\"http://127.0.0.1:3000/fail\").await });\n\n        assert_eq!(result, true);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","tests","http_tests.rs"],"content":"mod common;\n\n#[cfg(test)]\nmod tests {\n    use crate::common::http_server::{run_service, TestServiceFactory};\n    use capp::http::{\n        build_http_client, fetch_url, fetch_url_content, HttpClientParams,\n    };\n\n    // pub async fn start_test_server(addr: SocketAddr) {\n    //     let make_svc = make_service_fn(|_conn| async {\n    //         Ok::\u003c_, hyper::Error\u003e(service_fn(handle_request))\n    //     });\n\n    //     let server = Server::bind(\u0026addr).serve(make_svc);\n    //     println!(\"Test server running on http://{}\", addr);\n\n    //     if let Err(e) = server.await {\n    //         eprintln!(\"Server error: {}\", e);\n    //     }\n    // }\n\n    // async fn handle_request(\n    //     _req: Request\u003cBody\u003e,\n    // ) -\u003e Result\u003cResponse\u003cBody\u003e, hyper::Error\u003e {\n    //     let response = Response::builder()\n    //         .status(200)\n    //         .body(Body::from(\"Hello, World!\"))\n    //         .unwrap();\n    //     Ok(response)\n    // }\n\n    #[test]\n    fn test_http_request() {\n        let rt = tokio::runtime::Runtime::new().unwrap();\n        let _server_handle = rt.spawn(run_service(3000, TestServiceFactory));\n\n        // Wait for the test server to start\n        std::thread::sleep(std::time::Duration::from_millis(100));\n\n        let params = HttpClientParams {\n            proxy_provider: None,\n            timeout: 5,\n            connect_timeout: 2,\n            user_agent: \"test-client\",\n        };\n\n        let client = build_http_client(params).expect(\"Failed to build client\");\n\n        let rt = tokio::runtime::Runtime::new().unwrap();\n        let resp = rt.block_on(async {\n            fetch_url(client.clone(), \"http://127.0.0.1:3000\")\n                .await\n                .ok()\n                .unwrap()\n        });\n\n        assert_eq!(resp.status(), 200);\n\n        let rt = tokio::runtime::Runtime::new().unwrap();\n        let resp = rt.block_on(async {\n            fetch_url_content(client, \"http://127.0.0.1:3000/fail\")\n                .await\n                .ok()\n                .unwrap()\n        });\n\n        assert_eq!(\n            (reqwest::StatusCode::NOT_FOUND, \"not found\".to_string()),\n            resp\n        );\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","tests","manager_tests.rs"],"content":"#[cfg(test)]\nmod tests {\n    use async_trait::async_trait;\n    use capp::config::Configurable;\n    use capp::manager::{\n        Computation, ComputationError, WorkerId, WorkerOptionsBuilder,\n        WorkersManager, WorkersManagerOptionsBuilder,\n    };\n    use capp::queue::{AbstractTaskQueue, InMemoryTaskQueue, TaskQueue};\n    use capp::task::Task;\n    use serde::{Deserialize, Serialize};\n    use std::sync::Arc;\n    use tokio::runtime::Runtime;\n\n    #[derive(Debug, Clone, Serialize, Deserialize)]\n    pub struct TestData {\n        pub domain: String,\n        pub value: u32,\n        pub finished: bool,\n    }\n\n    #[derive(Debug)]\n    pub struct TestComputation {}\n\n    #[derive(Debug, Serialize, Deserialize)]\n    pub struct Context {\n        name: String,\n        config: serde_yaml::Value,\n        is_test: bool,\n    }\n\n    impl Configurable for Context {\n        fn config(\u0026self) -\u003e \u0026serde_yaml::Value {\n            \u0026self.config\n        }\n    }\n\n    impl Context {\n        fn from_config(config_file_path: impl AsRef\u003cstd::path::Path\u003e) -\u003e Self {\n            let config = Self::load_config(config_file_path);\n            Self {\n                name: \"test-app\".to_string(),\n                is_test: true,\n                config: config.unwrap(),\n            }\n        }\n    }\n\n    #[async_trait]\n    impl Computation\u003cTestData, Context\u003e for TestComputation {\n        /// Process will fail tasks which value can be divided to 3\n        async fn call(\n            \u0026self,\n            worker_id: WorkerId,\n            _ctx: Arc\u003cContext\u003e,\n            _storage: AbstractTaskQueue\u003cTestData\u003e,\n            task: \u0026mut Task\u003cTestData\u003e,\n        ) -\u003e Result\u003c(), ComputationError\u003e {\n            tracing::info!(\"[worker-{}] Processing task: {:?}\", worker_id, task);\n            let rem = task.payload.value % 3;\n            // fail if can be divided by 3\n            if rem == 0 {\n                return Err(ComputationError::Function(format!(\n                    \"Can be divide {} to 3\",\n                    \u0026task.payload.value\n                )));\n            };\n\n            task.payload.finished = true;\n            Ok(())\n        }\n    }\n\n    /// Make storage filled with test data.\n    /// For current set following conditions should be true:\n    /// total tasks = 9\n    /// number of failed tasks = 4\n    fn make_storage() -\u003e InMemoryTaskQueue\u003cTestData\u003e {\n        let storage = InMemoryTaskQueue::new();\n\n        let rt = Runtime::new().unwrap();\n\n        // Only 1 number can be divided by 3\n        for i in 1..=3 {\n            let task: Task\u003cTestData\u003e = Task::new(TestData {\n                domain: \"one\".to_string(),\n                value: i,\n                finished: false,\n            });\n            let _ = rt.block_on(storage.push(\u0026task));\n        }\n\n        // all 3 numbers can be divided by 3\n        for i in 1..=3 {\n            let task: Task\u003cTestData\u003e = Task::new(TestData {\n                domain: \"two\".to_string(),\n                value: i * 3,\n                finished: false,\n            });\n            let _ = rt.block_on(storage.push(\u0026task));\n        }\n\n        // No numbers can be divided by 3\n        for _ in 1..=3 {\n            let task: Task\u003cTestData\u003e = Task::new(TestData {\n                domain: \"three\".to_string(),\n                value: 2,\n                finished: false,\n            });\n            let _ = rt.block_on(storage.push(\u0026task));\n        }\n        storage\n    }\n\n    #[test]\n    fn test_storage() {\n        let storage = make_storage();\n        assert_eq!(storage.list.lock().unwrap().len(), 9);\n    }\n\n    #[test]\n    fn test_manager() {\n        let rt = Runtime::new().unwrap();\n\n        let ctx = Arc::new(Context::from_config(\"tests/simple_config.yml\"));\n        let storage = Arc::new(make_storage());\n\n        let storage_len_before = storage.list.lock().unwrap().len();\n        assert_eq!(storage_len_before, 9);\n\n        let computation = Arc::new(TestComputation {});\n        let manager_options = WorkersManagerOptionsBuilder::default()\n            .worker_options(\n                WorkerOptionsBuilder::default()\n                    .max_retries(10_u32)\n                    .task_limit(3)\n                    .no_task_found_delay(std::time::Duration::from_millis(50))\n                    .build()\n                    .unwrap(),\n            )\n            .concurrency_limit(1 as usize)\n            .task_limit(Some(9))\n            .build()\n            .unwrap();\n\n        let mut manager = WorkersManager::new_from_arcs(\n            ctx,\n            computation,\n            storage.clone(),\n            manager_options,\n        );\n        rt.block_on(manager.run_workers());\n\n        let storage_len_after = storage.list.lock().unwrap().len();\n\n        // 4 tasks should fail\n        assert_eq!(storage_len_after, 7);\n        // all successful tasks should be removed from storage\n        // 7 should left\n        let keys_len = storage.hashmap.lock().unwrap().len();\n        assert_eq!(keys_len, 7);\n\n        // dbg!(\u0026storage);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","tests","redis_rr_tests.rs"],"content":"#[cfg(test)]\nmod tests {\n    use capp::queue::{\n        HasTagKey, RedisRoundRobinTaskQueue, TaskQueue, TaskQueueError,\n    };\n    use capp::task::Task;\n    use dotenvy::dotenv;\n    use rustis::client::Client;\n    use rustis::commands::{GenericCommands, HashCommands, ListCommands};\n    use serde::{Deserialize, Serialize};\n    use std::collections::HashSet;\n    use tokio;\n\n    #[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n    struct TestData {\n        value: u32,\n        tag: String,\n    }\n\n    impl HasTagKey for TestData {\n        type TagValue = String;\n        fn get_tag_value(\u0026self) -\u003e Self::TagValue {\n            self.tag.clone()\n        }\n    }\n\n    async fn get_redis_connection() -\u003e Client {\n        dotenv().ok();\n        let uri = std::env::var(\"REDIS_URI\").expect(\"Set REDIS_URI env variable\");\n        Client::connect(uri)\n            .await\n            .expect(\"Error while establishing redis connection\")\n    }\n\n    async fn setup_queue(test_name: \u0026str) -\u003e RedisRoundRobinTaskQueue\u003cTestData\u003e {\n        let redis = get_redis_connection().await;\n        let tags = HashSet::from([\n            \"tag1\".to_string(),\n            \"tag2\".to_string(),\n            \"tag3\".to_string(),\n        ]);\n        let unique_name = format!(\"capp-test-redis-rr-{}\", test_name);\n        RedisRoundRobinTaskQueue::new(redis, \u0026unique_name, tags)\n            .await\n            .expect(\"Failed to create RedisRoundRobinTaskQueue\")\n    }\n\n    async fn cleanup_queue(queue: \u0026RedisRoundRobinTaskQueue\u003cTestData\u003e) {\n        let mut keys_to_delete = vec![\n            queue.get_hashmap_key(),\n            queue.get_list_key(\"tag1\"),\n            queue.get_list_key(\"tag2\"),\n            queue.get_list_key(\"tag3\"),\n            queue.get_dlq_key(),\n        ];\n        // Add counter keys to the list of keys to delete\n        keys_to_delete.extend(queue.get_counter_keys());\n        queue\n            .client\n            .del(keys_to_delete)\n            .await\n            .expect(\"Failed to clean up Redis keys\");\n    }\n\n    #[tokio::test]\n    async fn test_typical_workflow() {\n        let queue = setup_queue(\"workflow\").await;\n        cleanup_queue(\u0026queue).await;\n\n        // Push tasks with different tags\n        let task1 = Task::new(TestData {\n            value: 1,\n            tag: \"tag1\".to_string(),\n        });\n        let task2 = Task::new(TestData {\n            value: 2,\n            tag: \"tag2\".to_string(),\n        });\n        let task3 = Task::new(TestData {\n            value: 3,\n            tag: \"tag3\".to_string(),\n        });\n\n        queue.push(\u0026task1).await.expect(\"Failed to push task1\");\n        queue.push(\u0026task2).await.expect(\"Failed to push task2\");\n        queue.push(\u0026task3).await.expect(\"Failed to push task3\");\n\n        // Pop tasks and check round-robin order\n        let popped_task1 = queue.pop().await.expect(\"Failed to pop task1\");\n        let popped_task2 = queue.pop().await.expect(\"Failed to pop task2\");\n        let popped_task3 = queue.pop().await.expect(\"Failed to pop task3\");\n\n        // Check that all tags are represented\n        let popped_tags: HashSet\u003cString\u003e = vec![\n            popped_task1.payload.tag.clone(),\n            popped_task2.payload.tag.clone(),\n            popped_task3.payload.tag.clone(),\n        ]\n        .into_iter()\n        .collect();\n\n        assert_eq!(\n            popped_tags,\n            HashSet::from([\n                \"tag1\".to_string(),\n                \"tag2\".to_string(),\n                \"tag3\".to_string()\n            ]),\n            \"All tags should be represented in the popped tasks\"\n        );\n\n        // Ack one task, nack another, and check queue state\n        queue\n            .ack(\u0026popped_task1.task_id)\n            .await\n            .expect(\"Failed to ack task1\");\n        queue\n            .nack(\u0026popped_task2)\n            .await\n            .expect(\"Failed to nack task2\");\n\n        let hashmap_len = queue\n            .client\n            .hlen(\u0026queue.get_hashmap_key())\n            .await\n            .expect(\"Failed to get hashmap length\");\n        assert_eq!(hashmap_len, 1, \"Only one task should remain in the hashmap\");\n\n        let dlq_len = queue\n            .client\n            .llen(\u0026queue.get_dlq_key())\n            .await\n            .expect(\"Failed to get DLQ length\");\n        assert_eq!(dlq_len, 1, \"One task should be in the DLQ\");\n\n        cleanup_queue(\u0026queue).await;\n    }\n\n    #[tokio::test]\n    async fn test_push_and_pop() {\n        let queue = setup_queue(\"push-pop\").await;\n        cleanup_queue(\u0026queue).await;\n        let task = Task::new(TestData {\n            value: 42,\n            tag: \"tag1\".to_string(),\n        });\n\n        queue.push(\u0026task).await.expect(\"Failed to push task\");\n\n        let popped_task = queue.pop().await.expect(\"Failed to pop task\");\n        assert_eq!(popped_task.payload, task.payload);\n\n        cleanup_queue(\u0026queue).await;\n    }\n\n    #[tokio::test]\n    async fn test_empty_queue() {\n        let queue = setup_queue(\"empty-queue\").await;\n        cleanup_queue(\u0026queue).await;\n\n        let task_1 = Task::new(TestData {\n            value: 1,\n            tag: \"tag1\".to_string(),\n        });\n\n        let task_2 = Task::new(TestData {\n            value: 2,\n            tag: \"tag2\".to_string(),\n        });\n\n        let task_3 = Task::new(TestData {\n            value: 3,\n            tag: \"tag2\".to_string(),\n        });\n\n        queue.push(\u0026task_1).await.expect(\"Failed to push task\");\n        queue.push(\u0026task_2).await.expect(\"Failed to push task\");\n        queue.push(\u0026task_3).await.expect(\"Failed to push task\");\n\n        queue.pop().await.expect(\"Failed to pop task\");\n        queue.pop().await.expect(\"Failed to pop task\");\n        queue.pop().await.expect(\"Failed to pop task\");\n\n        let should_be_error = queue.pop().await;\n        assert!(should_be_error.is_err());\n\n        cleanup_queue(\u0026queue).await;\n    }\n\n    #[tokio::test]\n    async fn test_round_robin_behavior() {\n        let queue = setup_queue(\"round-robin\").await;\n        cleanup_queue(\u0026queue).await;\n\n        let tasks = vec![\n            Task::new(TestData {\n                value: 1,\n                tag: \"tag1\".to_string(),\n            }),\n            Task::new(TestData {\n                value: 2,\n                tag: \"tag2\".to_string(),\n            }),\n            Task::new(TestData {\n                value: 3,\n                tag: \"tag3\".to_string(),\n            }),\n            Task::new(TestData {\n                value: 4,\n                tag: \"tag1\".to_string(),\n            }),\n            Task::new(TestData {\n                value: 5,\n                tag: \"tag2\".to_string(),\n            }),\n            Task::new(TestData {\n                value: 6,\n                tag: \"tag3\".to_string(),\n            }),\n        ];\n\n        for task in \u0026tasks {\n            queue.push(task).await.expect(\"Failed to push task\");\n        }\n\n        let mut popped_values = Vec::new();\n        for _ in 0..6 {\n            let popped_task = queue.pop().await.expect(\"Failed to pop task\");\n            popped_values.push(popped_task.payload.value);\n        }\n\n        assert_eq!(popped_values.len(), 6, \"Should have popped 6 tasks\");\n        assert!(\n            popped_values.contains(\u00261) \u0026\u0026 popped_values.contains(\u00264),\n            \"Should contain both tag1 tasks\"\n        );\n        assert!(\n            popped_values.contains(\u00262) \u0026\u0026 popped_values.contains(\u00265),\n            \"Should contain both tag2 tasks\"\n        );\n        assert!(\n            popped_values.contains(\u00263) \u0026\u0026 popped_values.contains(\u00266),\n            \"Should contain both tag3 tasks\"\n        );\n\n        // Attempt to pop again, should be empty\n        match queue.pop().await {\n            Err(TaskQueueError::QueueEmpty) =\u003e (),\n            _ =\u003e panic!(\"Queue not empty!\"),\n        }\n        cleanup_queue(\u0026queue).await;\n    }\n\n    #[tokio::test]\n    async fn test_ack() {\n        let queue = setup_queue(\"ack\").await;\n        cleanup_queue(\u0026queue).await;\n        let task = Task::new(TestData {\n            value: 42,\n            tag: \"tag1\".to_string(),\n        });\n\n        queue.push(\u0026task).await.expect(\"Failed to push task\");\n        let popped_task = queue.pop().await.expect(\"Failed to pop task\");\n        queue\n            .ack(\u0026popped_task.task_id)\n            .await\n            .expect(\"Failed to ack task\");\n\n        let task_exists: bool = queue\n            .client\n            .hexists(\u0026queue.get_hashmap_key(), popped_task.task_id.to_string())\n            .await\n            .expect(\"Failed to check task existence\");\n        assert!(!task_exists, \"Task should have been removed after ack\");\n\n        cleanup_queue(\u0026queue).await;\n    }\n\n    #[tokio::test]\n    async fn test_nack() {\n        let queue = setup_queue(\"nack\").await;\n        let task = Task::new(TestData {\n            value: 42,\n            tag: \"tag1\".to_string(),\n        });\n\n        queue.push(\u0026task).await.expect(\"Failed to push task\");\n        let popped_task = queue.pop().await.expect(\"Failed to pop task\");\n        queue.nack(\u0026popped_task).await.expect(\"Failed to nack task\");\n\n        let task_exists: bool = queue\n            .client\n            .hexists(\u0026queue.get_hashmap_key(), popped_task.task_id.to_string())\n            .await\n            .expect(\"Failed to check task existence\");\n        assert!(\n            !task_exists,\n            \"Task should have been removed from hashmap after nack\"\n        );\n\n        let dlq_len = queue\n            .client\n            .llen(\u0026queue.get_dlq_key())\n            .await\n            .expect(\"Failed to read DLQ\");\n        assert_eq!(dlq_len, 1, \"Task should have been added to DLQ\");\n\n        cleanup_queue(\u0026queue).await;\n    }\n\n    #[tokio::test]\n    async fn test_set() {\n        let queue = setup_queue(\"set\").await;\n        let mut task = Task::new(TestData {\n            value: 42,\n            tag: \"tag1\".to_string(),\n        });\n\n        queue.push(\u0026task).await.expect(\"Failed to push task\");\n        task.payload.value = 43;\n        queue.set(\u0026task).await.expect(\"Failed to set task\");\n\n        let updated_task_json: String = queue\n            .client\n            .hget(\u0026queue.get_hashmap_key(), task.task_id.to_string())\n            .await\n            .expect(\"Failed to get updated task\");\n        let updated_task: Task\u003cTestData\u003e = serde_json::from_str(\u0026updated_task_json)\n            .expect(\"Failed to deserialize updated task\");\n\n        assert_eq!(updated_task.payload.value, 43);\n\n        cleanup_queue(\u0026queue).await;\n    }\n\n    #[tokio::test]\n    async fn test_queue_empty() {\n        let queue = setup_queue(\"empty\").await;\n        cleanup_queue(\u0026queue).await;\n\n        match queue.pop().await {\n            Err(TaskQueueError::QueueEmpty) =\u003e (),\n            _ =\u003e panic!(\"Expected QueueEmpty error\"),\n        }\n    }\n\n    #[tokio::test]\n    async fn test_purge() {\n        let queue = setup_queue(\"purge-test\").await;\n\n        // Push some tasks\n        let tasks = vec![\n            Task::new(TestData {\n                value: 1,\n                tag: \"tag1\".to_string(),\n            }),\n            Task::new(TestData {\n                value: 2,\n                tag: \"tag2\".to_string(),\n            }),\n            Task::new(TestData {\n                value: 3,\n                tag: \"tag3\".to_string(),\n            }),\n        ];\n\n        for task in \u0026tasks {\n            queue.push(task).await.expect(\"Failed to push task\");\n        }\n\n        // Verify that tasks are in the queue\n        for _ in 0..3 {\n            assert!(queue.pop().await.is_ok(), \"Should be able to pop a task\");\n        }\n\n        // Purge the queue\n        queue.purge().await.expect(\"Failed to purge queue\");\n\n        // Verify that all queues are empty\n        assert!(\n            matches!(queue.pop().await, Err(TaskQueueError::QueueEmpty)),\n            \"Queue should be empty after purge\"\n        );\n\n        // Verify that all keys have been deleted\n        let mut keys_to_check = vec![\n            queue.get_hashmap_key(),\n            queue.get_list_key(\"tag1\"),\n            queue.get_list_key(\"tag2\"),\n            queue.get_list_key(\"tag3\"),\n            queue.get_dlq_key(),\n        ];\n        keys_to_check.extend(queue.get_counter_keys());\n\n        for key in keys_to_check {\n            let exists: usize = queue\n                .client\n                .exists(\u0026key)\n                .await\n                .expect(\"Failed to check key existence\");\n            assert!(exists == 0, \"Key {} should not exist after purge\", key);\n        }\n\n        // Clean up any remaining keys (though there shouldn't be any)\n        cleanup_queue(\u0026queue).await;\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","tests","redis_tests.rs"],"content":"#[cfg(test)]\nmod tests {\n    use capp::queue::{RedisTaskQueue, TaskQueue, TaskQueueError};\n    use capp::task::Task;\n    use dotenvy::dotenv;\n    use rustis::client::Client;\n    use rustis::commands::{GenericCommands, HashCommands, ListCommands};\n    use serde::{Deserialize, Serialize};\n    use tokio;\n\n    #[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n    struct TestData {\n        value: u32,\n    }\n\n    async fn get_redis_connection() -\u003e Client {\n        dotenv().ok();\n        let uri = std::env::var(\"REDIS_URI\").expect(\"Set REDIS_URI env variable\");\n        Client::connect(uri)\n            .await\n            .expect(\"Error while establishing redis connection\")\n    }\n\n    async fn setup_queue(name: \u0026str) -\u003e RedisTaskQueue\u003cTestData\u003e {\n        let redis = get_redis_connection().await;\n        RedisTaskQueue::new(redis, name)\n            .await\n            .expect(\"Failed to create RedisTaskQueue\")\n    }\n\n    async fn cleanup_queue(queue: \u0026RedisTaskQueue\u003cTestData\u003e) {\n        queue\n            .client\n            .del([\u0026queue.list_key, \u0026queue.hashmap_key, \u0026queue.dlq_key])\n            .await\n            .expect(\"Failed to clean up Redis keys\");\n    }\n\n    #[tokio::test]\n    async fn test_typical_workflow() {\n        let redis = get_redis_connection().await;\n        let queue: RedisTaskQueue\u003cTestData\u003e =\n            RedisTaskQueue::new(redis, \"capp-test-workflow\")\n                .await\n                .expect(\"Failed to create RedisTaskQueue\");\n        // clean queue\n        queue\n            .client\n            .del([\u0026queue.list_key, \u0026queue.hashmap_key, \u0026queue.dlq_key])\n            .await\n            .expect(\"Failed to clean up Redis keys\");\n\n        // check push\n        let task = Task::new(TestData { value: 42 });\n        let result = queue.push(\u0026task).await;\n        assert!(result.is_ok());\n\n        // check pop\n        let task_from_queue = queue.pop().await;\n        assert!(!\u0026task_from_queue.is_err());\n        let task_from_queue = task_from_queue.unwrap();\n        assert!(task_from_queue.get_payload().value == 42);\n\n        // ack task and check queue is empty\n        let acked = queue.ack(\u0026task_from_queue.task_id).await;\n        assert!(acked.is_ok());\n        let queue_list_len = queue.client.llen(\u0026queue.list_key).await;\n        assert_eq!(queue_list_len.unwrap(), 0);\n        let queue_hashmap_len = queue.client.hlen(\u0026queue.hashmap_key).await;\n        assert_eq!(queue_hashmap_len.unwrap(), 0);\n\n        // check how ack/nack working and check ordering\n        let task_1 = Task::new(TestData { value: 1 });\n        let task_2 = Task::new(TestData { value: 2 });\n        let _ = queue.push(\u0026task_1).await;\n        let _ = queue.push(\u0026task_2).await;\n        let queue_list_len = queue.client.llen(\u0026queue.list_key).await;\n        assert_eq!(queue_list_len.unwrap(), 2);\n        let queue_hashmap_len = queue.client.hlen(\u0026queue.hashmap_key).await;\n        assert_eq!(queue_hashmap_len.unwrap(), 2);\n\n        let task_1_from_queue = queue.pop().await.unwrap();\n        assert_eq!(task_1_from_queue.payload.value, 1);\n        let acked = queue.ack(\u0026task_1_from_queue.task_id).await;\n        assert!(acked.is_ok());\n\n        let task_2_from_queue = queue.pop().await.unwrap();\n        assert_eq!(task_2_from_queue.payload.value, 2);\n        let nacked = queue.nack(\u0026task_2_from_queue).await;\n        assert!(nacked.is_ok());\n        let dlq_len = queue.client.llen(\u0026queue.dlq_key).await.unwrap();\n        assert_eq!(dlq_len, 1);\n\n        queue\n            .client\n            .del([\u0026queue.list_key, \u0026queue.hashmap_key, \u0026queue.dlq_key])\n            .await\n            .expect(\"Failed to clean up Redis keys\");\n    }\n\n    #[tokio::test]\n    async fn test_push_and_pop() {\n        let queue = setup_queue(\"capp-test-push-pop\").await;\n        let task = Task::new(TestData { value: 42 });\n\n        queue.push(\u0026task).await.expect(\"Failed to push task\");\n\n        let popped_task = queue.pop().await.expect(\"Failed to pop task\");\n        assert_eq!(popped_task.payload, task.payload);\n\n        cleanup_queue(\u0026queue).await;\n    }\n\n    #[tokio::test]\n    async fn test_push_multiple_and_pop_order() {\n        let queue = setup_queue(\"capp-test-push-pop-order\").await;\n        let tasks = vec![\n            Task::new(TestData { value: 1 }),\n            Task::new(TestData { value: 2 }),\n            Task::new(TestData { value: 3 }),\n        ];\n\n        for task in \u0026tasks {\n            queue.push(task).await.expect(\"Failed to push task\");\n        }\n\n        for expected_value in 1..=3 {\n            let popped_task = queue.pop().await.expect(\"Failed to pop task\");\n            assert_eq!(popped_task.payload.value, expected_value);\n        }\n\n        assert!(matches!(queue.pop().await, Err(TaskQueueError::QueueEmpty)));\n\n        cleanup_queue(\u0026queue).await;\n    }\n\n    #[tokio::test]\n    async fn test_ack() {\n        let queue = setup_queue(\"capp-test-ack\").await;\n        let task = Task::new(TestData { value: 42 });\n\n        queue.push(\u0026task).await.expect(\"Failed to push task\");\n        let popped_task = queue.pop().await.expect(\"Failed to pop task\");\n        dbg!(\u0026popped_task);\n        queue\n            .ack(\u0026popped_task.task_id)\n            .await\n            .expect(\"Failed to ack task\");\n\n        let task_exists: bool = queue\n            .client\n            .hexists(\u0026queue.hashmap_key, popped_task.task_id.to_string())\n            .await\n            .expect(\"Failed to check task existence\");\n        assert!(!task_exists, \"Task should have been removed after ack\");\n\n        cleanup_queue(\u0026queue).await;\n    }\n\n    #[tokio::test]\n    async fn test_nack() {\n        let queue = setup_queue(\"capp-test-nack\").await;\n        let task = Task::new(TestData { value: 42 });\n\n        queue.push(\u0026task).await.expect(\"Failed to push task\");\n        let popped_task = queue.pop().await.expect(\"Failed to pop task\");\n        queue.nack(\u0026popped_task).await.expect(\"Failed to nack task\");\n\n        let task_exists: bool = queue\n            .client\n            .hexists(\u0026queue.hashmap_key, popped_task.task_id.to_string())\n            .await\n            .expect(\"Failed to check task existence\");\n        assert!(\n            !task_exists,\n            \"Task should have been removed from hashmap after nack\"\n        );\n\n        let dlq_len = queue\n            .client\n            .llen(\u0026queue.dlq_key)\n            .await\n            .expect(\"Failed to read DLQ\");\n        assert_eq!(dlq_len, 1, \"Task should have been added to DLQ\");\n\n        let dlq_task: Vec\u003cString\u003e =\n            queue.client.rpop(\u0026queue.dlq_key, 1).await.unwrap();\n\n        let dlq_task: Task\u003cTestData\u003e = serde_json::from_str(\u0026dlq_task[0])\n            .expect(\"Failed to deserialize task from DLQ\");\n        assert_eq!(dlq_task.payload.value, popped_task.payload.value);\n\n        cleanup_queue(\u0026queue).await;\n    }\n\n    #[tokio::test]\n    async fn test_set() {\n        let queue = setup_queue(\"capp-test-set\").await;\n        let mut task = Task::new(TestData { value: 42 });\n\n        queue.push(\u0026task).await.expect(\"Failed to push task\");\n        task.payload.value = 43;\n        queue.set(\u0026task).await.expect(\"Failed to set task\");\n\n        let updated_task_json: String = queue\n            .client\n            .hget(\u0026queue.hashmap_key, task.task_id.to_string())\n            .await\n            .expect(\"Failed to get updated task\");\n        let updated_task: Task\u003cTestData\u003e = serde_json::from_str(\u0026updated_task_json)\n            .expect(\"Failed to deserialize updated task\");\n\n        assert_eq!(updated_task.payload.value, 43);\n\n        cleanup_queue(\u0026queue).await;\n    }\n\n    #[tokio::test]\n    async fn test_queue_empty() {\n        let queue = setup_queue(\"capp-test-empty\").await;\n        cleanup_queue(\u0026queue).await;\n\n        match queue.pop().await {\n            Err(TaskQueueError::QueueEmpty) =\u003e (),\n            _ =\u003e panic!(\"Expected QueueEmpty error\"),\n        }\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","tmp","storage","backends","memory.rs"],"content":"//! In-memory implementation of TaskStorage trait. The storage allows tasks to be\n//! pushed to and popped from a queue, and also allows tasks to be set and\n//! retrieved by their UUID.\nuse crate::prelude::{Task, TaskId, TaskStorage, TaskStorageError};\nuse async_trait::async_trait;\nuse serde::de::DeserializeOwned;\nuse serde::Serialize;\nuse std::collections::{HashMap, VecDeque};\nuse std::marker::PhantomData;\nuse std::sync::Mutex;\n\n/// A simple in-memory implementation of the `TaskStorage` trait.\n/// The `InMemoryTaskStorage` struct includes a hashmap for storing tasks by\n/// their TaskId's, and a list for maintaining the order of the tasks.\npub struct InMemoryTaskStorage\u003cD\u003e {\n    pub hashmap: Mutex\u003cHashMap\u003cTaskId, String\u003e\u003e,\n    pub list: Mutex\u003cVecDeque\u003cTaskId\u003e\u003e,\n    pub dlq: Mutex\u003cHashMap\u003cTaskId, String\u003e\u003e,\n    _marker1: PhantomData\u003cD\u003e,\n}\n\nimpl\u003cData\u003e InMemoryTaskStorage\u003cData\u003e {\n    /// Construct a new empty in-memory task storage\n    pub fn new() -\u003e Self {\n        Self {\n            hashmap: Mutex::new(HashMap::new()),\n            list: Mutex::new(VecDeque::new()),\n            dlq: Mutex::new(HashMap::new()),\n            _marker1: PhantomData,\n        }\n    }\n}\n\nimpl\u003cData\u003e Default for InMemoryTaskStorage\u003cData\u003e {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\nimpl\u003cData\u003e std::fmt::Debug for InMemoryTaskStorage\u003cData\u003e {\n    fn fmt(\u0026self, f: \u0026mut std::fmt::Formatter\u003c'_\u003e) -\u003e std::fmt::Result {\n        // Lock the mutexes to access the data.\n        let hashmap = self.hashmap.lock().unwrap();\n        let list = self.list.lock().unwrap();\n\n        // Use the debug builders to format the output.\n        f.debug_struct(\"InMemoryTaskStorage\")\n            .field(\"hashmap\", \u0026*hashmap)\n            .field(\"list\", \u0026*list)\n            .finish()\n    }\n}\n\n#[async_trait]\nimpl\u003cData\u003e TaskStorage\u003cData\u003e for InMemoryTaskStorage\u003cData\u003e\nwhere\n    Data: std::fmt::Debug\n        + Clone\n        + Serialize\n        + DeserializeOwned\n        + Send\n        + Sync\n        + 'static,\n{\n    async fn task_ack(\n        \u0026self,\n        task_id: \u0026TaskId,\n    ) -\u003e Result\u003cTask\u003cData\u003e, TaskStorageError\u003e {\n        let mut hashmap = self.hashmap.lock().map_err(|_| {\n            TaskStorageError::StorageError(format!(\"Mutex lock error: {}\", task_id))\n        })?;\n        let task_value =\n            hashmap\n                .remove(task_id)\n                .ok_or(TaskStorageError::StorageError(format!(\n                    \"Error removing task from HashMap: {}\",\n                    task_id\n                )))?;\n        let task = serde_json::from_str(\u0026task_value)\n            .map_err(|err| TaskStorageError::SerializationError(err.to_string()))?;\n        Ok(task)\n    }\n\n    async fn task_get(\n        \u0026self,\n        task_id: \u0026TaskId,\n    ) -\u003e Result\u003cTask\u003cData\u003e, TaskStorageError\u003e {\n        let hashmap = self.hashmap.lock().map_err(|_| {\n            TaskStorageError::StorageError(format!(\"Mutex lock error: {}\", task_id))\n        })?;\n        let task_value =\n            hashmap\n                .get(task_id)\n                .ok_or(TaskStorageError::StorageError(format!(\n                    \"Error getting task from HashMap: {}\",\n                    task_id\n                )))?;\n        let task: Task\u003cData\u003e = serde_json::from_str(task_value)\n            .map_err(|err| TaskStorageError::SerializationError(err.to_string()))?;\n        Ok(task)\n    }\n\n    async fn task_set(\u0026self, task: \u0026Task\u003cData\u003e) -\u003e Result\u003c(), TaskStorageError\u003e {\n        let mut hashmap = self.hashmap.lock().map_err(|_| {\n            TaskStorageError::StorageError(\"Lock error on task hashmap\".to_string())\n        })?;\n        let task_value = serde_json::to_string(task)\n            .map_err(|err| TaskStorageError::SerializationError(err.to_string()))?;\n        hashmap.insert(task.task_id, task_value);\n        Ok(())\n    }\n\n    async fn task_pop(\u0026self) -\u003e Result\u003cTask\u003cData\u003e, TaskStorageError\u003e {\n        let mut list = self.list.lock().map_err(|_| {\n            TaskStorageError::StorageError(\"Lock error\".to_string())\n        })?;\n        let hashmap = self.hashmap.lock().map_err(|_| {\n            TaskStorageError::StorageError(\"Lock error on task hashmap\".to_string())\n        })?;\n\n        if let Some(task_id) = list.pop_front() {\n            let task_value = hashmap.get(\u0026task_id).unwrap();\n            let task: Task\u003cData\u003e = serde_json::from_str(task_value)\n                .map_err(|err| TaskStorageError::StorageError(err.to_string()))?;\n            return Ok(task);\n        }\n        Err(TaskStorageError::StorageIsEmptyError)\n    }\n\n    async fn task_push(\u0026self, task: \u0026Task\u003cData\u003e) -\u003e Result\u003c(), TaskStorageError\u003e {\n        let mut list = self.list.lock().map_err(|_| {\n            TaskStorageError::StorageError(\"Lock error on task list\".to_string())\n        })?;\n        let mut hashmap = self.hashmap.lock().map_err(|_| {\n            TaskStorageError::StorageError(\"Lock error on task hashmap\".to_string())\n        })?;\n\n        let task_value = serde_json::to_string(task)\n            .map_err(|err| TaskStorageError::SerializationError(err.to_string()))?;\n        hashmap.insert(task.task_id, task_value);\n        list.push_back(task.task_id);\n        Ok(())\n    }\n\n    async fn task_to_dlq(\u0026self, task: \u0026Task\u003cData\u003e) -\u003e Result\u003c(), TaskStorageError\u003e {\n        let mut dlq = self.hashmap.lock().map_err(|_| {\n            TaskStorageError::StorageError(\"Lock error on task hashmap\".to_string())\n        })?;\n        let task_value = serde_json::to_string(task)\n            .map_err(|err| TaskStorageError::StorageError(err.to_string()))?;\n        dlq.insert(task.task_id, task_value);\n        Ok(())\n    }\n\n    // general storage operations\n    async fn purge(\u0026self) -\u003e Result\u003c(), TaskStorageError\u003e {\n        let mut list = self.list.lock().map_err(|_| {\n            TaskStorageError::StorageError(\"Lock error on task list\".to_string())\n        })?;\n        let mut hashmap = self.hashmap.lock().map_err(|_| {\n            TaskStorageError::StorageError(\"Lock error on task hashmap\".to_string())\n        })?;\n        let mut dlq = self.hashmap.lock().map_err(|_| {\n            TaskStorageError::StorageError(\"Lock error on task hashmap\".to_string())\n        })?;\n        list.clear();\n        hashmap.clear();\n        dlq.clear();\n        Ok(())\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use std::assert_eq;\n\n    use super::*;\n    use crate::prelude::Task;\n    use serde::{Deserialize, Serialize};\n    use tokio::runtime::Runtime;\n\n    #[derive(Debug, Clone, Serialize, Deserialize)]\n    struct TaskData {\n        value: u32,\n    }\n\n    #[test]\n    fn storage_init() {\n        let storage: InMemoryTaskStorage\u003cTaskData\u003e = InMemoryTaskStorage::new();\n        assert_eq!(storage.list.lock().unwrap().len(), 0);\n    }\n\n    #[test]\n    fn storage_push_pop_ops() {\n        let rt = Runtime::new().unwrap();\n        let storage: InMemoryTaskStorage\u003cTaskData\u003e = InMemoryTaskStorage::new();\n\n        let task = Task::new(TaskData { value: 42 });\n        let push_result = rt.block_on(storage.task_push(\u0026task));\n        assert!(push_result.is_ok());\n        assert_eq!(storage.list.lock().unwrap().len(), 1);\n        assert_eq!(storage.hashmap.lock().unwrap().keys().len(), 1);\n\n        let task = Task::new(TaskData { value: 33 });\n        let _ = rt.block_on(storage.task_push(\u0026task));\n\n        let task = rt.block_on(storage.task_pop()).unwrap();\n        // let task = rt.block_on(storage.task_pop()).unwrap().unwrap();\n        assert_eq!(task.payload.value, 42);\n        assert_eq!(storage.list.lock().unwrap().len(), 1);\n        assert_eq!(storage.hashmap.lock().unwrap().keys().len(), 2);\n    }\n\n    #[test]\n    fn storage_get_set_ops() {\n        let rt = Runtime::new().unwrap();\n        let storage: InMemoryTaskStorage\u003cTaskData\u003e = InMemoryTaskStorage::new();\n\n        let mut task = Task::new(TaskData { value: 42 });\n        let _ = rt.block_on(storage.task_push(\u0026task));\n        let result = rt.block_on(storage.task_get(\u0026task.task_id)).unwrap();\n        assert_eq!(result.payload.value, 42);\n\n        task.payload.value = 11;\n        let _ = rt.block_on(storage.task_set(\u0026task));\n\n        let task = rt.block_on(storage.task_pop()).unwrap();\n        let task_acked = rt.block_on(storage.task_ack(\u0026task.task_id)).unwrap();\n        assert_eq!(task_acked.payload.value, 11);\n        assert_eq!(task_acked.task_id, task.task_id);\n\n        assert_eq!(storage.hashmap.lock().unwrap().keys().len(), 0);\n        assert_eq!(storage.list.lock().unwrap().len(), 0);\n    }\n\n    #[test]\n    fn storage_ack() {\n        let rt = Runtime::new().unwrap();\n        let storage: InMemoryTaskStorage\u003cTaskData\u003e = InMemoryTaskStorage::new();\n\n        let task = Task::new(TaskData { value: 42 });\n        let _ = rt.block_on(storage.task_push(\u0026task));\n        let task = Task::new(TaskData { value: 33 });\n        let _ = rt.block_on(storage.task_push(\u0026task));\n\n        let task = rt.block_on(storage.task_pop()).unwrap();\n        let task = rt.block_on(storage.task_ack(\u0026task.task_id)).unwrap();\n        assert_eq!(task.payload.value, 42);\n\n        assert_eq!(storage.hashmap.lock().unwrap().keys().len(), 1);\n        assert_eq!(storage.list.lock().unwrap().len(), 1);\n    }\n}\n","traces":[{"line":24,"address":[],"length":0,"stats":{"Line":0}},{"line":26,"address":[],"length":0,"stats":{"Line":0}},{"line":27,"address":[],"length":0,"stats":{"Line":0}},{"line":28,"address":[],"length":0,"stats":{"Line":0}},{"line":35,"address":[],"length":0,"stats":{"Line":0}},{"line":36,"address":[],"length":0,"stats":{"Line":0}},{"line":41,"address":[],"length":0,"stats":{"Line":0}},{"line":43,"address":[],"length":0,"stats":{"Line":0}},{"line":44,"address":[],"length":0,"stats":{"Line":0}},{"line":47,"address":[],"length":0,"stats":{"Line":0}},{"line":48,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":147,"address":[],"length":0,"stats":{"Line":0}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":150,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":152,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":160,"address":[],"length":0,"stats":{"Line":0}},{"line":161,"address":[],"length":0,"stats":{"Line":0}},{"line":163,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":169,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":80},{"path":["/","Users","alexc","code","capp-rs","tmp","storage","backends","redis.rs"],"content":"//! Provides implementation of trait to store task into redis\n//! TODO: make sequental ops into atomic transaction\nuse crate::prelude::*;\nuse async_trait::async_trait;\nuse rustis::commands::{GenericCommands, HashCommands, ListCommands};\nuse serde::de::DeserializeOwned;\nuse serde::Serialize;\nuse std::marker::PhantomData;\n\n/// A simple implementation of the `TaskStorage` trait on top of redis\npub struct RedisTaskStorage\u003cD\u003e {\n    pub key: String,\n    pub redis: rustis::client::Client,\n    _marker1: PhantomData\u003cD\u003e,\n}\n\nimpl\u003cD\u003e RedisTaskStorage\u003cD\u003e {\n    /// Construct a new empty redis task storage\n    pub fn new(key: \u0026str, redis: rustis::client::Client) -\u003e Self {\n        Self {\n            key: key.to_string(),\n            redis,\n            _marker1: PhantomData,\n        }\n    }\n\n    pub fn get_hashmap_key(\u0026self) -\u003e String {\n        format!(\"{}:{}\", self.key, \"hm\")\n    }\n\n    pub fn get_list_key(\u0026self) -\u003e String {\n        format!(\"{}:{}\", self.key, \"ls\")\n    }\n\n    pub fn get_dlq_key(\u0026self) -\u003e String {\n        format!(\"{}:{}\", self.key, \"dlq\")\n    }\n}\n\nimpl\u003cD\u003e std::fmt::Debug for RedisTaskStorage\u003cD\u003e {\n    fn fmt(\u0026self, f: \u0026mut std::fmt::Formatter\u003c'_\u003e) -\u003e std::fmt::Result {\n        // TODO: implement debug output for data in redis\n        // Use the debug builders to format the output.\n        // NOTE: here i will need to do actual queries to redis\n        f.debug_struct(\"RedisTaskStorage\")\n            // .field(\"hashmap\", \u0026*hashmap)\n            // .field(\"list\", \u0026*list)\n            .finish()\n    }\n}\n\n#[async_trait]\nimpl\u003cD\u003e TaskStorage\u003cD\u003e for RedisTaskStorage\u003cD\u003e\nwhere\n    D: std::fmt::Debug\n        + Clone\n        + Serialize\n        + DeserializeOwned\n        + Send\n        + Sync\n        + 'static,\n{\n    async fn task_ack(\n        \u0026self,\n        task_id: \u0026TaskId,\n    ) -\u003e Result\u003cTask\u003cD\u003e, TaskStorageError\u003e {\n        let hashmap_key = self.get_hashmap_key();\n        let uuid_as_str = task_id.to_string();\n        let task_value: String =\n            self.redis.hget(\u0026hashmap_key, \u0026uuid_as_str).await?;\n        let _ = self.redis.hdel(hashmap_key, \u0026uuid_as_str).await;\n        let task = serde_json::from_str(\u0026task_value).map_err(|err| {\n            TaskStorageError::DeserializationError(err.to_string())\n        })?;\n        Ok(task)\n    }\n\n    async fn task_get(\n        \u0026self,\n        task_id: \u0026TaskId,\n    ) -\u003e Result\u003cTask\u003cD\u003e, TaskStorageError\u003e {\n        let hashmap_key = self.get_hashmap_key();\n        let uuid_as_str = task_id.to_string();\n        let task_value: String =\n            self.redis.hget(\u0026hashmap_key, \u0026uuid_as_str).await?;\n        let task_data: Task\u003cD\u003e =\n            serde_json::from_str(\u0026task_value).map_err(|err| {\n                TaskStorageError::DeserializationError(err.to_string())\n            })?;\n        Ok(task_data)\n    }\n\n    async fn task_set(\u0026self, task: \u0026Task\u003cD\u003e) -\u003e Result\u003c(), TaskStorageError\u003e {\n        let hashmap_key = self.get_hashmap_key();\n        let task_value: String = serde_json::to_string(task)\n            .map_err(|err| TaskStorageError::SerializationError(err.to_string()))?;\n        let uuid_as_str = task.task_id.to_string();\n        let _ = self\n            .redis\n            .hset(\u0026hashmap_key, [(\u0026uuid_as_str, \u0026task_value)])\n            .await;\n        Ok(())\n    }\n\n    async fn task_pop(\u0026self) -\u003e Result\u003cTask\u003cD\u003e, TaskStorageError\u003e {\n        let list_key = self.get_list_key();\n        let hashmap_key = self.get_hashmap_key();\n        let task_ids: Vec\u003cString\u003e = self.redis.rpop(\u0026list_key, 1).await?;\n        if task_ids.len() \u003e 0 {\n            let task_id = task_ids.first().unwrap();\n            let task_value: String = self.redis.hget(\u0026hashmap_key, task_id).await?;\n            let task: Task\u003cD\u003e =\n                serde_json::from_str(\u0026task_value).map_err(|err| {\n                    TaskStorageError::DeserializationError(err.to_string())\n                })?;\n            return Ok(task);\n        }\n\n        Err(TaskStorageError::StorageIsEmptyError)\n    }\n\n    async fn task_push(\u0026self, task: \u0026Task\u003cD\u003e) -\u003e Result\u003c(), TaskStorageError\u003e {\n        let task_value = serde_json::to_string(task)\n            .map_err(|err| TaskStorageError::SerializationError(err.to_string()))?;\n        let list_key = self.get_list_key();\n        let hashmap_key = self.get_hashmap_key();\n        let uuid_as_str = task.task_id.to_string();\n\n        let _ = self.redis.lpush(\u0026list_key, \u0026uuid_as_str).await?;\n        let _ = self\n            .redis\n            .hset(\u0026hashmap_key, [(\u0026uuid_as_str, \u0026task_value)])\n            .await?;\n        Ok(())\n    }\n\n    async fn task_to_dlq(\u0026self, task: \u0026Task\u003cD\u003e) -\u003e Result\u003c(), TaskStorageError\u003e {\n        let task_value = serde_json::to_string(task)\n            .map_err(|err| TaskStorageError::SerializationError(err.to_string()))?;\n        let dlq_key = self.get_dlq_key();\n        let uuid_as_str = task.task_id.to_string();\n\n        let _ = self\n            .redis\n            .hset(\u0026dlq_key, [(\u0026uuid_as_str, \u0026task_value)])\n            .await?;\n        Ok(())\n    }\n\n    async fn purge(\u0026self) -\u003e Result\u003c(), TaskStorageError\u003e {\n        let _ = self.redis.del(self.get_hashmap_key()).await?;\n        let _ = self.redis.del(self.get_list_key()).await?;\n        let _ = self.redis.del(self.get_dlq_key()).await?;\n        Ok(())\n    }\n}\n","traces":[{"line":19,"address":[],"length":0,"stats":{"Line":0}},{"line":21,"address":[],"length":0,"stats":{"Line":0}},{"line":27,"address":[],"length":0,"stats":{"Line":0}},{"line":28,"address":[],"length":0,"stats":{"Line":0}},{"line":31,"address":[],"length":0,"stats":{"Line":0}},{"line":32,"address":[],"length":0,"stats":{"Line":0}},{"line":35,"address":[],"length":0,"stats":{"Line":0}},{"line":36,"address":[],"length":0,"stats":{"Line":0}},{"line":41,"address":[],"length":0,"stats":{"Line":0}},{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":147,"address":[],"length":0,"stats":{"Line":0}},{"line":150,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":152,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":75},{"path":["/","Users","alexc","code","capp-rs","tmp","storage","backends","redis_rr.rs"],"content":"//! `RedisRoundRobinTaskStorage` provides an asynchronous task storage mechanism\n//! built on top of Redis, with a round-robin approach to accessing tasks across\n//! different queues.\n//!\n//! This storage structure maintains domain-specific queues, allowing for tasks\n//! to be categorized and processed based on their associated key. The round-robin\n//! mechanism ensures that tasks from one domain do not dominate the queue, allowing\n//! for balanced task processing across all domains.\n//!\n//! Features:\n//! - **Tag-based Queues**: Tasks are enqueued and dequeued based on their\n//!   tag, preventing any single tag from monopolizing worker resources.\n//! - **Round Robin Access**: The storage fetches tasks in a round-robin manner\n//!   across the tags, ensuring fair access and processing for all tags.\n//! - **Asynchronous Operations**: All task operations, including enqueueing,\n//!   dequeueing, and acknowledging, are performed asynchronously for optimal\n//!   performance.\n//!\n//! # Examples\n//!\n//! ```rust\n//! // TODO: Insert basic usage example here.\n//! ```\n//!\n//! Note: The exact tag key for each task is determined from the `TaskData`\n//! field, and can be configured during the storage initialization.\n\nuse crate::prelude::{HasTagKey, Task, TaskId, TaskStorage, TaskStorageError};\nuse async_trait::async_trait;\nuse rustis::commands::{GenericCommands, HashCommands, ListCommands};\nuse serde::{de::DeserializeOwned, Serialize};\nuse std::{\n    marker::PhantomData,\n    sync::{\n        atomic::{AtomicUsize, Ordering},\n        Arc, Mutex,\n    },\n};\n\npub struct RedisRoundRobinTaskStorage\u003cD\u003e {\n    pub key: String,\n    pub redis: rustis::client::Client,\n    pub tags: Arc\u003cMutex\u003cstd::collections::HashSet\u003cString\u003e\u003e\u003e,\n    pub current_tag_index: Arc\u003cAtomicUsize\u003e,\n    pub tag_field_name: String,\n    _marker1: PhantomData\u003cD\u003e,\n}\n\n#[async_trait]\nimpl\u003cD\u003e TaskStorage\u003cD\u003e for RedisRoundRobinTaskStorage\u003cD\u003e\nwhere\n    D: std::fmt::Debug\n        + Clone\n        + HasTagKey\n        + Serialize\n        + DeserializeOwned\n        + Send\n        + Sync\n        + 'static,\n{\n    async fn task_ack(\n        \u0026self,\n        task_id: \u0026TaskId,\n    ) -\u003e Result\u003cTask\u003cD\u003e, TaskStorageError\u003e {\n        let hashmap_key = self.get_hashmap_key();\n        let uuid_as_str = task_id.to_string();\n        let task_value: String =\n            self.redis.hget(\u0026hashmap_key, \u0026uuid_as_str).await?;\n        let _ = self.redis.hdel(hashmap_key, \u0026uuid_as_str).await;\n        let task = serde_json::from_str(\u0026task_value).map_err(|err| {\n            TaskStorageError::DeserializationError(err.to_string())\n        })?;\n        Ok(task)\n    }\n\n    async fn task_get(\n        \u0026self,\n        task_id: \u0026TaskId,\n    ) -\u003e Result\u003cTask\u003cD\u003e, TaskStorageError\u003e {\n        let hashmap_key = self.get_hashmap_key();\n        let uuid_as_str = task_id.to_string();\n        let task_value: String =\n            self.redis.hget(\u0026hashmap_key, \u0026uuid_as_str).await?;\n        let task_data: Task\u003cD\u003e =\n            serde_json::from_str(\u0026task_value).map_err(|err| {\n                TaskStorageError::DeserializationError(err.to_string())\n            })?;\n        Ok(task_data)\n    }\n\n    async fn task_set(\u0026self, task: \u0026Task\u003cD\u003e) -\u003e Result\u003c(), TaskStorageError\u003e {\n        let hashmap_key = self.get_hashmap_key();\n        let task_value: String = serde_json::to_string(task)\n            .map_err(|err| TaskStorageError::SerializationError(err.to_string()))?;\n        let uuid_as_str = task.task_id.to_string();\n        let _ = self\n            .redis\n            .hset(\u0026hashmap_key, [(\u0026uuid_as_str, \u0026task_value)])\n            .await;\n        Ok(())\n    }\n\n    async fn task_pop(\u0026self) -\u003e Result\u003cTask\u003cD\u003e, TaskStorageError\u003e {\n        let queue_name = self.get_next_queue()?;\n        let list_key = self.get_list_key(\u0026queue_name);\n        let hashmap_key = self.get_hashmap_key();\n        let task_ids: Vec\u003cString\u003e = self.redis.rpop(\u0026list_key, 1).await?;\n        if task_ids.len() \u003e 0 {\n            let task_id = task_ids.first().unwrap();\n            let task_value: String = self.redis.hget(\u0026hashmap_key, task_id).await?;\n            let task: Task\u003cD\u003e =\n                serde_json::from_str(\u0026task_value).map_err(|err| {\n                    TaskStorageError::DeserializationError(err.to_string())\n                })?;\n            return Ok(task);\n        }\n\n        Err(TaskStorageError::StorageIsEmptyError)\n    }\n\n    async fn task_push(\u0026self, task: \u0026Task\u003cD\u003e) -\u003e Result\u003c(), TaskStorageError\u003e {\n        let queue_name = task.payload.get_tag_value().to_string();\n        let task_value = serde_json::to_string(task)\n            .map_err(|err| TaskStorageError::SerializationError(err.to_string()))?;\n        let list_key = self.get_list_key(\u0026queue_name);\n        let hashmap_key = self.get_hashmap_key();\n        let uuid_as_str = task.task_id.to_string();\n\n        let _ = self.redis.lpush(\u0026list_key, \u0026uuid_as_str).await?;\n        let _ = self\n            .redis\n            .hset(\u0026hashmap_key, [(\u0026uuid_as_str, \u0026task_value)])\n            .await?;\n        Ok(())\n    }\n\n    async fn task_to_dlq(\u0026self, task: \u0026Task\u003cD\u003e) -\u003e Result\u003c(), TaskStorageError\u003e {\n        let task_value = serde_json::to_string(task)\n            .map_err(|err| TaskStorageError::SerializationError(err.to_string()))?;\n        let dlq_key = self.get_dlq_key();\n        let uuid_as_str = task.task_id.to_string();\n\n        let _ = self\n            .redis\n            .hset(\u0026dlq_key, [(\u0026uuid_as_str, \u0026task_value)])\n            .await?;\n        Ok(())\n    }\n\n    async fn purge(\u0026self) -\u003e Result\u003c(), TaskStorageError\u003e {\n        let _ = self.redis.del(self.get_hashmap_key()).await?;\n        // TODO: can do better\n        let tags: Vec\u003cString\u003e =\n            self.tags.lock().unwrap().iter().map(|t| t.into()).collect();\n        for tag in tags {\n            let _ = self.redis.del(self.get_list_key(\u0026tag)).await?;\n        }\n        let _ = self.redis.del(self.get_dlq_key()).await?;\n        Ok(())\n    }\n}\n\nimpl\u003cD\u003e RedisRoundRobinTaskStorage\u003cD\u003e {\n    /// Construct a new empty redis task storage\n    pub fn new(\n        key: \u0026str,\n        tags: std::collections::HashSet\u003cString\u003e,\n        tag_field_name: \u0026str,\n        redis: rustis::client::Client,\n    ) -\u003e Self {\n        Self {\n            key: key.to_string(),\n            redis,\n            tags: Arc::new(Mutex::new(tags)),\n            current_tag_index: Arc::new(AtomicUsize::new(0)),\n            tag_field_name: tag_field_name.to_string(),\n            _marker1: PhantomData,\n        }\n    }\n\n    pub fn get_hashmap_key(\u0026self) -\u003e String {\n        format!(\"{}:{}\", self.key, \"hm\")\n    }\n\n    pub fn get_list_key(\u0026self, queue_key: \u0026str) -\u003e String {\n        format!(\"{}:{}:{}\", self.key, queue_key, \"ls\")\n    }\n\n    pub fn get_dlq_key(\u0026self) -\u003e String {\n        format!(\"{}:{}\", self.key, \"dlq\")\n    }\n\n    fn get_next_queue(\u0026self) -\u003e Result\u003cString, TaskStorageError\u003e {\n        let queues = self.tags.lock().unwrap();\n        let len = queues.len();\n        if queues.is_empty() {\n            return Err(TaskStorageError::EmptyValueError(\n                \"self.tags is empty\".to_string(),\n            ));\n        }\n\n        let index = self.current_tag_index.fetch_add(1, Ordering::Relaxed) % len;\n        Ok(queues.iter().nth(index).unwrap().clone())\n    }\n}\n\nimpl\u003cD\u003e std::fmt::Debug for RedisRoundRobinTaskStorage\u003cD\u003e {\n    fn fmt(\u0026self, f: \u0026mut std::fmt::Formatter\u003c'_\u003e) -\u003e std::fmt::Result {\n        // TODO: implement debug output for data in redis\n        // Use the debug builders to format the output.\n        f.debug_struct(\"RedisRoundRobinTaskStorage\")\n            // .field(\"hashmap\", \u0026*hashmap)\n            // .field(\"list\", \u0026*list)\n            .finish()\n    }\n}\n","traces":[{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":147,"address":[],"length":0,"stats":{"Line":0}},{"line":150,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":0}},{"line":172,"address":[],"length":0,"stats":{"Line":0}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":0}},{"line":176,"address":[],"length":0,"stats":{"Line":0}},{"line":181,"address":[],"length":0,"stats":{"Line":0}},{"line":182,"address":[],"length":0,"stats":{"Line":0}},{"line":185,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":189,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":0}},{"line":193,"address":[],"length":0,"stats":{"Line":0}},{"line":194,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":202,"address":[],"length":0,"stats":{"Line":0}},{"line":203,"address":[],"length":0,"stats":{"Line":0}},{"line":208,"address":[],"length":0,"stats":{"Line":0}},{"line":211,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":90},{"path":["/","Users","alexc","code","capp-rs","tmp","storage","backends.rs"],"content":"pub mod memory;\n#[cfg(feature = \"redis\")]\npub mod redis;\n#[cfg(feature = \"redis\")]\npub mod redis_rr;\n\npub use memory::InMemoryTaskStorage;\n#[cfg(feature = \"redis\")]\npub use redis::RedisTaskStorage;\n#[cfg(feature = \"redis\")]\npub use redis_rr::RedisRoundRobinTaskStorage;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","tmp","storage.rs"],"content":"//! This module provides a trait for interacting with task storage.\n//! The storage allows tasks to be pushed to and popped from a queue,\n//! and also allows tasks to be set and retrieved by their UUID.\nuse async_trait::async_trait;\nuse serde::{de::DeserializeOwned, Serialize};\nuse thiserror::Error;\n\npub mod backends;\npub mod task;\n\npub use backends::InMemoryTaskStorage;\n#[cfg(feature = \"redis\")]\npub use backends::{RedisRoundRobinTaskStorage, RedisTaskStorage};\npub use task::{Task, TaskId, TaskStatus};\n\npub type AbstractTaskStorage\u003cD\u003e = std::sync::Arc\u003cdyn TaskStorage\u003cD\u003e + Send + Sync\u003e;\n\n#[derive(Error, Debug)]\npub enum TaskStorageError {\n    #[error(\"Storage error: {0}\")]\n    StorageError(String),\n    #[error(\"Serialization error: {0}\")]\n    SerializationError(String),\n    #[error(\"Deserialization error: {0}\")]\n    DeserializationError(String),\n    #[error(\"Task not found {0}\")]\n    TaskNotFound(TaskId),\n    #[error(\"Empty value \")]\n    EmptyValueError(String),\n    #[error(\"Storage is empty\")]\n    StorageIsEmptyError,\n    #[cfg(feature = \"redis\")]\n    #[error(\"Redis error\")]\n    RedisError(#[from] rustis::Error),\n}\n\n/// A trait that describes the necessary methods for task storage. This includes\n/// methods for acknowledging a task, getting a task by its UUID, setting a task,\n/// popping a task from the queue, and pushing a task into the queue.\n/// Whole functions should be non blocking. I.e. task_push should return None\n/// to be able to process situation when there is no tasks in queue on worker side.\n#[async_trait]\npub trait TaskStorage\u003cData\u003e\nwhere\n    Data: std::fmt::Debug\n        + Clone\n        + Serialize\n        + DeserializeOwned\n        + Send\n        + Sync\n        + 'static,\n{\n    // task operations\n    async fn task_ack(\n        \u0026self,\n        task_id: \u0026TaskId,\n    ) -\u003e Result\u003cTask\u003cData\u003e, TaskStorageError\u003e;\n    async fn task_get(\n        \u0026self,\n        task_id: \u0026TaskId,\n    ) -\u003e Result\u003cTask\u003cData\u003e, TaskStorageError\u003e;\n    async fn task_set(\u0026self, task: \u0026Task\u003cData\u003e) -\u003e Result\u003c(), TaskStorageError\u003e;\n    async fn task_pop(\u0026self) -\u003e Result\u003cTask\u003cData\u003e, TaskStorageError\u003e;\n    async fn task_push(\u0026self, task: \u0026Task\u003cData\u003e) -\u003e Result\u003c(), TaskStorageError\u003e;\n    async fn task_to_dlq(\u0026self, task: \u0026Task\u003cData\u003e) -\u003e Result\u003c(), TaskStorageError\u003e;\n\n    // general storage operations\n    async fn purge(\u0026self) -\u003e Result\u003c(), TaskStorageError\u003e;\n}\n\n// Used for round robin queue\npub trait HasTagKey {\n    type TagValue: ToString + PartialEq;\n    fn get_tag_value(\u0026self) -\u003e Self::TagValue;\n}\n","traces":[],"covered":0,"coverable":0}]};
        var previousData = {"files":[{"path":["/","Users","alexc","code","capp-rs","capp","src","lib.rs"],"content":"//! # CAPP - \"Comprehensive Asynchronous Parallel Processing\" or just \"Crawler APP\"\n//!\n//! `capp` is a Rust library designed to provide powerful and flexible tools for building efficient web crawlers and other asynchronous, parallel processing applications. It offers a robust framework for managing concurrent tasks, handling network requests, and processing large amounts of data in a scalable manner.\n//!\n//! ## Features\n//!\n//! - **Asynchronous Task Management**: Utilize tokio-based asynchronous processing for efficient, non-blocking execution of tasks.\n//! - **Flexible Task Queue**: Implement various backend storage options for task queues, including in-memory and Redis-based solutions.\n//! - **Round-Robin Task Distribution**: Ensure fair distribution of tasks across different domains or categories.\n//! - **Configurable Workers**: Set up and manage multiple worker instances to process tasks concurrently.\n//! - **Error Handling and Retry Mechanisms**: Robust error handling with configurable retry policies for failed tasks.\n//! - **Dead Letter Queue (DLQ)**: Automatically move problematic tasks to a separate queue for later analysis or reprocessing.\n//! - **Health Checks**: Built-in health check functionality to ensure the stability of your crawling or processing system.\n//! - **Extensible Architecture**: Easily extend the library with custom task types, processing logic, and storage backends.\n//!\n//! ## Use Cases\n//!\n//! While `capp` is primarily designed for building web crawlers, its architecture makes it suitable for a variety of parallel processing tasks, including:\n//!\n//! - Web scraping and data extraction\n//! - Distributed task processing\n//! - Batch job management\n//! - Asynchronous API clients\n//! - Large-scale data processing pipelines\n//!\n//! ## Getting Started\n//!\n//! To use `capp` in your project, add it to your `Cargo.toml`:\n//!\n//! ```toml\n//! [dependencies]\n//! capp = \"0.4\"\n//! ```\n//!\n//! Check examples!\n//!\n//! ## Modules\n//!\n//! - `config`: Configuration management for your application.\n//! - `healthcheck`: Functions for performing health checks on your system.\n//! - `http`: Utilities for making HTTP requests and handling responses.\n//! - `manager`: Task and worker management structures.\n//! - `queue`: Task queue implementations and traits.\n//! - `task`: Definitions and utilities for working with tasks.\npub mod manager;\npub mod prelude;\n\n// re-export\npub use async_trait;\n#[cfg(feature = \"http\")]\npub use derive_builder;\n#[cfg(feature = \"http\")]\npub use reqwest;\n#[cfg(feature = \"redis\")]\npub use rustis;\npub use serde;\npub use serde_json;\npub use serde_yaml;\npub use thiserror;\npub use tracing;\npub use tracing_subscriber;\npub use uuid;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","capp","src","manager","computation.rs"],"content":"use async_trait::async_trait;\nuse capp_queue::queue::AbstractTaskQueue;\nuse capp_queue::task::Task;\nuse serde::{de::DeserializeOwned, Serialize};\nuse std::sync::Arc;\nuse thiserror::Error;\n\nuse super::worker::WorkerId;\n\n#[derive(Error, Debug)]\npub enum ComputationError {\n    #[error(\"I/O error: {0}\")]\n    Io(#[from] std::io::Error),\n    #[error(\"Database error: {0}\")]\n    Db(String),\n    #[error(\"Task storage error: {0}\")]\n    Storage(String),\n    #[error(\"Task error: {0}\")]\n    Task(String),\n    #[error(\"Computation execution error: {0}\")]\n    Function(String),\n    #[error(\"Max retries: {0}\")]\n    MaxRetries(String),\n}\n\n/// A trait defining the interface for processing a task. This trait is\n/// intended to be implemented by a worker that will process tasks\n/// of a specific type.\n#[async_trait]\npub trait Computation\u003cData, Ctx\u003e\nwhere\n    Data: Clone + Serialize + DeserializeOwned + Send + Sync + 'static,\n    Ctx: Send + Sync + 'static,\n{\n    /// Do computation The worker_id is passed for logging or\n    /// debugging purposes. The task is a mutable reference,\n    /// allowing the processor to modify the task data as part of the processing.\n    async fn call(\n        \u0026self,\n        worker_id: WorkerId,\n        ctx: Arc\u003cCtx\u003e,\n        // NOTE: i used type alias instead of this\n        // is something put this line back and remove next one!\n        // storage: Arc\u003cdyn TaskStorage\u003cData\u003e + Send + Sync\u003e,\n        queue: AbstractTaskQueue\u003cData\u003e,\n        task: \u0026mut Task\u003cData\u003e,\n    ) -\u003e Result\u003c(), ComputationError\u003e;\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","capp","src","manager","handler.rs"],"content":"//! This module defines the `TaskHandler` trait, which provides a generic interface\n//! for asynchronous task processing. It allows for flexible implementation of\n//! request handling with associated types for requests, responses, and errors.\n\nuse crate::prelude::WorkerId;\nuse async_trait::async_trait;\nuse capp_queue::queue::AbstractTaskQueue;\nuse capp_queue::task::Task;\nuse std::sync::Arc;\n\n/// A trait for handling asynchronous tasks or requests.\n///\n/// This trait uses associated types to allow for flexible implementations\n/// with different request, response, and error types.\n///\n/// # Type Parameters\n///\n/// * `Req`: The type of the request or task to be handled.\n/// * `Res`: The type of the response returned after handling the request.\n/// * `Error`: The type of error that can occur during request handling.\n///\n/// # Examples\n///\n/// ```no_run\n/// use async_trait::async_trait;\n///\n/// struct MyHandler;\n///\n/// #[async_trait]\n/// impl TaskHandler for MyHandler {\n///     type Req = String;\n///     type Res = usize;\n///     type Error = std::io::Error;\n///\n///     async fn handle(\u0026self, req: \u0026Self::Req) -\u003e Result\u003cSelf::Res, Self::Error\u003e {\n///         Ok(req.len())\n///     }\n/// }\n/// ```\n#[async_trait]\npub trait TaskHandler {\n    type Req;\n    type Res;\n    type Error;\n\n    /// Handles a request asynchronously.\n    ///\n    /// This method takes a reference to a request of type `Req` and returns\n    /// a `Result` containing either a response of type `Res` or an error of type `Error`.\n    ///\n    /// # Arguments\n    ///\n    /// * `req`: A reference to the request to be handled.\n    ///\n    /// # Returns\n    ///\n    /// Returns a `Result\u003cSelf::Res, Self::Error\u003e` which is:\n    /// - `Ok(res)` containing the response if the request was handled successfully.\n    /// - `Err(error)` if an error occurred during request handling.\n    async fn handle(\u0026self, req: \u0026Self::Req) -\u003e Result\u003cSelf::Res, Self::Error\u003e;\n}\n\n#[async_trait::async_trait]\npub trait RequestBuilder\u003cD, Ctx, Req\u003e\nwhere\n    D: std::fmt::Debug + Clone,\n{\n    async fn build_request(\n        worker_id: WorkerId,\n        ctx: Arc\u003cCtx\u003e,\n        queue: AbstractTaskQueue\u003cD\u003e,\n        task: \u0026Task\u003cD\u003e,\n    ) -\u003e Req;\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::io;\n\n    struct MyTaskHandler;\n\n    #[derive(Debug, PartialEq)]\n    struct MyRequest {\n        content: String,\n    }\n\n    #[async_trait]\n    impl TaskHandler for MyTaskHandler {\n        type Req = MyRequest;\n        type Res = String;\n        type Error = io::Error;\n\n        async fn handle(\u0026self, req: \u0026Self::Req) -\u003e Result\u003cSelf::Res, Self::Error\u003e {\n            if req.content == \"error\" {\n                Err(io::Error::new(io::ErrorKind::Other, \"Error triggered\"))\n            } else {\n                Ok(format!(\"Processed: {}\", req.content))\n            }\n        }\n    }\n\n    #[tokio::test]\n    async fn test_successful_handle() {\n        let handler = MyTaskHandler;\n        let request = MyRequest {\n            content: \"test content\".to_string(),\n        };\n\n        let result = handler.handle(\u0026request).await;\n        assert!(result.is_ok());\n        assert_eq!(result.unwrap(), \"Processed: test content\");\n    }\n\n    #[tokio::test]\n    async fn test_error_handle() {\n        let handler = MyTaskHandler;\n        let request = MyRequest {\n            content: \"error\".to_string(),\n        };\n\n        let result = handler.handle(\u0026request).await;\n        assert!(result.is_err());\n        assert_eq!(result.unwrap_err().kind(), io::ErrorKind::Other);\n    }\n\n    #[tokio::test]\n    async fn test_multiple_requests() {\n        let handler = MyTaskHandler;\n        let requests = vec![\n            MyRequest {\n                content: \"first\".to_string(),\n            },\n            MyRequest {\n                content: \"second\".to_string(),\n            },\n            MyRequest {\n                content: \"third\".to_string(),\n            },\n        ];\n\n        for request in requests {\n            let result = handler.handle(\u0026request).await;\n            assert!(result.is_ok());\n            assert_eq!(result.unwrap(), format!(\"Processed: {}\", request.content));\n        }\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","capp","src","manager","stats.rs"],"content":"use serde::Serialize;\n\n#[derive(Debug, Serialize)]\npub struct SharedStats\u003c'a\u003e {\n    workers_stats: Vec\u003c\u0026'a WorkerStats\u003e,\n}\n\n#[derive(Clone, Debug, Serialize)]\npub struct WorkerStats {\n    pub total_execution_time: std::time::Duration,\n    pub tasks_processed: usize,\n    pub tasks_succeeded: usize,\n    pub tasks_failed: usize,\n}\n\nimpl Default for WorkerStats {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\nimpl WorkerStats {\n    pub fn new() -\u003e Self {\n        Self {\n            total_execution_time: std::time::Duration::new(0, 0),\n            tasks_processed: 0,\n            tasks_succeeded: 0,\n            tasks_failed: 0,\n        }\n    }\n\n    pub fn record_execution_time(\u0026mut self, duration: std::time::Duration) {\n        self.total_execution_time += duration;\n        self.tasks_processed += 1;\n    }\n\n    pub fn record_success(\u0026mut self) {\n        self.tasks_succeeded += 1;\n    }\n\n    pub fn record_failure(\u0026mut self) {\n        self.tasks_failed += 1;\n    }\n\n    pub fn average_execution_time(\u0026self) -\u003e std::time::Duration {\n        if self.tasks_processed == 0 {\n            return std::time::Duration::new(0, 0);\n        }\n        self.total_execution_time / self.tasks_processed as u32\n    }\n}\n\nimpl\u003c'a\u003e SharedStats\u003c'a\u003e {\n    pub fn new() -\u003e Self {\n        Self {\n            workers_stats: Vec::new(),\n        }\n    }\n\n    pub fn add_worker_stats(\u0026mut self, stats: \u0026'a WorkerStats) {\n        self.workers_stats.push(stats);\n    }\n}\n\nimpl\u003c'a\u003e Default for SharedStats\u003c'a\u003e {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n","traces":[{"line":17,"address":[],"length":0,"stats":{"Line":0}},{"line":18,"address":[],"length":0,"stats":{"Line":0}},{"line":23,"address":[],"length":0,"stats":{"Line":0}},{"line":25,"address":[],"length":0,"stats":{"Line":0}},{"line":32,"address":[],"length":0,"stats":{"Line":0}},{"line":33,"address":[],"length":0,"stats":{"Line":0}},{"line":34,"address":[],"length":0,"stats":{"Line":0}},{"line":37,"address":[],"length":0,"stats":{"Line":0}},{"line":38,"address":[],"length":0,"stats":{"Line":0}},{"line":41,"address":[],"length":0,"stats":{"Line":0}},{"line":42,"address":[],"length":0,"stats":{"Line":0}},{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":46,"address":[],"length":0,"stats":{"Line":0}},{"line":47,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":54,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":21},{"path":["/","Users","alexc","code","capp-rs","capp","src","manager","worker.rs"],"content":"use crate::manager::{Computation, WorkerStats};\nuse capp_config::config::Configurable;\nuse capp_queue::queue::{AbstractTaskQueue, TaskQueue, TaskQueueError};\nuse derive_builder::Builder;\nuse serde::{de::DeserializeOwned, Serialize};\nuse std::{sync::Arc, time::Duration};\nuse tokio::sync::{\n    broadcast,\n    mpsc::{self, error::TryRecvError},\n};\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]\npub struct WorkerId(usize);\n\n#[derive(Builder, Default, Clone, Debug)]\n#[builder(public, setter(into))]\npub struct WorkerOptions {\n    #[builder(default = \"3\")]\n    pub max_retries: u32,\n    #[builder(default = \"None\")]\n    pub task_limit: Option\u003cusize\u003e,\n    #[builder(default = \"std::time::Duration::from_secs(5)\")]\n    pub no_task_found_delay: Duration,\n}\n\npub enum WorkerCommand {\n    Shutdown, // Gracefully shut down worker\n}\n\npub struct Worker\u003cData, Comp, Ctx\u003e {\n    worker_id: WorkerId,\n    ctx: Arc\u003cCtx\u003e,\n    queue: AbstractTaskQueue\u003cData\u003e,\n    computation: Arc\u003cComp\u003e,\n    pub stats: WorkerStats,\n    pub options: WorkerOptions,\n}\n\n/// A worker implementation that fetches a task from the storage, processes it,\n/// and then updates the task status. If the processing fails,\n/// the task is retried up to N times.\nimpl\u003cData, Comp, Ctx\u003e Worker\u003cData, Comp, Ctx\u003e\nwhere\n    Data: std::fmt::Debug\n        + Clone\n        + Serialize\n        + DeserializeOwned\n        + Send\n        + Sync\n        + 'static,\n    Comp: Computation\u003cData, Ctx\u003e + Send + Sync + 'static,\n    Ctx: Configurable + Send + Sync + 'static,\n{\n    pub fn new(\n        worker_id: WorkerId,\n        ctx: Arc\u003cCtx\u003e,\n        queue: Arc\u003cdyn TaskQueue\u003cData\u003e + Send + Sync\u003e,\n        computation: Arc\u003cComp\u003e,\n        options: WorkerOptions,\n    ) -\u003e Self {\n        Self {\n            worker_id,\n            ctx,\n            queue,\n            computation,\n            options,\n            stats: WorkerStats::new(),\n        }\n    }\n\n    pub fn get_stats(\u0026self) -\u003e \u0026WorkerStats {\n        \u0026self.stats\n    }\n\n    /// Worker run lify-cycle\n    /// 1) pop task from queue (or wait a bit)\n    /// 2) run computation over task\n    /// 3) update task according to computation result\n    ///\n    /// Return true if should continue or false otherwise\n    pub async fn run(\u0026mut self) -\u003e anyhow::Result\u003cbool\u003e {\n        // Implement limiting amount of tasks per worker\n        if let Some(limit) = self.options.task_limit {\n            if self.stats.tasks_processed \u003e= limit {\n                tracing::info!(\n                    \"[{}] task_limit reached: {}\",\n                    self.worker_id,\n                    limit\n                );\n                return Ok(false);\n            }\n        };\n\n        let start_time = std::time::Instant::now();\n        match self.queue.pop().await {\n            Ok(mut task) =\u003e {\n                task.set_in_progress();\n                let result = {\n                    self.computation\n                        .call(\n                            self.worker_id,\n                            self.ctx.clone(),\n                            self.queue.clone(),\n                            \u0026mut task,\n                        )\n                        .await\n                };\n                match result {\n                    Ok(_) =\u003e {\n                        task.set_succeed();\n                        self.queue.set(\u0026task).await.unwrap();\n                        self.queue.ack(\u0026task.task_id).await.unwrap();\n                        tracing::info!(\n                            \"[{}] Task {} succeed: {:?}\",\n                            self.worker_id,\n                            \u0026task.task_id,\n                            \u0026task.payload\n                        );\n\n                        // record stats on success\n                        self.stats.record_execution_time(start_time.elapsed());\n                        self.stats.record_success();\n                    }\n                    Err(err) =\u003e {\n                        task.set_retry(\u0026err.to_string());\n                        if task.retries \u003c self.options.max_retries {\n                            self.queue.push(\u0026task).await.unwrap();\n                            tracing::error!(\n                                \"[{}] Task {} failed, retrying ({}): {:?}\",\n                                self.worker_id,\n                                \u0026task.task_id,\n                                \u0026task.retries,\n                                \u0026err\n                            );\n                        } else {\n                            task.set_dlq(\"Max retries\");\n                            self.queue.nack(\u0026task).await.unwrap();\n                            tracing::error!(\n                                \"[{}] Task {} failed, max reties ({}): {:?}\",\n                                self.worker_id,\n                                \u0026task.task_id,\n                                \u0026task.retries,\n                                \u0026err\n                            );\n                        }\n\n                        self.stats.record_execution_time(start_time.elapsed());\n                        self.stats.record_failure();\n                    }\n                }\n            }\n            Err(TaskQueueError::QueueEmpty) =\u003e {\n                tracing::warn!(\"[{}] No tasks found, waiting...\", self.worker_id);\n                // wait for a while till try to fetch task\n                tokio::time::sleep(self.options.no_task_found_delay).await;\n            }\n            Err(_err) =\u003e {}\n        };\n        Ok(true)\n    }\n}\n\nimpl\u003cData, Comp, Ctx\u003e std::fmt::Debug for Worker\u003cData, Comp, Ctx\u003e {\n    fn fmt(\u0026self, f: \u0026mut std::fmt::Formatter\u003c'_\u003e) -\u003e std::fmt::Result {\n        f.debug_struct(\"Worker\")\n            .field(\"worker_id\", \u0026self.worker_id)\n            .field(\"options\", \u0026self.options)\n            .field(\"stats\", \u0026self.stats)\n            // Optionally, you can add other fields here\n            .finish()\n    }\n}\n\nimpl WorkerId {\n    pub fn new(id: usize) -\u003e Self {\n        Self(id)\n    }\n\n    pub fn get(\u0026self) -\u003e usize {\n        self.0\n    }\n}\n\nimpl std::fmt::Display for WorkerId {\n    fn fmt(\u0026self, f: \u0026mut std::fmt::Formatter\u003c'_\u003e) -\u003e std::fmt::Result {\n        write!(f, \"{}\", self.0)\n    }\n}\n\n/// This wrapper used to create new Worker setup internal logging\n/// and handle comminications with worker\npub async fn worker_wrapper\u003cData, Comp, Ctx\u003e(\n    worker_id: WorkerId,\n    ctx: Arc\u003cCtx\u003e,\n    storage: Arc\u003cdyn TaskQueue\u003cData\u003e + Send + Sync\u003e,\n    computation: Arc\u003cComp\u003e,\n    mut commands: mpsc::Receiver\u003cWorkerCommand\u003e,\n    mut terminate: broadcast::Receiver\u003c()\u003e,\n    worker_options: WorkerOptions,\n) where\n    Data: std::fmt::Debug\n        + Clone\n        + Serialize\n        + DeserializeOwned\n        + Send\n        + Sync\n        + 'static,\n    Comp: Computation\u003cData, Ctx\u003e + Send + Sync + 'static,\n    Ctx: Configurable + Send + Sync + 'static,\n{\n    let mut worker = Worker::new(\n        worker_id,\n        ctx.clone(),\n        storage.clone(),\n        computation.clone(),\n        worker_options,\n    );\n    let mut should_stop = false;\n\n    'worker: loop {\n        tokio::select! {\n            _ = terminate.recv() =\u003e {\n                tracing::info!(\"Terminating immediately\");\n                return;\n            },\n            run_result = worker.run(), if !should_stop =\u003e {\n                match commands.try_recv() {\n                    Ok(WorkerCommand::Shutdown) =\u003e {\n                        tracing::error!(\"[{}] Shutdown received\", worker_id);\n                        should_stop = true;\n                    }\n                    Err(TryRecvError::Disconnected) =\u003e break 'worker,\n                    _ =\u003e {}\n\n                }\n                // If worker ask to shutdown for some reason\n                // i.e some amount of tasks finished\n                if let Ok(re) = run_result {\n                    if !re {\n                        return;\n                    }\n                }\n            }\n        };\n\n        // If a stop command was received, finish any ongoing work and then exit.\n        if should_stop {\n            tracing::info!(\n                \"[{}] Completing current task before stopping.\",\n                worker_id\n            );\n            break;\n        }\n    }\n\n    tracing::info!(\"completed\");\n}\n\n/// This wrapper used to create new Worker setup internal logging\n/// and handle comminications with worker\npub async fn worker_wrapper_old\u003cData, Comp, Ctx\u003e(\n    worker_id: WorkerId,\n    ctx: Arc\u003cCtx\u003e,\n    storage: Arc\u003cdyn TaskQueue\u003cData\u003e + Send + Sync\u003e,\n    computation: Arc\u003cComp\u003e,\n    mut commands: mpsc::Receiver\u003cWorkerCommand\u003e,\n    mut terminate: broadcast::Receiver\u003c()\u003e,\n    worker_options: WorkerOptions,\n) where\n    Data: std::fmt::Debug\n        + Clone\n        + Serialize\n        + DeserializeOwned\n        + Send\n        + Sync\n        + 'static,\n    Comp: Computation\u003cData, Ctx\u003e + Send + Sync + 'static,\n    Ctx: Configurable + Send + Sync + 'static,\n{\n    let mut worker = Worker::new(\n        worker_id,\n        ctx.clone(),\n        storage.clone(),\n        computation.clone(),\n        worker_options,\n    );\n    let mut should_stop = false;\n\n    // setup spans\n    let span = tracing::info_span!(\"worker\", _id = %worker_id);\n    let _enter = span.enter();\n\n    'worker: loop {\n        tokio::select! {\n            _ = terminate.recv() =\u003e {\n                tracing::info!(\"Terminating immediately\");\n                return;\n            },\n            run_result = worker.run(), if !should_stop =\u003e {\n                match commands.try_recv() {\n                    Ok(WorkerCommand::Shutdown) =\u003e {\n                        tracing::error!(\"Shutdown received\");\n                        should_stop = true;\n                    }\n                    Err(TryRecvError::Disconnected) =\u003e break 'worker,\n                    _ =\u003e {}\n\n                }\n                // If worker ask to shutdown for some reason\n                // i.e some amount of tasks finished\n                if let Ok(re) = run_result {\n                    if !re {\n                        return;\n                    }\n                }\n            }\n        };\n\n        // If a stop command was received, finish any ongoing work and then exit.\n        if should_stop {\n            tracing::info!(\"Completing current task before stopping.\",);\n            break;\n        }\n    }\n\n    tracing::info!(\"completed\");\n}\n\n#[cfg(test)]\nmod tests {\n    use std::assert_eq;\n\n    use super::*;\n\n    #[test]\n    fn worker_options() {\n        let options = WorkerOptionsBuilder::default().build().unwrap();\n        assert_eq!(options.max_retries, 3);\n        assert_eq!(options.task_limit, None);\n        assert_eq!(options.no_task_found_delay, Duration::from_millis(5000));\n    }\n}\n","traces":[{"line":54,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":147,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":0}},{"line":152,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":165,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":0}},{"line":176,"address":[],"length":0,"stats":{"Line":0}},{"line":179,"address":[],"length":0,"stats":{"Line":0}},{"line":180,"address":[],"length":0,"stats":{"Line":0}},{"line":185,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":192,"address":[],"length":0,"stats":{"Line":0}},{"line":212,"address":[],"length":0,"stats":{"Line":0}},{"line":213,"address":[],"length":0,"stats":{"Line":0}},{"line":214,"address":[],"length":0,"stats":{"Line":0}},{"line":215,"address":[],"length":0,"stats":{"Line":0}},{"line":216,"address":[],"length":0,"stats":{"Line":0}},{"line":218,"address":[],"length":0,"stats":{"Line":0}},{"line":220,"address":[],"length":0,"stats":{"Line":0}},{"line":221,"address":[],"length":0,"stats":{"Line":0}},{"line":222,"address":[],"length":0,"stats":{"Line":0}},{"line":223,"address":[],"length":0,"stats":{"Line":0}},{"line":224,"address":[],"length":0,"stats":{"Line":0}},{"line":226,"address":[],"length":0,"stats":{"Line":0}},{"line":227,"address":[],"length":0,"stats":{"Line":0}},{"line":228,"address":[],"length":0,"stats":{"Line":0}},{"line":229,"address":[],"length":0,"stats":{"Line":0}},{"line":230,"address":[],"length":0,"stats":{"Line":0}},{"line":232,"address":[],"length":0,"stats":{"Line":0}},{"line":233,"address":[],"length":0,"stats":{"Line":0}},{"line":238,"address":[],"length":0,"stats":{"Line":0}},{"line":239,"address":[],"length":0,"stats":{"Line":0}},{"line":240,"address":[],"length":0,"stats":{"Line":0}},{"line":247,"address":[],"length":0,"stats":{"Line":0}},{"line":248,"address":[],"length":0,"stats":{"Line":0}},{"line":249,"address":[],"length":0,"stats":{"Line":0}},{"line":250,"address":[],"length":0,"stats":{"Line":0}},{"line":252,"address":[],"length":0,"stats":{"Line":0}},{"line":256,"address":[],"length":0,"stats":{"Line":0}},{"line":261,"address":[],"length":0,"stats":{"Line":0}},{"line":281,"address":[],"length":0,"stats":{"Line":0}},{"line":282,"address":[],"length":0,"stats":{"Line":0}},{"line":283,"address":[],"length":0,"stats":{"Line":0}},{"line":284,"address":[],"length":0,"stats":{"Line":0}},{"line":285,"address":[],"length":0,"stats":{"Line":0}},{"line":287,"address":[],"length":0,"stats":{"Line":0}},{"line":290,"address":[],"length":0,"stats":{"Line":0}},{"line":291,"address":[],"length":0,"stats":{"Line":0}},{"line":293,"address":[],"length":0,"stats":{"Line":0}},{"line":294,"address":[],"length":0,"stats":{"Line":0}},{"line":295,"address":[],"length":0,"stats":{"Line":0}},{"line":296,"address":[],"length":0,"stats":{"Line":0}},{"line":297,"address":[],"length":0,"stats":{"Line":0}},{"line":299,"address":[],"length":0,"stats":{"Line":0}},{"line":300,"address":[],"length":0,"stats":{"Line":0}},{"line":301,"address":[],"length":0,"stats":{"Line":0}},{"line":302,"address":[],"length":0,"stats":{"Line":0}},{"line":303,"address":[],"length":0,"stats":{"Line":0}},{"line":305,"address":[],"length":0,"stats":{"Line":0}},{"line":306,"address":[],"length":0,"stats":{"Line":0}},{"line":311,"address":[],"length":0,"stats":{"Line":0}},{"line":312,"address":[],"length":0,"stats":{"Line":0}},{"line":313,"address":[],"length":0,"stats":{"Line":0}},{"line":320,"address":[],"length":0,"stats":{"Line":0}},{"line":321,"address":[],"length":0,"stats":{"Line":0}},{"line":322,"address":[],"length":0,"stats":{"Line":0}},{"line":326,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":127},{"path":["/","Users","alexc","code","capp-rs","capp","src","manager","workers_manager.rs"],"content":"use super::WorkerId;\nuse crate::manager::{\n    worker_wrapper, Computation, WorkerCommand, WorkerOptions, WorkerOptionsBuilder,\n};\nuse capp_config::config::Configurable;\nuse capp_queue::queue::TaskQueue;\nuse derive_builder::Builder;\nuse serde::{de::DeserializeOwned, Serialize};\nuse std::{\n    collections::HashMap,\n    sync::{\n        atomic::{AtomicUsize, Ordering},\n        Arc, Mutex,\n    },\n};\nuse tokio::{\n    signal,\n    sync::{broadcast, mpsc},\n};\nuse tracing::Instrument;\n\ntype WorkerCommandSenders =\n    Arc\u003cMutex\u003cHashMap\u003cWorkerId, mpsc::Sender\u003cWorkerCommand\u003e\u003e\u003e\u003e;\n\n#[derive(Builder, Default, Clone, Debug)]\n#[builder(public, setter(into))]\npub struct WorkersManagerOptions {\n    #[builder(default = \"WorkerOptionsBuilder::default().build().unwrap()\")]\n    pub worker_options: WorkerOptions,\n    #[builder(default = \"None\")]\n    pub task_limit: Option\u003cu32\u003e,\n    #[builder(default = \"4\")]\n    pub concurrency_limit: usize,\n    #[builder(default = \"10\")]\n    pub no_task_found_delay_sec: usize,\n}\n\n// New WorkersManager struct\npub struct WorkersManager\u003cData, Comp, Ctx\u003e {\n    pub ctx: Arc\u003cCtx\u003e,\n    pub computation: Arc\u003cComp\u003e,\n    pub queue: Arc\u003cdyn TaskQueue\u003cData\u003e + Send + Sync\u003e,\n    pub options: WorkersManagerOptions,\n}\n\nimpl\u003cData, Comp, Ctx\u003e WorkersManager\u003cData, Comp, Ctx\u003e\nwhere\n    Data: Clone\n        + Serialize\n        + DeserializeOwned\n        + Send\n        + Sync\n        + 'static\n        + std::fmt::Debug,\n    Comp: Computation\u003cData, Ctx\u003e + Send + Sync + 'static,\n    Ctx: Configurable + Send + Sync + 'static,\n{\n    pub fn new(\n        ctx: Ctx,\n        computation: Comp,\n        queue: impl TaskQueue\u003cData\u003e + Send + Sync + 'static,\n        options: WorkersManagerOptions,\n    ) -\u003e Self {\n        Self {\n            ctx: Arc::new(ctx),\n            computation: Arc::new(computation),\n            queue: Arc::new(queue),\n            options,\n        }\n    }\n\n    pub fn new_from_arcs(\n        ctx: Arc\u003cCtx\u003e,\n        computation: Arc\u003cComp\u003e,\n        queue: Arc\u003cdyn TaskQueue\u003cData\u003e + Send + Sync\u003e,\n        options: WorkersManagerOptions,\n    ) -\u003e Self {\n        Self {\n            ctx,\n            computation,\n            queue,\n            options,\n        }\n    }\n\n    pub async fn run_workers(\u0026mut self) {\n        // This will start the workers and handle the shutdown signals\n        let mut worker_handlers = Vec::new();\n        let command_senders: WorkerCommandSenders =\n            Arc::new(Mutex::new(HashMap::new()));\n        let (terminate_sender, _) = broadcast::channel::\u003c()\u003e(10);\n\n        for i in 1..=self.options.concurrency_limit {\n            let worker_id = WorkerId::new(i);\n            let (command_sender, command_receiver) =\n                mpsc::channel::\u003cWorkerCommand\u003e(100);\n\n            command_senders\n                .lock()\n                .unwrap()\n                .insert(worker_id, command_sender);\n            let terminate_receiver = terminate_sender.subscribe();\n\n            let worker_span = tracing::info_span!(\"worker\", worker_id = %i);\n            let worker = tokio::spawn(worker_wrapper::\u003cData, Comp, Ctx\u003e(\n                WorkerId::new(i),\n                Arc::clone(\u0026self.ctx),\n                Arc::clone(\u0026self.queue),\n                Arc::clone(\u0026self.computation),\n                command_receiver,\n                terminate_receiver,\n                self.options.worker_options.clone(),\n            ))\n            .instrument(worker_span.clone());\n            worker_handlers.push(worker);\n        }\n\n        // Following part setup separate thread to catch ctrl+c\n        // signal. Single press will send Shutdown signal to all workers.\n        // next ctrl-c will terminate workers immediately.\n        self.ctrl_c_handler(command_senders, terminate_sender).await;\n\n        for (worker_id, handler) in worker_handlers.into_iter().enumerate() {\n            let worker_id = worker_id + 1;\n            match handler.await {\n                Ok(res) =\u003e {\n                    tracing::info!(\"[{}] Worker stopped: {:?}\", worker_id, res);\n                }\n                Err(err) =\u003e {\n                    tracing::error!(\n                        \"[{}] Fatal error in one of the workers: {:?}\",\n                        worker_id,\n                        err\n                    );\n                }\n            }\n        }\n\n        tracing::info!(\"All workers stopped\")\n    }\n\n    async fn ctrl_c_handler(\n        \u0026mut self,\n        command_senders: WorkerCommandSenders,\n        terminate_sender: tokio::sync::broadcast::Sender\u003c()\u003e,\n    ) {\n        let ctrl_c_counter = Arc::new(AtomicUsize::new(0));\n\n        // Setup signal handling\n        let signal_counter = ctrl_c_counter.clone();\n        let command_senders = command_senders.clone();\n\n        tokio::spawn(async move {\n            loop {\n                signal::ctrl_c()\n                    .await\n                    .expect(\"Failed to listen for ctrl+c event\");\n                let count = signal_counter.fetch_add(1, Ordering::SeqCst);\n\n                match count {\n                    0 =\u003e {\n                        // First Ctrl+C: Attempt to gracefully stop all workers.\n                        tracing::warn!(\n                        \"Ctrl+C received, sending stop command to all workers...\"\n                    );\n                        let senders: Vec\u003c_\u003e = {\n                            let lock = command_senders.lock().unwrap();\n                            lock.values().cloned().collect()\n                        };\n                        for sender in senders {\n                            let _ = sender.send(WorkerCommand::Shutdown).await;\n                        }\n                    }\n                    _ =\u003e {\n                        // Second Ctrl+C: Force terminate all workers.\n                        tracing::warn!(\n                            \"Ctrl+C received again, terminating all workers...\"\n                        );\n                        terminate_sender.send(()).unwrap();\n                        break;\n                    }\n                }\n            }\n        });\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn excutor_options_builder() {\n        let options = WorkersManagerOptionsBuilder::default().build().unwrap();\n        assert_eq!(options.concurrency_limit, 4);\n    }\n}\n","traces":[{"line":58,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":147,"address":[],"length":0,"stats":{"Line":0}},{"line":150,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":160,"address":[],"length":0,"stats":{"Line":0}},{"line":161,"address":[],"length":0,"stats":{"Line":0}},{"line":163,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":170,"address":[],"length":0,"stats":{"Line":0}},{"line":171,"address":[],"length":0,"stats":{"Line":0}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":176,"address":[],"length":0,"stats":{"Line":0}},{"line":177,"address":[],"length":0,"stats":{"Line":0}},{"line":179,"address":[],"length":0,"stats":{"Line":0}},{"line":180,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":64},{"path":["/","Users","alexc","code","capp-rs","capp","src","manager.rs"],"content":"pub mod computation;\npub mod handler;\npub mod stats;\npub mod worker;\npub mod workers_manager;\n\npub use computation::{Computation, ComputationError};\npub use handler::TaskHandler;\npub use stats::{SharedStats, WorkerStats};\npub use worker::{\n    worker_wrapper, Worker, WorkerCommand, WorkerId, WorkerOptions,\n    WorkerOptionsBuilder, WorkerOptionsBuilderError,\n};\npub use workers_manager::{\n    WorkersManager, WorkersManagerOptions, WorkersManagerOptionsBuilder,\n    WorkersManagerOptionsBuilderError,\n};\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","capp","src","prelude.rs"],"content":"pub use crate::manager::*;\n#[cfg(feature = \"http\")]\npub use capp_config::http::*;\n#[cfg(feature = \"http\")]\npub use capp_config::proxy::*;\npub use capp_config::router::*;\npub use capp_config::*;\npub use capp_queue::queue::*;\npub use capp_queue::task::*;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","capp-config","src","config.rs"],"content":"use std::{\n    fs,\n    io::{self, BufRead},\n    path,\n};\n\n#[derive(thiserror::Error, Debug)]\npub enum ConfigError {\n    #[error(\"IO error: {0}\")]\n    Io(#[from] std::io::Error),\n    #[error(\"YAML parsing error: {0}\")]\n    YamlParse(#[from] serde_yaml::Error),\n    #[error(\"Line parsing error: {0}\")]\n    LineParse(String),\n}\n\npub trait Configurable {\n    fn config(\u0026self) -\u003e \u0026serde_yaml::Value;\n\n    // read configuration from yaml config\n    fn load_config(\n        config_file_path: impl AsRef\u003cpath::Path\u003e,\n    ) -\u003e Result\u003cserde_yaml::Value, ConfigError\u003e {\n        let content: String = fs::read_to_string(config_file_path)?;\n        let config: serde_yaml::Value = serde_yaml::from_str(\u0026content)?;\n        Ok(config)\n    }\n\n    /// Load Vec\u003cString\u003e from file with path `file path`\n    fn load_text_file_lines(\n        file_path: impl AsRef\u003cpath::Path\u003e,\n    ) -\u003e Result\u003cVec\u003cString\u003e, ConfigError\u003e {\n        let file = fs::File::open(file_path)?;\n        let lines = io::BufReader::new(file)\n            .lines()\n            .map(|l| l.map_err(|e| ConfigError::LineParse(e.to_string())))\n            .collect::\u003cResult\u003cVec\u003c_\u003e, _\u003e\u003e()?;\n        Ok(lines)\n    }\n\n    fn load_text_file_content(\n        file_path: impl AsRef\u003cpath::Path\u003e,\n    ) -\u003e Result\u003cString, io::Error\u003e {\n        fs::read_to_string(file_path)\n    }\n\n    /// Extract Value from config using dot notation i.e. \"app.concurrency\"\n    fn get_config_value(\u0026self, key: \u0026str) -\u003e Option\u003c\u0026serde_yaml::Value\u003e {\n        let keys: Vec\u003c\u0026str\u003e = key.split('.').collect();\n        Self::get_value_recursive(self.config(), \u0026keys)\n    }\n\n    fn get_value_recursive\u003c'a\u003e(\n        config: \u0026'a serde_yaml::Value,\n        keys: \u0026[\u0026str],\n    ) -\u003e Option\u003c\u0026'a serde_yaml::Value\u003e {\n        if keys.is_empty() {\n            return None;\n        };\n\n        match config {\n            serde_yaml::Value::Mapping(map) =\u003e {\n                let key = keys[0];\n                let remaining_keys = \u0026keys[1..];\n\n                if let Some(value) =\n                    map.get(serde_yaml::Value::String(key.to_string()))\n                {\n                    if remaining_keys.is_empty() {\n                        Some(value)\n                    } else {\n                        Self::get_value_recursive(value, remaining_keys)\n                    }\n                } else {\n                    None\n                }\n            }\n            _ =\u003e None,\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::fs::File;\n    use std::io::Write;\n    use tempfile::tempdir;\n\n    pub struct TestApp {\n        config: serde_yaml::Value,\n        user_agents: Option\u003cVec\u003cString\u003e\u003e,\n    }\n\n    impl Configurable for TestApp {\n        fn config(\u0026self) -\u003e \u0026serde_yaml::Value {\n            \u0026self.config\n        }\n    }\n\n    impl TestApp {\n        fn from_config(config_file_path: impl AsRef\u003cpath::Path\u003e) -\u003e Self {\n            let config = Self::load_config(config_file_path);\n            Self {\n                config: config.unwrap(),\n                user_agents: None,\n            }\n        }\n\n        fn load_uas(\u0026mut self, uas_file_path: impl AsRef\u003cpath::Path\u003e) {\n            self.user_agents = Self::load_text_file_lines(uas_file_path).ok();\n        }\n    }\n\n    #[test]\n    fn test_load_config() {\n        let config_path = \"../tests/simple_config.yml\";\n        let app = TestApp::from_config(config_path);\n\n        assert_eq!(app.config[\"app\"][\"threads\"].as_u64(), Some(4));\n        assert_eq!(app.config()[\"app\"][\"max_queue\"].as_u64(), Some(500));\n        assert_eq!(app.user_agents, None);\n    }\n\n    #[test]\n    fn test_load_config_valid_yaml() {\n        let dir = tempdir().unwrap();\n        let config_path = dir.path().join(\"config.yml\");\n        let mut file = File::create(\u0026config_path).unwrap();\n        writeln!(file, \"key: value\\napp:\\n  setting: 42\").unwrap();\n\n        let config = TestApp::load_config(\u0026config_path);\n        assert!(config.is_ok());\n        let config = config.unwrap();\n        assert_eq!(config[\"key\"].as_str(), Some(\"value\"));\n        assert_eq!(config[\"app\"][\"setting\"].as_i64(), Some(42));\n    }\n\n    #[test]\n    fn test_load_config_invalid_yaml() {\n        let dir = tempdir().unwrap();\n        let config_path = dir.path().join(\"config.yml\");\n        let mut file = File::create(\u0026config_path).unwrap();\n        writeln!(file, \"invalid: : yaml: content\").unwrap();\n\n        let config = TestApp::load_config(\u0026config_path);\n        assert!(matches!(config, Err(ConfigError::YamlParse(_))));\n    }\n\n    #[test]\n    fn test_load_text_file_lines() {\n        let dir = tempdir().unwrap();\n        let file_path = dir.path().join(\"test.txt\");\n        let mut file = File::create(\u0026file_path).unwrap();\n        writeln!(file, \"line1\\nline2\\nline3\").unwrap();\n\n        let lines = TestApp::load_text_file_lines(\u0026file_path);\n        assert!(lines.is_ok());\n        let lines = lines.unwrap();\n        assert_eq!(lines, vec![\"line1\", \"line2\", \"line3\"]);\n    }\n\n    #[test]\n    fn test_get_config_value_empty_keys() {\n        let config_path = \"../tests/simple_config.yml\";\n        let app = TestApp::from_config(config_path);\n        assert_eq!(app.get_config_value(\"\"), None);\n    }\n\n    #[test]\n    fn test_get_config_value() {\n        let config_path = \"../tests/simple_config.yml\";\n        let app = TestApp::from_config(config_path);\n\n        assert_eq!(\n            app.get_config_value(\"logging.log_to_redis\")\n                .unwrap()\n                .as_bool(),\n            Some(true)\n        )\n    }\n\n    #[test]\n    fn test_get_config_value_recursive() {\n        let yaml = r#\"\n        app:\n          nested:\n            value: 42\n        \"#;\n        let config: serde_yaml::Value = serde_yaml::from_str(yaml).unwrap();\n        let app = TestApp {\n            config,\n            user_agents: None,\n        };\n\n        assert_eq!(\n            app.get_config_value(\"app.nested.value\")\n                .and_then(|v| v.as_i64()),\n            Some(42)\n        );\n        assert_eq!(app.get_config_value(\"app.missing.value\"), None);\n        assert_eq!(app.get_config_value(\"missing\"), None);\n    }\n\n    #[test]\n    fn test_load_lines() {\n        let config_path = \"../tests/simple_config.yml\";\n        let mut app = TestApp::from_config(config_path);\n        let uas_file_path = {\n            app.get_config_value(\"app.user_agents_file\")\n                .unwrap()\n                .as_str()\n                .unwrap()\n                .to_owned()\n        };\n        app.load_uas(\u0026uas_file_path);\n    }\n}\n","traces":[{"line":11,"address":[],"length":0,"stats":{"Line":3}},{"line":14,"address":[],"length":0,"stats":{"Line":6}},{"line":15,"address":[],"length":0,"stats":{"Line":0}},{"line":16,"address":[],"length":0,"stats":{"Line":0}},{"line":20,"address":[],"length":0,"stats":{"Line":1}},{"line":23,"address":[],"length":0,"stats":{"Line":2}},{"line":24,"address":[],"length":0,"stats":{"Line":0}},{"line":26,"address":[],"length":0,"stats":{"Line":0}},{"line":29,"address":[],"length":0,"stats":{"Line":0}},{"line":32,"address":[],"length":0,"stats":{"Line":0}},{"line":35,"address":[],"length":0,"stats":{"Line":0}},{"line":39,"address":[],"length":0,"stats":{"Line":2}},{"line":40,"address":[],"length":0,"stats":{"Line":2}},{"line":41,"address":[],"length":0,"stats":{"Line":2}},{"line":44,"address":[],"length":0,"stats":{"Line":4}},{"line":48,"address":[],"length":0,"stats":{"Line":4}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":52,"address":[],"length":0,"stats":{"Line":4}},{"line":53,"address":[],"length":0,"stats":{"Line":4}},{"line":54,"address":[],"length":0,"stats":{"Line":4}},{"line":55,"address":[],"length":0,"stats":{"Line":4}},{"line":57,"address":[],"length":0,"stats":{"Line":4}},{"line":58,"address":[],"length":0,"stats":{"Line":0}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":2}},{"line":63,"address":[],"length":0,"stats":{"Line":2}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}}],"covered":16,"coverable":28},{"path":["/","Users","alexc","code","capp-rs","capp-config","src","healthcheck.rs"],"content":"use reqwest::{Client, StatusCode};\nuse serde_json::Value;\nuse tokio::time::{timeout, Duration};\n\n// const GOOGLE: \u0026str = \"http://www.google.com\";\n\n/// Check if internet is available.\n/// There are a few hosts that are commonly used to check it\n/// because they are typically reliable and have high uptime. i\n/// Examples:\n///     - Google's primary domain: https://www.google.com\n///     - Cloudflare's DNS resolver: https://1.1.1.1\n///     - Quad9's DNS resolver: https://9.9.9.9\npub async fn internet(http_url: \u0026str) -\u003e bool {\n    let client = Client::new();\n    let request_future = client.get(http_url).send();\n\n    let response = match timeout(Duration::from_secs(1), request_future).await {\n        Ok(response) =\u003e response.unwrap(),\n        Err(_) =\u003e {\n            tracing::error!(\n                \"Internet healthcheck request timed out: {}\",\n                StatusCode::REQUEST_TIMEOUT\n            );\n            return false;\n        }\n    };\n\n    if response.status() == StatusCode::NOT_FOUND\n        \u0026\u0026 response.content_length() == Some(9)\n    {\n        return true;\n    }\n\n    tracing::error!(\n        \"Internet healthcheck unexpected response status or content length: {:?}\",\n        response\n    );\n    false\n}\n\npub async fn test_proxy(proxy_url: \u0026str) -\u003e bool {\n    let client = Client::new();\n    let proxy_client = Client::builder()\n        .proxy(reqwest::Proxy::all(proxy_url).unwrap())\n        .build()\n        .unwrap();\n\n    let ip_check_url = \"https://httpbin.org/ip\";\n\n    // Get local IP\n    let local_ip = match get_ip(\u0026client, ip_check_url).await {\n        Ok(ip) =\u003e ip,\n        Err(_) =\u003e return false,\n    };\n\n    // Get IP through proxy\n    let proxy_ip = match get_ip(\u0026proxy_client, ip_check_url).await {\n        Ok(ip) =\u003e ip,\n        Err(_) =\u003e return false,\n    };\n\n    // Compare IPs\n    local_ip != proxy_ip\n}\n\nasync fn get_ip(client: \u0026Client, url: \u0026str) -\u003e Result\u003cString, reqwest::Error\u003e {\n    let response = client.get(url).send().await?;\n    let body: Value = response.json().await?;\n    Ok(body[\"origin\"].as_str().unwrap_or(\"\").to_string())\n}\n","traces":[{"line":14,"address":[],"length":0,"stats":{"Line":0}},{"line":15,"address":[],"length":0,"stats":{"Line":0}},{"line":16,"address":[],"length":0,"stats":{"Line":0}},{"line":18,"address":[],"length":0,"stats":{"Line":0}},{"line":19,"address":[],"length":0,"stats":{"Line":0}},{"line":21,"address":[],"length":0,"stats":{"Line":0}},{"line":22,"address":[],"length":0,"stats":{"Line":0}},{"line":25,"address":[],"length":0,"stats":{"Line":0}},{"line":29,"address":[],"length":0,"stats":{"Line":0}},{"line":30,"address":[],"length":0,"stats":{"Line":0}},{"line":32,"address":[],"length":0,"stats":{"Line":0}},{"line":35,"address":[],"length":0,"stats":{"Line":0}},{"line":36,"address":[],"length":0,"stats":{"Line":0}},{"line":39,"address":[],"length":0,"stats":{"Line":0}},{"line":42,"address":[],"length":0,"stats":{"Line":0}},{"line":43,"address":[],"length":0,"stats":{"Line":0}},{"line":44,"address":[],"length":0,"stats":{"Line":0}},{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":52,"address":[],"length":0,"stats":{"Line":0}},{"line":53,"address":[],"length":0,"stats":{"Line":0}},{"line":54,"address":[],"length":0,"stats":{"Line":0}},{"line":58,"address":[],"length":0,"stats":{"Line":0}},{"line":59,"address":[],"length":0,"stats":{"Line":0}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":64,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":30},{"path":["/","Users","alexc","code","capp-rs","capp-config","src","http.rs"],"content":"//! HTTP client module for making web requests with configurable proxy support.\n//!\n//! This module provides functionality for building and configuring HTTP clients with\n//! features such as:\n//! - Configurable proxy support with port range expansion\n//! - Timeout settings\n//! - User agent customization\n//! - Retry mechanisms with exponential backoff\n//!\n//! # Example\n//! ```no_run\n//! use capp_config::http::{HttpClientParams, build_http_client};\n//! use serde_yaml::Value;\n//!\n//! let config: Value = serde_yaml::from_str(r#\"\n//! http:\n//!     proxy:\n//!         use: true\n//!         uri: http://proxy.example.com:{8080-8082}\n//!     timeout: 30\n//!     connect_timeout: 10\n//! \"#).unwrap();\n//!\n//! let params = HttpClientParams::from_config(\u0026config[\"http\"], \"my-crawler/1.0\");\n//! let client = build_http_client(params).unwrap();\n//! ```\nuse crate::proxy::{ProxyProvider, RandomProxyProvider};\nuse backoff::ExponentialBackoffBuilder;\n\n/// Parameters for configuring an HTTP client.\n///\n/// This struct holds all configuration needed to build a customized HTTP client,\n/// including timeout settings, proxy configuration, and user agent string.\n#[derive(Debug)]\npub struct HttpClientParams\u003c'a\u003e {\n    pub timeout: u64,\n    pub connect_timeout: u64,\n    pub proxy_provider: Option\u003cBox\u003cdyn ProxyProvider + Send + Sync\u003e\u003e,\n    pub user_agent: \u0026'a str,\n}\n\nimpl\u003c'a\u003e HttpClientParams\u003c'a\u003e {\n    /// Creates an HttpClientParams instance from a YAML configuration.\n    ///\n    /// The configuration should follow this structure:\n    /// ```yaml\n    /// http:\n    ///     proxy:\n    ///         use: true\n    ///         uri: http://user:pass@proxy.example.com:8080\n    ///     timeout: 30\n    ///     connect_timeout: 10\n    /// ```\n    ///\n    /// The proxy URI can include a port range using the format:\n    /// `http://proxy.example.com:{8080-8090}`\n    ///\n    /// # Arguments\n    /// * `http_config` - YAML configuration containing HTTP settings\n    /// * `user_agent` - User agent string to be used in requests\n    ///\n    /// # Panics\n    /// Panics if required configuration fields are missing (timeout, connect_timeout)\n    pub fn from_config(\n        http_config: \u0026serde_yaml::Value,\n        user_agent: \u0026'a str,\n    ) -\u003e Self {\n        let timeout = http_config[\"timeout\"]\n            .as_u64()\n            .expect(\"No timeout field in config\");\n        let connect_timeout = http_config[\"connect_timeout\"]\n            .as_u64()\n            .expect(\"No connect_timeout field in config\");\n\n        let proxy_provider =\n            if http_config[\"proxy\"][\"use\"].as_bool().unwrap_or(false) {\n                Some(Box::new(\n                    RandomProxyProvider::from_config(\u0026http_config[\"proxy\"])\n                        .expect(\"Failed to create proxy provider\"),\n                ) as Box\u003cdyn ProxyProvider + Send + Sync\u003e)\n            } else {\n                None\n            };\n\n        Self {\n            timeout,\n            connect_timeout,\n            proxy_provider,\n            user_agent,\n        }\n    }\n}\n\n/// Builds an HTTP client with the specified parameters.\n///\n/// Creates a reqwest::Client configured with:\n/// - TLS settings\n/// - Timeout configurations\n/// - User agent\n/// - Optional proxy support\n///\n/// # Arguments\n/// * `params` - Configuration parameters for the client\n///\n/// # Returns\n/// A Result containing either the configured client or an error\npub fn build_http_client(\n    params: HttpClientParams,\n) -\u003e Result\u003creqwest::Client, reqwest::Error\u003e {\n    let mut client_builder = reqwest::ClientBuilder::new()\n        .use_rustls_tls()\n        .danger_accept_invalid_certs(true)\n        .timeout(std::time::Duration::from_secs(params.timeout))\n        .connect_timeout(std::time::Duration::from_secs(params.connect_timeout))\n        .user_agent(params.user_agent);\n\n    if let Some(proxy_provider) = params.proxy_provider {\n        if let Some(proxy_uri) = proxy_provider.get_proxy() {\n            client_builder = client_builder.proxy(\n                reqwest::Proxy::all(\u0026proxy_uri).expect(\"Failed to create proxy\"),\n            );\n        }\n    }\n\n    client_builder.build()\n}\n\n/// Fetches a URL with automatic retries.\n///\n/// Makes a GET request to the specified URL, automatically retrying on failure\n/// using exponential backoff. This method only retrieves headers and status,\n/// not the response body.\n///\n/// # Arguments\n/// * `client` - The HTTP client to use for the request\n/// * `url` - The URL to fetch\n///\n/// # Returns\n/// A Result containing either the response or an error\npub async fn fetch_url(\n    client: reqwest::Client,\n    url: \u0026str,\n) -\u003e Result\u003creqwest::Response, reqwest::Error\u003e {\n    let backoff = ExponentialBackoffBuilder::new()\n        .with_max_interval(std::time::Duration::from_secs(10))\n        .build();\n    backoff::future::retry(backoff, || async { Ok(client.get(url).send().await?) })\n        .await\n}\n\n/// Fetches content from a URL with automatic retries.\n///\n/// Makes a GET request to the specified URL and retrieves the full response body,\n/// automatically retrying on failure using exponential backoff.\n///\n/// # Arguments\n/// * `client` - The HTTP client to use for the request\n/// * `url` - The URL to fetch\n///\n/// # Returns\n/// A Result containing either a tuple of (StatusCode, response_body) or an error\npub async fn fetch_url_content(\n    client: reqwest::Client,\n    url: \u0026str,\n) -\u003e Result\u003c(reqwest::StatusCode, String), reqwest::Error\u003e {\n    let backoff = ExponentialBackoffBuilder::new()\n        .with_max_interval(std::time::Duration::from_secs(10))\n        .with_max_elapsed_time(Some(std::time::Duration::from_secs(30)))\n        .build();\n\n    let fetch_content = || async {\n        let response = client.get(url).send().await?;\n        let status = response.status();\n        let text = response.text().await?;\n        Ok((status, text))\n    };\n\n    backoff::future::retry(backoff, fetch_content).await\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use serde_yaml::Value;\n    use std::collections::HashSet;\n    use std::time::Duration;\n\n    const YAML_CONF_SINGLE_PORT: \u0026str = r#\"\n    http:\n        proxy:\n            use: true\n            uri: http://proxy1.example.com:8080\n        timeout: 30\n        connect_timeout: 10\n    \"#;\n\n    const YAML_CONF_PORT_RANGE: \u0026str = r#\"\n    http:\n        proxy:\n            use: true\n            uri: http://proxy1.example.com:{8080-8082}\n        timeout: 30\n        connect_timeout: 10\n    \"#;\n\n    const YAML_CONF_MULTIPLE_PORT_RANGES: \u0026str = r#\"\n    http:\n        proxy:\n            use: true\n            uris:\n                - http://proxy1.example.com:{8080-8082}\n                - http://proxy2.example.com:9090\n                - http://proxy3.example.com:{9000-9001}\n        timeout: 30\n        connect_timeout: 10\n    \"#;\n\n    const YAML_CONF_TEXT: \u0026str = r#\"\n    http:\n      proxy:\n        use: true\n        uri: http://bro:admin@proxygate1.com:42042\n      timeout: 30\n      connect_timeout: 10\n    \"#;\n\n    const WRONG_YAML_CONF_TEXT: \u0026str = r#\"\n    http:\n      proxy:\n        use: true\n        uri: http://bro:admin@proxygate1.com:42042\n      connect_timeout: 10\n    \"#;\n\n    #[test]\n    fn test_build_client() {\n        let client = build_http_client(HttpClientParams {\n            timeout: 10,\n            connect_timeout: 5,\n            proxy_provider: None,\n            user_agent: \"hello\",\n        });\n\n        assert!(client.is_ok());\n    }\n\n    #[test]\n    fn test_build_client_from_config() {\n        let config: serde_yaml::Value =\n            serde_yaml::from_str(YAML_CONF_TEXT).unwrap();\n        let client = build_http_client(HttpClientParams::from_config(\n            config.get(\"http\").unwrap(),\n            \"hellobot\",\n        ));\n        assert!(client.is_ok());\n    }\n\n    #[test]\n    #[should_panic(expected = \"No timeout field in config\")]\n    fn test_build_client_bad_config() {\n        let config: serde_yaml::Value =\n            serde_yaml::from_str(WRONG_YAML_CONF_TEXT).unwrap();\n        let _ = build_http_client(HttpClientParams::from_config(\n            config.get(\"http\").unwrap(),\n            \"hellobot\",\n        ));\n    }\n\n    #[test]\n    fn test_http_client_single_port() {\n        let config: Value = serde_yaml::from_str(YAML_CONF_SINGLE_PORT).unwrap();\n        let client_params =\n            HttpClientParams::from_config(\u0026config[\"http\"], \"test-agent/1.0\");\n\n        assert_eq!(client_params.timeout, 30);\n        assert_eq!(client_params.connect_timeout, 10);\n\n        if let Some(provider) = client_params.proxy_provider {\n            let proxy = provider.get_proxy().unwrap();\n            assert_eq!(proxy, \"http://proxy1.example.com:8080\");\n        } else {\n            panic!(\"Expected proxy provider to be configured\");\n        }\n    }\n\n    #[test]\n    fn test_http_client_port_range() {\n        let config: Value = serde_yaml::from_str(YAML_CONF_PORT_RANGE).unwrap();\n        let client_params =\n            HttpClientParams::from_config(\u0026config[\"http\"], \"test-agent/1.0\");\n\n        let mut seen_ports = HashSet::new();\n        if let Some(provider) = client_params.proxy_provider {\n            // Test multiple calls to verify different ports are used\n            for _ in 0..10 {\n                let proxy = provider.get_proxy().unwrap();\n                let port = extract_port_from_proxy_url(\u0026proxy);\n                seen_ports.insert(port);\n            }\n        }\n\n        // Should see all three ports from range 8080-8082\n        assert_eq!(seen_ports.len(), 3);\n        assert!(seen_ports.contains(\u00268080));\n        assert!(seen_ports.contains(\u00268081));\n        assert!(seen_ports.contains(\u00268082));\n    }\n\n    #[test]\n    fn test_http_client_multiple_port_ranges() {\n        let config: Value =\n            serde_yaml::from_str(YAML_CONF_MULTIPLE_PORT_RANGES).unwrap();\n        let client_params =\n            HttpClientParams::from_config(\u0026config[\"http\"], \"test-agent/1.0\");\n\n        let mut seen_proxies = HashSet::new();\n        if let Some(provider) = client_params.proxy_provider {\n            // Test multiple calls to verify different proxies are used\n            for _ in 0..20 {\n                let proxy = provider.get_proxy().unwrap();\n                seen_proxies.insert(proxy);\n            }\n        }\n\n        // Should see:\n        // 3 ports from proxy1 (8080-8082)\n        // 1 from proxy2 (9090)\n        // 2 from proxy3 (9000-9001)\n        assert_eq!(seen_proxies.len(), 6);\n\n        // Verify specific proxy patterns\n        assert!(seen_proxies\n            .iter()\n            .any(|p| p == \"http://proxy1.example.com:8080\"));\n        assert!(seen_proxies\n            .iter()\n            .any(|p| p == \"http://proxy1.example.com:8081\"));\n        assert!(seen_proxies\n            .iter()\n            .any(|p| p == \"http://proxy1.example.com:8082\"));\n        assert!(seen_proxies\n            .iter()\n            .any(|p| p == \"http://proxy2.example.com:9090\"));\n        assert!(seen_proxies\n            .iter()\n            .any(|p| p == \"http://proxy3.example.com:9000\"));\n        assert!(seen_proxies\n            .iter()\n            .any(|p| p == \"http://proxy3.example.com:9001\"));\n    }\n\n    #[test]\n    fn test_http_client_builder_timeouts_are_set() {\n        let config: Value = serde_yaml::from_str(YAML_CONF_PORT_RANGE).unwrap();\n        let client_params =\n            HttpClientParams::from_config(\u0026config[\"http\"], \"test-agent/1.0\");\n\n        assert_eq!(client_params.timeout, Duration::from_secs(30).as_secs());\n        assert_eq!(\n            client_params.connect_timeout,\n            Duration::from_secs(10).as_secs()\n        );\n    }\n\n    #[test]\n    fn test_proxy_disabled() {\n        let yaml = r#\"\n        http:\n            proxy:\n                use: false\n                uri: http://proxy1.example.com:8080\n            timeout: 30\n            connect_timeout: 10\n        \"#;\n\n        let config: Value = serde_yaml::from_str(yaml).unwrap();\n        let client_params =\n            HttpClientParams::from_config(\u0026config[\"http\"], \"test-agent/1.0\");\n\n        assert!(\n            client_params.proxy_provider.is_none(),\n            \"Proxy provider should be None when disabled\"\n        );\n    }\n\n    #[test]\n    #[should_panic(expected = \"No timeout field in config\")]\n    fn test_missing_timeout() {\n        let yaml = r#\"\n        http:\n            proxy:\n                use: true\n                uri: http://proxy1.example.com:8080\n            connect_timeout: 10\n        \"#;\n\n        let config: Value = serde_yaml::from_str(yaml).unwrap();\n        let _ = HttpClientParams::from_config(\u0026config[\"http\"], \"test-agent/1.0\");\n    }\n\n    #[test]\n    fn test_invalid_port_range() {\n        let yaml = r#\"\n        http:\n            proxy:\n                use: true\n                uri: http://proxy1.example.com:{8082-8080}\n            timeout: 30\n            connect_timeout: 10\n        \"#;\n\n        let config: Value = serde_yaml::from_str(yaml).unwrap();\n        let client_params =\n            HttpClientParams::from_config(\u0026config[\"http\"], \"test-agent/1.0\");\n\n        if let Some(provider) = client_params.proxy_provider {\n            let proxy = provider.get_proxy().unwrap();\n            // Should treat invalid range as literal string\n            assert_eq!(proxy, \"http://proxy1.example.com:{8082-8080}\");\n        }\n    }\n\n    // Helper function to extract port number from proxy URL\n    fn extract_port_from_proxy_url(url: \u0026str) -\u003e u16 {\n        let parts: Vec\u003c\u0026str\u003e = url.split(':').collect();\n        parts.last().unwrap().parse().unwrap()\n    }\n}\n","traces":[{"line":64,"address":[],"length":0,"stats":{"Line":9}},{"line":68,"address":[],"length":0,"stats":{"Line":9}},{"line":71,"address":[],"length":0,"stats":{"Line":9}},{"line":75,"address":[],"length":0,"stats":{"Line":9}},{"line":76,"address":[],"length":0,"stats":{"Line":9}},{"line":77,"address":[],"length":0,"stats":{"Line":6}},{"line":78,"address":[],"length":0,"stats":{"Line":6}},{"line":79,"address":[],"length":0,"stats":{"Line":6}},{"line":80,"address":[],"length":0,"stats":{"Line":6}},{"line":82,"address":[],"length":0,"stats":{"Line":3}},{"line":107,"address":[],"length":0,"stats":{"Line":2}},{"line":110,"address":[],"length":0,"stats":{"Line":2}},{"line":113,"address":[],"length":0,"stats":{"Line":2}},{"line":114,"address":[],"length":0,"stats":{"Line":2}},{"line":115,"address":[],"length":0,"stats":{"Line":2}},{"line":117,"address":[],"length":0,"stats":{"Line":3}},{"line":118,"address":[],"length":0,"stats":{"Line":2}},{"line":119,"address":[],"length":0,"stats":{"Line":1}},{"line":120,"address":[],"length":0,"stats":{"Line":1}},{"line":125,"address":[],"length":0,"stats":{"Line":2}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":147,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":0}},{"line":162,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":171,"address":[],"length":0,"stats":{"Line":0}},{"line":172,"address":[],"length":0,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":0}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":0}},{"line":178,"address":[],"length":0,"stats":{"Line":0}}],"covered":20,"coverable":35},{"path":["/","Users","alexc","code","capp-rs","capp-config","src","lib.rs"],"content":"pub mod config;\n#[cfg(feature = \"http\")]\npub mod healthcheck;\npub mod http;\npub mod proxy;\npub mod router;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","capp-config","src","proxy.rs"],"content":"use rand::seq::SliceRandom;\nuse rand::thread_rng;\nuse regex::Regex;\nuse serde::{Deserialize, Serialize};\nuse std::fmt;\nuse std::sync::{LazyLock, Mutex};\n\n// Add Debug to the trait bounds\npub trait ProxyProvider: Send + Sync + fmt::Debug {\n    fn get_proxy(\u0026self) -\u003e Option\u003cString\u003e;\n}\n\nstatic PORT_RANGE_RE: LazyLock\u003cRegex\u003e = LazyLock::new(|| {\n    Regex::new(r\"\\{(\\d+)-(\\d+)\\}\").expect(\"Failed to compile port range regex\")\n});\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ProxyConfig {\n    pub use_proxy: bool,\n    pub uris: Vec\u003cString\u003e,\n}\n\nimpl ProxyConfig {\n    fn expand_uri(uri: \u0026str) -\u003e Vec\u003cString\u003e {\n        if let Some(captures) = PORT_RANGE_RE.captures(uri) {\n            if let (Some(start), Some(end)) = (\n                captures.get(1).and_then(|m| m.as_str().parse::\u003cu16\u003e().ok()),\n                captures.get(2).and_then(|m| m.as_str().parse::\u003cu16\u003e().ok()),\n            ) {\n                if start \u003c= end {\n                    return (start..=end)\n                        .map(|port| uri.replace(\u0026captures[0], \u0026port.to_string()))\n                        .collect();\n                }\n            }\n        }\n        vec![uri.to_string()]\n    }\n\n    pub fn from_config(config: \u0026serde_yaml::Value) -\u003e Option\u003cSelf\u003e {\n        let use_proxy = config[\"use\"].as_bool()?;\n        let uris = if use_proxy {\n            match config[\"uris\"].as_sequence() {\n                Some(seq) =\u003e seq\n                    .iter()\n                    .filter_map(|v| v.as_str())\n                    .flat_map(Self::expand_uri)\n                    .collect(),\n                None =\u003e {\n                    if let Some(uri) = config[\"uri\"].as_str() {\n                        Self::expand_uri(uri)\n                    } else {\n                        vec![]\n                    }\n                }\n            }\n        } else {\n            vec![]\n        };\n\n        Some(ProxyConfig { use_proxy, uris })\n    }\n}\n\n#[derive(Debug)]\npub struct RandomProxyProvider {\n    config: ProxyConfig,\n}\n\nimpl RandomProxyProvider {\n    pub fn new(config: ProxyConfig) -\u003e Self {\n        Self { config }\n    }\n\n    pub fn from_config(config: \u0026serde_yaml::Value) -\u003e Option\u003cSelf\u003e {\n        let config = ProxyConfig::from_config(config)?;\n        Some(Self::new(config))\n    }\n}\n\nimpl ProxyProvider for RandomProxyProvider {\n    fn get_proxy(\u0026self) -\u003e Option\u003cString\u003e {\n        if !self.config.use_proxy || self.config.uris.is_empty() {\n            return None;\n        }\n\n        // Create a new thread_rng for each call\n        let mut rng = thread_rng();\n        self.config.uris.choose(\u0026mut rng).cloned()\n    }\n}\n\n// Round robin implementation\n#[derive(Debug)]\npub struct RoundRobinProxyProvider {\n    config: ProxyConfig,\n    current: Mutex\u003cusize\u003e,\n}\n\nimpl RoundRobinProxyProvider {\n    pub fn new(config: ProxyConfig) -\u003e Self {\n        Self {\n            config,\n            current: Mutex::new(0),\n        }\n    }\n\n    pub fn from_config(config: \u0026serde_yaml::Value) -\u003e Option\u003cSelf\u003e {\n        let config = ProxyConfig::from_config(config)?;\n        Some(Self::new(config))\n    }\n}\n\nimpl ProxyProvider for RoundRobinProxyProvider {\n    fn get_proxy(\u0026self) -\u003e Option\u003cString\u003e {\n        if !self.config.use_proxy || self.config.uris.is_empty() {\n            return None;\n        }\n\n        let mut current = self.current.lock().ok()?;\n        let proxy = self.config.uris[*current].clone();\n        *current = (*current + 1) % self.config.uris.len();\n        Some(proxy)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use serde_yaml::Value;\n\n    const YAML_CONF_SINGLE: \u0026str = r#\"\n    proxy:\n        use: true\n        uri: http://proxy1.example.com:8080\n        timeout: 30\n        connect_timeout: 10\n    \"#;\n\n    const YAML_CONF_MULTIPLE: \u0026str = r#\"\n    proxy:\n        use: true\n        uris:\n            - http://proxy1.example.com:8080\n            - http://proxy2.example.com:8080\n            - http://proxy3.example.com:8080\n        timeout: 30\n        connect_timeout: 10\n    \"#;\n\n    #[test]\n    fn test_proxy_provider() {\n        let config: Value = serde_yaml::from_str(YAML_CONF_SINGLE).unwrap();\n        let provider = RandomProxyProvider::from_config(\u0026config[\"proxy\"]).unwrap();\n\n        let proxy_url = provider.get_proxy().unwrap();\n        assert!(proxy_url.as_str() == \"http://proxy1.example.com:8080\");\n    }\n\n    #[test]\n    fn test_random_proxy_provider() {\n        let config: Value = serde_yaml::from_str(YAML_CONF_MULTIPLE).unwrap();\n        let provider = RandomProxyProvider::from_config(\u0026config[\"proxy\"]).unwrap();\n\n        // Test multiple calls return different proxies\n        let mut seen = std::collections::HashSet::new();\n        for _ in 0..10 {\n            if let Some(proxy) = provider.get_proxy() {\n                seen.insert(proxy);\n            }\n        }\n        assert!(seen.len() \u003e 1); // Should see multiple different proxies\n    }\n\n    #[test]\n    fn test_round_robin_proxy_provider() {\n        let config: Value = serde_yaml::from_str(YAML_CONF_MULTIPLE).unwrap();\n        let provider =\n            RoundRobinProxyProvider::from_config(\u0026config[\"proxy\"]).unwrap();\n\n        // Test round robin behavior\n        let first = provider.get_proxy();\n        let second = provider.get_proxy();\n        let third = provider.get_proxy();\n        let fourth = provider.get_proxy(); // Should wrap around to first\n\n        assert_ne!(first, second);\n        assert_ne!(second, third);\n        assert_eq!(first, fourth);\n    }\n\n    #[test]\n    fn test_proxy_provider_disabled() {\n        let config: Value = serde_yaml::from_str(\n            r#\"\n        proxy:\n            use: false\n            uri: http://proxy1.example.com:8080\n        \"#,\n        )\n        .unwrap();\n\n        let provider = RandomProxyProvider::from_config(\u0026config[\"proxy\"]).unwrap();\n        assert_eq!(provider.get_proxy(), None);\n    }\n\n    #[test]\n    fn test_proxy_config_port_range() {\n        let yaml = r#\"\n        proxy:\n            use: true\n            uri: http://proxy1.example.com:{8080-8082}\n        \"#;\n\n        let config: Value = serde_yaml::from_str(yaml).unwrap();\n        let proxy_config = ProxyConfig::from_config(\u0026config[\"proxy\"]).unwrap();\n\n        assert_eq!(proxy_config.uris.len(), 3);\n        assert!(proxy_config\n            .uris\n            .contains(\u0026\"http://proxy1.example.com:8080\".to_string()));\n        assert!(proxy_config\n            .uris\n            .contains(\u0026\"http://proxy1.example.com:8081\".to_string()));\n        assert!(proxy_config\n            .uris\n            .contains(\u0026\"http://proxy1.example.com:8082\".to_string()));\n    }\n\n    #[test]\n    fn test_proxy_config_multiple_uris_with_ranges() {\n        let yaml = r#\"\n        proxy:\n            use: true\n            uris:\n                - http://proxy1.example.com:{8080-8082}\n                - http://proxy2.example.com:8090\n                - http://proxy3.example.com:{9000-9001}\n        \"#;\n\n        let config: Value = serde_yaml::from_str(yaml).unwrap();\n        let proxy_config = ProxyConfig::from_config(\u0026config[\"proxy\"]).unwrap();\n\n        assert_eq!(proxy_config.uris.len(), 6); // 3 from first range + 1 single + 2 from last range\n        assert!(proxy_config\n            .uris\n            .contains(\u0026\"http://proxy2.example.com:8090\".to_string()));\n    }\n\n    #[test]\n    fn test_invalid_port_range() {\n        let yaml = r#\"\n        proxy:\n            use: true\n            uri: http://proxy1.example.com:{8082-8080}\n        \"#;\n\n        let config: Value = serde_yaml::from_str(yaml).unwrap();\n        let proxy_config = ProxyConfig::from_config(\u0026config[\"proxy\"]).unwrap();\n\n        // Should treat invalid range as literal string\n        assert_eq!(proxy_config.uris.len(), 1);\n        assert_eq!(\n            proxy_config.uris[0],\n            \"http://proxy1.example.com:{8082-8080}\".to_string()\n        );\n    }\n\n    #[test]\n    fn test_no_port_range() {\n        let yaml = r#\"\n        proxy:\n            use: true\n            uri: http://proxy1.example.com:8080\n        \"#;\n\n        let config: Value = serde_yaml::from_str(yaml).unwrap();\n        let proxy_config = ProxyConfig::from_config(\u0026config[\"proxy\"]).unwrap();\n\n        assert_eq!(proxy_config.uris.len(), 1);\n        assert_eq!(\n            proxy_config.uris[0],\n            \"http://proxy1.example.com:8080\".to_string()\n        );\n    }\n}\n","traces":[{"line":13,"address":[],"length":0,"stats":{"Line":1}},{"line":14,"address":[],"length":0,"stats":{"Line":1}},{"line":24,"address":[],"length":0,"stats":{"Line":21}},{"line":25,"address":[],"length":0,"stats":{"Line":30}},{"line":26,"address":[],"length":0,"stats":{"Line":9}},{"line":27,"address":[],"length":0,"stats":{"Line":9}},{"line":28,"address":[],"length":0,"stats":{"Line":9}},{"line":30,"address":[],"length":0,"stats":{"Line":9}},{"line":31,"address":[],"length":0,"stats":{"Line":7}},{"line":32,"address":[],"length":0,"stats":{"Line":33}},{"line":33,"address":[],"length":0,"stats":{"Line":7}},{"line":37,"address":[],"length":0,"stats":{"Line":14}},{"line":40,"address":[],"length":0,"stats":{"Line":14}},{"line":41,"address":[],"length":0,"stats":{"Line":28}},{"line":42,"address":[],"length":0,"stats":{"Line":14}},{"line":43,"address":[],"length":0,"stats":{"Line":13}},{"line":44,"address":[],"length":0,"stats":{"Line":4}},{"line":46,"address":[],"length":0,"stats":{"Line":20}},{"line":47,"address":[],"length":0,"stats":{"Line":4}},{"line":50,"address":[],"length":0,"stats":{"Line":18}},{"line":51,"address":[],"length":0,"stats":{"Line":9}},{"line":53,"address":[],"length":0,"stats":{"Line":0}},{"line":58,"address":[],"length":0,"stats":{"Line":1}},{"line":71,"address":[],"length":0,"stats":{"Line":9}},{"line":75,"address":[],"length":0,"stats":{"Line":9}},{"line":76,"address":[],"length":0,"stats":{"Line":18}},{"line":82,"address":[],"length":0,"stats":{"Line":45}},{"line":83,"address":[],"length":0,"stats":{"Line":89}},{"line":84,"address":[],"length":0,"stats":{"Line":1}},{"line":88,"address":[],"length":0,"stats":{"Line":44}},{"line":89,"address":[],"length":0,"stats":{"Line":44}},{"line":101,"address":[],"length":0,"stats":{"Line":1}},{"line":104,"address":[],"length":0,"stats":{"Line":1}},{"line":108,"address":[],"length":0,"stats":{"Line":1}},{"line":109,"address":[],"length":0,"stats":{"Line":2}},{"line":115,"address":[],"length":0,"stats":{"Line":4}},{"line":116,"address":[],"length":0,"stats":{"Line":8}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":4}},{"line":121,"address":[],"length":0,"stats":{"Line":4}},{"line":122,"address":[],"length":0,"stats":{"Line":4}},{"line":123,"address":[],"length":0,"stats":{"Line":4}}],"covered":40,"coverable":42},{"path":["/","Users","alexc","code","capp-rs","capp-config","src","router.rs"],"content":"//! URL classification and routing module.\n//!\n//! This module provides functionality for classifying URLs based on predefined rules\n//! and grouping them into categories. It is designed to be flexible and extensible,\n//! allowing for various classification strategies.\n//!\n//! The main components of this module are:\n//!\n//! - `Router`: The primary struct for URL classification and routing.\n//! - `URLClassifier`: An internal struct used by `Router` for URL classification.\n//! - `ClassificationRule`: A trait for implementing custom classification rules.\n//! - `RegexRule`: A concrete implementation of `ClassificationRule` using regular expressions.\n//!\n//! # Examples\n//!\n//! ```\n//! use capp_config::router::Router;\n//! use url::Url;\n//!\n//! let mut router = Router::new();\n//! router.add_regex_rule(\"example\", vec![\"example\\\\.com\"], vec![\"subdomain\\\\.example\\\\.com\"]).unwrap();\n//!\n//! let url = Url::parse(\"https://example.com/page\").unwrap();\n//! assert_eq!(router.classify_url(\u0026url), Some(\"example\".to_string()));\n//! ```\n//!\n//! This module is designed to be used optionally within a larger application context,\n//! providing URL classification capabilities when needed without being a mandatory component.\n#![warn(clippy::unwrap_used)]\nuse indexmap::IndexMap;\nuse regex::Regex;\nuse url::Url;\n\n// ClassifiedURLs as a type alias using IndexMap\npub type ClassifiedURLs = IndexMap\u003cString, Vec\u003cUrl\u003e\u003e;\n\n/// A URL classifier and router.\n///\n/// This struct provides functionality to classify URLs based on predefined rules\n/// and group them into categories.\n#[derive(Debug)]\npub struct Router {\n    classifier: URLClassifier,\n}\n\n// Define a trait for classification rules\ntrait ClassificationRule: Send + Sync {\n    fn classify(\u0026self, url: \u0026Url) -\u003e Option\u003cString\u003e;\n}\n\n// Implement the regex-based rule\nstruct RegexRule {\n    name: String,\n    allow: Vec\u003cRegex\u003e,\n    except: Vec\u003cRegex\u003e,\n}\n\nimpl Router {\n    /// Creates a new Router instance.\n    ///\n    /// # Returns\n    ///\n    /// A new `Router` with an empty set of classification rules.\n    pub fn new() -\u003e Self {\n        Router {\n            classifier: URLClassifier::new(),\n        }\n    }\n\n    /// Adds a new regex-based rule to the router.\n    ///\n    /// # Arguments\n    ///\n    /// * `name` - The name of the category this rule defines.\n    /// * `allow` - A vector of regex patterns that URLs must match to be included.\n    /// * `except` - A vector of regex patterns that, if matched, will exclude a URL.\n    ///\n    /// # Returns\n    ///\n    /// A `Result` which is `Ok(())` if the rule was added successfully, or an\n    /// `Err` containing a `regex::Error` if there was an issue compiling the regexes.\n    pub fn add_regex_rule(\n        \u0026mut self,\n        name: \u0026str,\n        allow: Vec\u003c\u0026str\u003e,\n        except: Vec\u003c\u0026str\u003e,\n    ) -\u003e Result\u003c(), regex::Error\u003e {\n        let rule = RegexRule {\n            name: name.to_string(),\n            allow: allow\n                .into_iter()\n                .map(Regex::new)\n                .collect::\u003cResult\u003c_, _\u003e\u003e()?,\n            except: except\n                .into_iter()\n                .map(Regex::new)\n                .collect::\u003cResult\u003c_, _\u003e\u003e()?,\n        };\n        self.classifier.add_rule(Box::new(rule));\n        Ok(())\n    }\n\n    /// Classifies a list of URLs into categories.\n    ///\n    /// # Arguments\n    ///\n    /// * `urls` - A vector of `Url`s to classify.\n    ///\n    /// # Returns\n    ///\n    /// An `IndexMap` where keys are category names and values are vectors of URLs\n    /// that belong to that category.\n    pub fn classify_urls(\u0026self, urls: Vec\u003cUrl\u003e) -\u003e ClassifiedURLs {\n        let mut classified = ClassifiedURLs::new();\n        for url in urls {\n            if let Some(category) = self.classifier.classify(\u0026url) {\n                classified.entry(category).or_default().push(url);\n            }\n        }\n        classified\n    }\n\n    /// Classifies a single URL.\n    ///\n    /// # Arguments\n    ///\n    /// * `url` - The `Url` to classify.\n    ///\n    /// # Returns\n    ///\n    /// An `Option\u003cString\u003e` containing the category name if the URL was classified,\n    /// or `None` if no matching rule was found.\n    pub fn classify_url(\u0026self, url: \u0026Url) -\u003e Option\u003cString\u003e {\n        self.classifier.classify(url)\n    }\n}\n\nimpl Default for Router {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\nimpl ClassificationRule for RegexRule {\n    fn classify(\u0026self, url: \u0026Url) -\u003e Option\u003cString\u003e {\n        let domain = url.domain()?;\n        let path = url.path();\n        let test_str = format!(\"{}{}\", domain, path);\n\n        #[allow(clippy::collapsible_if)]\n        if self.allow.iter().any(|r| r.is_match(\u0026test_str)) {\n            if self.except.iter().all(|r| !r.is_match(\u0026test_str)) {\n                return Some(self.name.clone());\n            }\n        }\n        None\n    }\n}\n\n// URLClassifier struct\npub struct URLClassifier {\n    rules: Vec\u003cBox\u003cdyn ClassificationRule\u003e\u003e,\n}\n\nimpl std::fmt::Debug for URLClassifier {\n    fn fmt(\u0026self, f: \u0026mut std::fmt::Formatter\u003c'_\u003e) -\u003e std::fmt::Result {\n        f.debug_struct(\"URLClassifier\")\n            .field(\"rules_count\", \u0026self.rules.len())\n            .finish()\n    }\n}\n\nimpl URLClassifier {\n    fn new() -\u003e Self {\n        URLClassifier { rules: Vec::new() }\n    }\n\n    fn add_rule(\u0026mut self, rule: Box\u003cdyn ClassificationRule\u003e) {\n        self.rules.push(rule);\n    }\n\n    fn classify(\u0026self, url: \u0026Url) -\u003e Option\u003cString\u003e {\n        for rule in \u0026self.rules {\n            if let Some(classification) = rule.classify(url) {\n                return Some(classification);\n            }\n        }\n        None\n    }\n}\n\n#[cfg(test)]\n#[allow(clippy::unwrap_used)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_add_regex_rule() {\n        let mut router = Router::new();\n        let result = router.add_regex_rule(\n            \"example\",\n            vec![\"example\\\\.com\"],\n            vec![\"subdomain\\\\.example\\\\.com\"],\n        );\n        assert!(result.is_ok());\n    }\n\n    #[test]\n    fn test_classify_url() {\n        let mut router = Router::new();\n        router\n            .add_regex_rule(\n                \"example\",\n                vec![\"example\\\\.com\"],\n                vec![\"subdomain\\\\.example\\\\.com\"],\n            )\n            .unwrap();\n\n        let url = Url::parse(\"https://example.com/page\").unwrap();\n        assert_eq!(router.classify_url(\u0026url), Some(\"example\".to_string()));\n\n        let url = Url::parse(\"https://subdomain.example.com/page\").unwrap();\n        assert_eq!(router.classify_url(\u0026url), None);\n    }\n\n    #[test]\n    fn test_classify_urls() {\n        let mut router = Router::new();\n        router\n            .add_regex_rule(\n                \"example\",\n                vec![\"example\\\\.com\"],\n                vec![\"subdomain\\\\.example\\\\.com\"],\n            )\n            .unwrap();\n\n        let urls = vec![\n            Url::parse(\"https://example.com/page1\").unwrap(),\n            Url::parse(\"https://subdomain.example.com/page\").unwrap(),\n            Url::parse(\"https://example.com/page2\").unwrap(),\n        ];\n\n        let classified = router.classify_urls(urls);\n        assert_eq!(classified.len(), 1);\n        assert_eq!(classified[\"example\"].len(), 2);\n    }\n}\n","traces":[{"line":64,"address":[],"length":0,"stats":{"Line":3}},{"line":66,"address":[],"length":0,"stats":{"Line":3}},{"line":82,"address":[],"length":0,"stats":{"Line":3}},{"line":89,"address":[],"length":0,"stats":{"Line":3}},{"line":90,"address":[],"length":0,"stats":{"Line":3}},{"line":94,"address":[],"length":0,"stats":{"Line":3}},{"line":99,"address":[],"length":0,"stats":{"Line":3}},{"line":100,"address":[],"length":0,"stats":{"Line":3}},{"line":113,"address":[],"length":0,"stats":{"Line":1}},{"line":114,"address":[],"length":0,"stats":{"Line":1}},{"line":115,"address":[],"length":0,"stats":{"Line":7}},{"line":116,"address":[],"length":0,"stats":{"Line":4}},{"line":117,"address":[],"length":0,"stats":{"Line":2}},{"line":120,"address":[],"length":0,"stats":{"Line":1}},{"line":133,"address":[],"length":0,"stats":{"Line":2}},{"line":134,"address":[],"length":0,"stats":{"Line":2}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":5}},{"line":146,"address":[],"length":0,"stats":{"Line":10}},{"line":151,"address":[],"length":0,"stats":{"Line":5}},{"line":152,"address":[],"length":0,"stats":{"Line":10}},{"line":153,"address":[],"length":0,"stats":{"Line":3}},{"line":156,"address":[],"length":0,"stats":{"Line":2}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":174,"address":[],"length":0,"stats":{"Line":3}},{"line":175,"address":[],"length":0,"stats":{"Line":3}},{"line":178,"address":[],"length":0,"stats":{"Line":3}},{"line":179,"address":[],"length":0,"stats":{"Line":3}},{"line":182,"address":[],"length":0,"stats":{"Line":5}},{"line":183,"address":[],"length":0,"stats":{"Line":12}},{"line":184,"address":[],"length":0,"stats":{"Line":3}},{"line":185,"address":[],"length":0,"stats":{"Line":3}},{"line":188,"address":[],"length":0,"stats":{"Line":2}}],"covered":31,"coverable":36},{"path":["/","Users","alexc","code","capp-rs","capp-queue","src","backend","memory.rs"],"content":"//! In-memory implementation of TaskStorage trait. The storage allows tasks to be\n//! pushed to and popped from a queue, and also allows tasks to be set and\n//! retrieved by their UUID.\n\nuse crate::queue::{TaskQueue, TaskQueueError};\nuse crate::task::{Task, TaskId};\nuse async_trait::async_trait;\nuse serde::de::DeserializeOwned;\nuse serde::Serialize;\nuse std::collections::{HashMap, VecDeque};\nuse std::marker::PhantomData;\nuse std::sync::Mutex;\n\npub struct InMemoryTaskQueue\u003cD\u003e {\n    pub hashmap: Mutex\u003cHashMap\u003cTaskId, String\u003e\u003e,\n    pub list: Mutex\u003cVecDeque\u003cTaskId\u003e\u003e,\n    pub dlq: Mutex\u003cHashMap\u003cTaskId, String\u003e\u003e,\n    _marker: PhantomData\u003cD\u003e,\n}\n\nimpl\u003cD\u003e InMemoryTaskQueue\u003cD\u003e {\n    pub fn new() -\u003e Self {\n        Self {\n            hashmap: Mutex::new(HashMap::new()),\n            list: Mutex::new(VecDeque::new()),\n            dlq: Mutex::new(HashMap::new()),\n            _marker: PhantomData,\n        }\n    }\n}\n\nimpl\u003cD\u003e Default for InMemoryTaskQueue\u003cD\u003e {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\n#[async_trait]\nimpl\u003cD\u003e TaskQueue\u003cD\u003e for InMemoryTaskQueue\u003cD\u003e\nwhere\n    D: std::fmt::Debug\n        + Clone\n        + Serialize\n        + DeserializeOwned\n        + Send\n        + Sync\n        + 'static,\n{\n    async fn push(\u0026self, task: \u0026Task\u003cD\u003e) -\u003e Result\u003c(), TaskQueueError\u003e {\n        let mut list = self\n            .list\n            .lock()\n            .map_err(|e| TaskQueueError::QueueError(e.to_string()))?;\n        let mut hashmap = self\n            .hashmap\n            .lock()\n            .map_err(|e| TaskQueueError::QueueError(e.to_string()))?;\n\n        let task_value = serde_json::to_string(task)\n            .map_err(|e| TaskQueueError::SerdeError(e.to_string()))?;\n        hashmap.insert(task.task_id, task_value);\n        list.push_back(task.task_id);\n        Ok(())\n    }\n\n    async fn pop(\u0026self) -\u003e Result\u003cTask\u003cD\u003e, TaskQueueError\u003e {\n        let mut list = self\n            .list\n            .lock()\n            .map_err(|e| TaskQueueError::QueueError(e.to_string()))?;\n        let hashmap = self\n            .hashmap\n            .lock()\n            .map_err(|e| TaskQueueError::QueueError(e.to_string()))?;\n\n        if let Some(task_id) = list.pop_front() {\n            let task_value = hashmap\n                .get(\u0026task_id)\n                .ok_or(TaskQueueError::TaskNotFound(task_id))?;\n            let task: Task\u003cD\u003e = serde_json::from_str(task_value)\n                .map_err(|e| TaskQueueError::SerdeError(e.to_string()))?;\n            Ok(task)\n        } else {\n            Err(TaskQueueError::QueueEmpty)\n        }\n    }\n\n    async fn ack(\u0026self, task_id: \u0026TaskId) -\u003e Result\u003c(), TaskQueueError\u003e {\n        let mut hashmap = self\n            .hashmap\n            .lock()\n            .map_err(|e| TaskQueueError::QueueError(e.to_string()))?;\n        hashmap\n            .remove(task_id)\n            .ok_or(TaskQueueError::TaskNotFound(*task_id))?;\n        Ok(())\n    }\n\n    async fn nack(\u0026self, task: \u0026Task\u003cD\u003e) -\u003e Result\u003c(), TaskQueueError\u003e {\n        let mut dlq = self\n            .dlq\n            .lock()\n            .map_err(|e| TaskQueueError::QueueError(e.to_string()))?;\n        let task_value = serde_json::to_string(task)\n            .map_err(|e| TaskQueueError::SerdeError(e.to_string()))?;\n        dlq.insert(task.task_id, task_value);\n\n        let mut hashmap = self\n            .hashmap\n            .lock()\n            .map_err(|e| TaskQueueError::QueueError(e.to_string()))?;\n        hashmap\n            .remove(\u0026task.task_id)\n            .ok_or(TaskQueueError::TaskNotFound(task.task_id))?;\n\n        Ok(())\n    }\n\n    async fn set(\u0026self, task: \u0026Task\u003cD\u003e) -\u003e Result\u003c(), TaskQueueError\u003e {\n        let mut hashmap = self\n            .hashmap\n            .lock()\n            .map_err(|e| TaskQueueError::QueueError(e.to_string()))?;\n        let task_value = serde_json::to_string(task)\n            .map_err(|e| TaskQueueError::SerdeError(e.to_string()))?;\n        hashmap.insert(task.task_id, task_value);\n        Ok(())\n    }\n}\n\nimpl\u003cD\u003e std::fmt::Debug for InMemoryTaskQueue\u003cD\u003e {\n    fn fmt(\u0026self, f: \u0026mut std::fmt::Formatter\u003c'_\u003e) -\u003e std::fmt::Result {\n        let hashmap = self.hashmap.lock().unwrap();\n        let list = self.list.lock().unwrap();\n        let dlq = self.dlq.lock().unwrap();\n\n        f.debug_struct(\"InMemoryTaskQueue\")\n            .field(\"hashmap\", \u0026*hashmap)\n            .field(\"list\", \u0026*list)\n            .field(\"dlq\", \u0026*dlq)\n            .finish()\n    }\n}\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use serde::{Deserialize, Serialize};\n\n    #[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n    struct TestData {\n        value: u32,\n    }\n\n    #[tokio::test]\n    async fn test_push_and_pop() {\n        let queue = InMemoryTaskQueue::\u003cTestData\u003e::new();\n        let task = Task::new(TestData { value: 42 });\n\n        queue.push(\u0026task).await.unwrap();\n        let popped_task = queue.pop().await.unwrap();\n\n        assert_eq!(popped_task.payload, TestData { value: 42 });\n    }\n\n    #[tokio::test]\n    async fn test_queue_empty() {\n        let queue = InMemoryTaskQueue::\u003cTestData\u003e::new();\n\n        match queue.pop().await {\n            Err(TaskQueueError::QueueEmpty) =\u003e (),\n            _ =\u003e panic!(\"Expected QueueEmpty error\"),\n        }\n    }\n\n    #[tokio::test]\n    async fn test_ack() {\n        let queue = InMemoryTaskQueue::\u003cTestData\u003e::new();\n        let task = Task::new(TestData { value: 42 });\n\n        queue.push(\u0026task).await.unwrap();\n        let popped_task = queue.pop().await.unwrap();\n        queue.ack(\u0026popped_task.task_id).await.unwrap();\n\n        // The queue should be empty after ack\n        assert!(matches!(queue.pop().await, Err(TaskQueueError::QueueEmpty)));\n    }\n\n    #[tokio::test]\n    async fn test_nack() {\n        let queue = InMemoryTaskQueue::\u003cTestData\u003e::new();\n        let task = Task::new(TestData { value: 42 });\n\n        queue.push(\u0026task).await.unwrap();\n        let popped_task = queue.pop().await.unwrap();\n        queue.nack(\u0026popped_task).await.unwrap();\n\n        // The queue should be empty after nack\n        assert!(matches!(queue.pop().await, Err(TaskQueueError::QueueEmpty)));\n\n        // The task should be in the DLQ\n        let dlq = queue.dlq.lock().unwrap();\n        assert_eq!(dlq.len(), 1);\n    }\n\n    #[tokio::test]\n    async fn test_set() {\n        let queue = InMemoryTaskQueue::\u003cTestData\u003e::new();\n        let mut task = Task::new(TestData { value: 42 });\n\n        queue.push(\u0026task).await.unwrap();\n\n        // Modify the task\n        task.payload.value = 43;\n        queue.set(\u0026task).await.unwrap();\n\n        let updated_task = queue.pop().await.unwrap();\n        assert_eq!(updated_task.payload, TestData { value: 43 });\n    }\n\n    #[tokio::test]\n    async fn test_multiple_tasks() {\n        let queue = InMemoryTaskQueue::\u003cTestData\u003e::new();\n        let tasks = vec![\n            Task::new(TestData { value: 1 }),\n            Task::new(TestData { value: 2 }),\n            Task::new(TestData { value: 3 }),\n        ];\n\n        for task in \u0026tasks {\n            queue.push(task).await.unwrap();\n        }\n\n        for expected_task in tasks {\n            let popped_task = queue.pop().await.unwrap();\n            assert_eq!(popped_task.payload, expected_task.payload);\n        }\n\n        // Queue should be empty now\n        assert!(matches!(queue.pop().await, Err(TaskQueueError::QueueEmpty)));\n    }\n\n    #[tokio::test]\n    async fn test_task_not_found() {\n        let queue = InMemoryTaskQueue::\u003cTestData\u003e::new();\n        let non_existent_task_id = TaskId::new();\n\n        match queue.ack(\u0026non_existent_task_id).await {\n            Err(TaskQueueError::TaskNotFound(_)) =\u003e (),\n            _ =\u003e panic!(\"Expected TaskNotFound error\"),\n        }\n    }\n}\n","traces":[{"line":22,"address":[],"length":0,"stats":{"Line":7}},{"line":24,"address":[],"length":0,"stats":{"Line":7}},{"line":25,"address":[],"length":0,"stats":{"Line":7}},{"line":26,"address":[],"length":0,"stats":{"Line":7}},{"line":33,"address":[],"length":0,"stats":{"Line":0}},{"line":34,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":7}},{"line":50,"address":[],"length":0,"stats":{"Line":14}},{"line":51,"address":[],"length":0,"stats":{"Line":7}},{"line":53,"address":[],"length":0,"stats":{"Line":14}},{"line":54,"address":[],"length":0,"stats":{"Line":7}},{"line":55,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":59,"address":[],"length":0,"stats":{"Line":7}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":7}},{"line":62,"address":[],"length":0,"stats":{"Line":7}},{"line":63,"address":[],"length":0,"stats":{"Line":7}},{"line":66,"address":[],"length":0,"stats":{"Line":11}},{"line":67,"address":[],"length":0,"stats":{"Line":22}},{"line":68,"address":[],"length":0,"stats":{"Line":11}},{"line":70,"address":[],"length":0,"stats":{"Line":22}},{"line":71,"address":[],"length":0,"stats":{"Line":11}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":7}},{"line":77,"address":[],"length":0,"stats":{"Line":7}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":7}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":7}},{"line":84,"address":[],"length":0,"stats":{"Line":4}},{"line":88,"address":[],"length":0,"stats":{"Line":2}},{"line":89,"address":[],"length":0,"stats":{"Line":4}},{"line":90,"address":[],"length":0,"stats":{"Line":2}},{"line":92,"address":[],"length":0,"stats":{"Line":4}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":1}},{"line":96,"address":[],"length":0,"stats":{"Line":1}},{"line":99,"address":[],"length":0,"stats":{"Line":1}},{"line":100,"address":[],"length":0,"stats":{"Line":2}},{"line":101,"address":[],"length":0,"stats":{"Line":1}},{"line":103,"address":[],"length":0,"stats":{"Line":2}},{"line":104,"address":[],"length":0,"stats":{"Line":1}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":1}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":1}},{"line":119,"address":[],"length":0,"stats":{"Line":1}},{"line":120,"address":[],"length":0,"stats":{"Line":2}},{"line":121,"address":[],"length":0,"stats":{"Line":1}},{"line":123,"address":[],"length":0,"stats":{"Line":2}},{"line":124,"address":[],"length":0,"stats":{"Line":1}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":1}},{"line":127,"address":[],"length":0,"stats":{"Line":1}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}}],"covered":43,"coverable":71},{"path":["/","Users","alexc","code","capp-rs","capp-queue","src","backend","redis.rs"],"content":"//! Provides implementation of trait to store task into redis\nuse async_trait::async_trait;\nuse rustis::client::{BatchPreparedCommand, Client, Pipeline};\nuse rustis::commands::{HashCommands, ListCommands};\nuse serde::{de::DeserializeOwned, Serialize};\nuse std::marker::PhantomData;\n\nuse crate::queue::{TaskQueue, TaskQueueError};\nuse crate::task::{Task, TaskId};\n\npub struct RedisTaskQueue\u003cD\u003e {\n    pub client: Client,\n    pub list_key: String,\n    pub hashmap_key: String,\n    pub dlq_key: String,\n    _marker: PhantomData\u003cD\u003e,\n}\n\nimpl\u003cD\u003e RedisTaskQueue\u003cD\u003e {\n    pub async fn new(\n        client: Client,\n        queue_name: \u0026str,\n    ) -\u003e Result\u003cSelf, TaskQueueError\u003e {\n        Ok(Self {\n            client,\n            list_key: format!(\"{}:{}\", queue_name, \"ls\"),\n            hashmap_key: format!(\"{}:{}\", queue_name, \"hm\"),\n            dlq_key: format!(\"{}:{}\", queue_name, \"dlq\"),\n            _marker: PhantomData,\n        })\n    }\n\n    async fn execute_pipeline(\n        \u0026self,\n        pipeline: Pipeline\u003c'_\u003e,\n    ) -\u003e Result\u003c(), TaskQueueError\u003e {\n        // NOTE: this strange construction .map(|_: ()| ())\n        // This change explicitly specifies that we're expecting a () (unit type) as the successful\n        // result of execute(). By doing this, we're no longer relying on the never type fallback,\n        // which resolves the warning.\n        pipeline\n            .execute()\n            .await\n            .map(|_: ()| ())\n            .map_err(|e| TaskQueueError::QueueError(e.to_string()))?;\n        Ok(())\n    }\n}\n\n#[async_trait]\nimpl\u003cD\u003e TaskQueue\u003cD\u003e for RedisTaskQueue\u003cD\u003e\nwhere\n    D: std::fmt::Debug\n        + Clone\n        + Serialize\n        + DeserializeOwned\n        + Send\n        + Sync\n        + 'static,\n{\n    async fn push(\u0026self, task: \u0026Task\u003cD\u003e) -\u003e Result\u003c(), TaskQueueError\u003e {\n        let task_json = serde_json::to_string(task)\n            .map_err(|e| TaskQueueError::SerdeError(e.to_string()))?;\n\n        let mut pipeline = self.client.create_pipeline();\n        pipeline\n            .rpush(\u0026self.list_key, \u0026task.task_id.to_string())\n            .forget();\n        pipeline\n            .hset(\u0026self.hashmap_key, [(\u0026task.task_id.to_string(), \u0026task_json)])\n            .forget();\n        self.execute_pipeline(pipeline).await\n    }\n\n    async fn pop(\u0026self) -\u003e Result\u003cTask\u003cD\u003e, TaskQueueError\u003e {\n        let task_ids: Vec\u003cString\u003e = self\n            .client\n            .lpop(\u0026self.list_key, 1)\n            .await\n            .map_err(|e| TaskQueueError::QueueError(e.to_string()))?;\n\n        if !task_ids.is_empty() {\n            let task_id = task_ids.first().unwrap();\n            let task_value: String =\n                self.client.hget(\u0026self.hashmap_key, task_id).await?;\n\n            let task: Task\u003cD\u003e = serde_json::from_str(\u0026task_value)\n                .map_err(|err| TaskQueueError::SerdeError(err.to_string()))?;\n            return Ok(task);\n        }\n\n        Err(TaskQueueError::QueueEmpty)\n    }\n\n    async fn ack(\u0026self, task_id: \u0026TaskId) -\u003e Result\u003c(), TaskQueueError\u003e {\n        let uuid_as_str = task_id.to_string();\n        let _ = self.client.hdel(\u0026self.hashmap_key, \u0026uuid_as_str).await?;\n        Ok(())\n    }\n\n    async fn nack(\u0026self, task: \u0026Task\u003cD\u003e) -\u003e Result\u003c(), TaskQueueError\u003e {\n        let uuid_as_str = task.task_id.to_string();\n        let task_json = serde_json::to_string(task)\n            .map_err(|e| TaskQueueError::SerdeError(e.to_string()))?;\n\n        let mut pipeline = self.client.create_pipeline();\n        pipeline.rpush(\u0026self.dlq_key, \u0026task_json).forget();\n        pipeline.hdel(\u0026self.hashmap_key, \u0026uuid_as_str).forget();\n        self.execute_pipeline(pipeline).await\n    }\n\n    async fn set(\u0026self, task: \u0026Task\u003cD\u003e) -\u003e Result\u003c(), TaskQueueError\u003e {\n        let task_json = serde_json::to_string(task)\n            .map_err(|e| TaskQueueError::SerdeError(e.to_string()))?;\n\n        self.client\n            .hset(\u0026self.hashmap_key, [(\u0026task.task_id.to_string(), \u0026task_json)])\n            .await\n            .map_err(|e| TaskQueueError::QueueError(e.to_string()))?;\n        Ok(())\n    }\n}\n","traces":[{"line":20,"address":[],"length":0,"stats":{"Line":0}},{"line":24,"address":[],"length":0,"stats":{"Line":0}},{"line":25,"address":[],"length":0,"stats":{"Line":0}},{"line":26,"address":[],"length":0,"stats":{"Line":0}},{"line":27,"address":[],"length":0,"stats":{"Line":0}},{"line":28,"address":[],"length":0,"stats":{"Line":0}},{"line":29,"address":[],"length":0,"stats":{"Line":0}},{"line":33,"address":[],"length":0,"stats":{"Line":0}},{"line":41,"address":[],"length":0,"stats":{"Line":0}},{"line":43,"address":[],"length":0,"stats":{"Line":0}},{"line":44,"address":[],"length":0,"stats":{"Line":0}},{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":46,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":0}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":63,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":56},{"path":["/","Users","alexc","code","capp-rs","capp-queue","src","backend","redis_rr.rs"],"content":"//! `RedisRoundRobinTaskStorage` provides an asynchronous task storage mechanism\n//! built on top of Redis, with a round-robin approach to accessing tasks across\n//! different queues.\n//!\n//! This storage structure maintains domain-specific queues, allowing for tasks\n//! to be categorized and processed based on their associated key. The round-robin\n//! mechanism ensures that tasks from one domain do not dominate the queue, allowing\n//! for balanced task processing across all domains.\n//!\n//! Note: The exact tag key for each task is determined from the `TaskData`\n//! field, and can be configured during the storage initialization.\n\nuse crate::queue::{HasTagKey, TaskQueue, TaskQueueError};\nuse crate::task::{Task, TaskId};\nuse async_trait::async_trait;\nuse rustis::client::{BatchPreparedCommand, Client, Pipeline};\nuse rustis::commands::{\n    GenericCommands, HashCommands, ListCommands, StringCommands,\n};\nuse serde::{de::DeserializeOwned, Serialize};\nuse std::collections::HashSet;\nuse std::marker::PhantomData;\nuse std::sync::Arc;\n\npub struct RedisRoundRobinTaskQueue\u003cD\u003e {\n    pub client: Client,\n    pub key: String,\n    pub tags: Arc\u003cHashSet\u003cString\u003e\u003e,\n    _marker: PhantomData\u003cD\u003e,\n}\n\nimpl\u003cD\u003e RedisRoundRobinTaskQueue\u003cD\u003e {\n    pub async fn new(\n        client: Client,\n        key: \u0026str,\n        tags: HashSet\u003cString\u003e,\n    ) -\u003e Result\u003cSelf, TaskQueueError\u003e {\n        let queue = Self {\n            client,\n            key: key.to_string(),\n            tags: Arc::new(tags),\n            _marker: PhantomData,\n        };\n\n        // Initialize counters for each tag\n        for tag in queue.tags.iter() {\n            queue.client.set(queue.get_counter_key(tag), 0).await?;\n        }\n\n        Ok(queue)\n    }\n\n    pub fn get_hashmap_key(\u0026self) -\u003e String {\n        format!(\"{}:hm\", self.key)\n    }\n\n    pub fn get_list_key(\u0026self, tag: \u0026str) -\u003e String {\n        format!(\"{}:{}:ls\", self.key, tag)\n    }\n\n    pub fn get_counter_key(\u0026self, tag: \u0026str) -\u003e String {\n        format!(\"{}:{}:counter\", self.key, tag)\n    }\n\n    pub fn get_counter_keys(\u0026self) -\u003e Vec\u003cString\u003e {\n        let mut result = vec![];\n        for tag in self.tags.iter() {\n            let key = self.get_counter_key(tag);\n            result.push(key);\n        }\n        result\n    }\n\n    pub fn get_dlq_key(\u0026self) -\u003e String {\n        format!(\"{}:dlq\", self.key)\n    }\n\n    async fn execute_pipeline(\n        \u0026self,\n        pipeline: Pipeline\u003c'_\u003e,\n    ) -\u003e Result\u003c(), TaskQueueError\u003e {\n        pipeline\n            .execute()\n            .await\n            .map(|_: ()| ())\n            .map_err(|e| TaskQueueError::QueueError(e.to_string()))?;\n        Ok(())\n    }\n\n    pub async fn get_next_non_empty_tag(\n        \u0026self,\n    ) -\u003e Result\u003cOption\u003cString\u003e, TaskQueueError\u003e {\n        for tag in self.tags.iter() {\n            let count: i64 = self.client.get(self.get_counter_key(tag)).await?;\n            if count \u003e 0 {\n                return Ok(Some(tag.clone()));\n            }\n        }\n        Ok(None)\n    }\n\n    pub async fn purge(\u0026self) -\u003e Result\u003cusize, TaskQueueError\u003e {\n        let mut keys_to_delete = vec![self.get_hashmap_key(), self.get_dlq_key()];\n        // Add list keys for all tags\n        for tag in self.tags.iter() {\n            keys_to_delete.push(self.get_list_key(tag));\n        }\n        // Add counter keys to the list of keys to delete\n        keys_to_delete.extend(self.get_counter_keys());\n        self.client\n            .del(keys_to_delete)\n            .await\n            .map_err(|e| TaskQueueError::QueueError(e.to_string()))\n    }\n}\n\n#[async_trait]\nimpl\u003cD\u003e TaskQueue\u003cD\u003e for RedisRoundRobinTaskQueue\u003cD\u003e\nwhere\n    D: std::fmt::Debug\n        + Clone\n        + Serialize\n        + DeserializeOwned\n        + Send\n        + Sync\n        + 'static\n        + HasTagKey,\n{\n    async fn push(\u0026self, task: \u0026Task\u003cD\u003e) -\u003e Result\u003c(), TaskQueueError\u003e {\n        let task_json = serde_json::to_string(task)\n            .map_err(|e| TaskQueueError::SerdeError(e.to_string()))?;\n        let tag = task.payload.get_tag_value().to_string();\n        let list_key = self.get_list_key(\u0026tag);\n        let hashmap_key = self.get_hashmap_key();\n        let counter_key = self.get_counter_key(\u0026tag);\n\n        let mut pipeline = self.client.create_pipeline();\n        pipeline\n            .lpush(\u0026list_key, \u0026task.task_id.to_string())\n            .forget();\n        pipeline\n            .hset(\u0026hashmap_key, [(\u0026task.task_id.to_string(), \u0026task_json)])\n            .forget();\n        pipeline.incr(counter_key).forget();\n        self.execute_pipeline(pipeline).await\n    }\n\n    async fn pop(\u0026self) -\u003e Result\u003cTask\u003cD\u003e, TaskQueueError\u003e {\n        let tag = self\n            .get_next_non_empty_tag()\n            .await?\n            .ok_or(TaskQueueError::QueueEmpty)?;\n\n        let list_key = self.get_list_key(\u0026tag);\n        let hashmap_key = self.get_hashmap_key();\n        let counter_key = self.get_counter_key(\u0026tag);\n\n        let task_ids: Vec\u003cString\u003e = self\n            .client\n            .rpop(\u0026list_key, 1)\n            .await\n            .map_err(|e| TaskQueueError::QueueError(e.to_string()))?;\n\n        if let Some(task_id) = task_ids.first() {\n            let task_value: String =\n                self.client.hget(\u0026hashmap_key, task_id).await?;\n            let task: Task\u003cD\u003e = serde_json::from_str(\u0026task_value)\n                .map_err(|err| TaskQueueError::SerdeError(err.to_string()))?;\n\n            // Decrement the counter\n            self.client.decr(counter_key).await?;\n\n            Ok(task)\n        } else {\n            Err(TaskQueueError::QueueEmpty)\n        }\n    }\n\n    async fn ack(\u0026self, task_id: \u0026TaskId) -\u003e Result\u003c(), TaskQueueError\u003e {\n        let uuid_as_str = task_id.to_string();\n        let _ = self\n            .client\n            .hdel(self.get_hashmap_key(), \u0026uuid_as_str)\n            .await?;\n        Ok(())\n    }\n\n    async fn nack(\u0026self, task: \u0026Task\u003cD\u003e) -\u003e Result\u003c(), TaskQueueError\u003e {\n        let uuid_as_str = task.task_id.to_string();\n        let task_json = serde_json::to_string(task)\n            .map_err(|e| TaskQueueError::SerdeError(e.to_string()))?;\n\n        let mut pipeline = self.client.create_pipeline();\n        pipeline.rpush(self.get_dlq_key(), \u0026task_json).forget();\n        pipeline.hdel(self.get_hashmap_key(), \u0026uuid_as_str).forget();\n        self.execute_pipeline(pipeline).await\n    }\n\n    async fn set(\u0026self, task: \u0026Task\u003cD\u003e) -\u003e Result\u003c(), TaskQueueError\u003e {\n        let task_json = serde_json::to_string(task)\n            .map_err(|e| TaskQueueError::SerdeError(e.to_string()))?;\n\n        self.client\n            .hset(\n                self.get_hashmap_key(),\n                [(\u0026task.task_id.to_string(), \u0026task_json)],\n            )\n            .await\n            .map_err(|e| TaskQueueError::QueueError(e.to_string()))?;\n        Ok(())\n    }\n}\n\nimpl\u003cD\u003e std::fmt::Debug for RedisRoundRobinTaskQueue\u003cD\u003e {\n    fn fmt(\u0026self, f: \u0026mut std::fmt::Formatter\u003c'_\u003e) -\u003e std::fmt::Result {\n        f.debug_struct(\"RedisRoundRobinTaskQueue\")\n            .field(\"key\", \u0026self.key)\n            .field(\"tags\", \u0026self.tags)\n            .finish()\n    }\n}\n","traces":[{"line":33,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":0}},{"line":41,"address":[],"length":0,"stats":{"Line":0}},{"line":46,"address":[],"length":0,"stats":{"Line":0}},{"line":47,"address":[],"length":0,"stats":{"Line":0}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":53,"address":[],"length":0,"stats":{"Line":0}},{"line":54,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":58,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":0}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":0}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":152,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":0}},{"line":160,"address":[],"length":0,"stats":{"Line":0}},{"line":161,"address":[],"length":0,"stats":{"Line":0}},{"line":162,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":165,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":171,"address":[],"length":0,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":0}},{"line":179,"address":[],"length":0,"stats":{"Line":0}},{"line":180,"address":[],"length":0,"stats":{"Line":0}},{"line":181,"address":[],"length":0,"stats":{"Line":0}},{"line":182,"address":[],"length":0,"stats":{"Line":0}},{"line":183,"address":[],"length":0,"stats":{"Line":0}},{"line":184,"address":[],"length":0,"stats":{"Line":0}},{"line":185,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":189,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[],"length":0,"stats":{"Line":0}},{"line":193,"address":[],"length":0,"stats":{"Line":0}},{"line":194,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":199,"address":[],"length":0,"stats":{"Line":0}},{"line":200,"address":[],"length":0,"stats":{"Line":0}},{"line":201,"address":[],"length":0,"stats":{"Line":0}},{"line":203,"address":[],"length":0,"stats":{"Line":0}},{"line":205,"address":[],"length":0,"stats":{"Line":0}},{"line":206,"address":[],"length":0,"stats":{"Line":0}},{"line":208,"address":[],"length":0,"stats":{"Line":0}},{"line":209,"address":[],"length":0,"stats":{"Line":0}},{"line":210,"address":[],"length":0,"stats":{"Line":0}},{"line":215,"address":[],"length":0,"stats":{"Line":0}},{"line":216,"address":[],"length":0,"stats":{"Line":0}},{"line":217,"address":[],"length":0,"stats":{"Line":0}},{"line":218,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":103},{"path":["/","Users","alexc","code","capp-rs","capp-queue","src","backend.rs"],"content":"pub mod memory;\n#[cfg(feature = \"redis\")]\npub mod redis;\n#[cfg(feature = \"redis\")]\npub mod redis_rr;\n\npub use memory::InMemoryTaskQueue;\n#[cfg(feature = \"redis\")]\npub use redis::RedisTaskQueue;\n#[cfg(feature = \"redis\")]\npub use redis_rr::RedisRoundRobinTaskQueue;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","capp-queue","src","lib.rs"],"content":"pub mod backend;\npub mod queue;\npub mod task;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","capp-queue","src","queue.rs"],"content":"//! This module provides a trait for interacting with task storage.\n//! The storage allows tasks to be pushed to and popped from a queue,\n//! and also allows tasks to be set and retrieved by their UUID.\n\nuse async_trait::async_trait;\nuse serde::{de::DeserializeOwned, Serialize};\nuse std::sync::Arc;\nuse thiserror::Error;\n\npub use crate::backend::InMemoryTaskQueue;\n#[cfg(feature = \"redis\")]\npub use crate::backend::{RedisRoundRobinTaskQueue, RedisTaskQueue};\nuse crate::task::{Task, TaskId};\n\n#[derive(Error, Debug)]\npub enum TaskQueueError {\n    #[error(\"Queue error: {0}\")]\n    QueueError(String),\n\n    #[error(\"Ser/De error: {0}\")]\n    SerdeError(String),\n\n    #[error(\"Task not found: {0}\")]\n    TaskNotFound(TaskId),\n\n    #[error(\"Queue is empty\")]\n    QueueEmpty,\n\n    #[cfg(feature = \"redis\")]\n    #[error(\"Redis error\")]\n    RedisError(#[from] rustis::Error),\n}\n\n#[async_trait]\npub trait TaskQueue\u003cData\u003e\nwhere\n    Data: std::fmt::Debug\n        + Clone\n        + Serialize\n        + DeserializeOwned\n        + Send\n        + Sync\n        + 'static,\n{\n    async fn push(\u0026self, task: \u0026Task\u003cData\u003e) -\u003e Result\u003c(), TaskQueueError\u003e;\n    async fn pop(\u0026self) -\u003e Result\u003cTask\u003cData\u003e, TaskQueueError\u003e;\n    async fn ack(\u0026self, task_id: \u0026TaskId) -\u003e Result\u003c(), TaskQueueError\u003e;\n    async fn nack(\u0026self, task: \u0026Task\u003cData\u003e) -\u003e Result\u003c(), TaskQueueError\u003e;\n    // NOTE: probably need to move into different trait\n    async fn set(\u0026self, task: \u0026Task\u003cData\u003e) -\u003e Result\u003c(), TaskQueueError\u003e;\n}\n\npub type AbstractTaskQueue\u003cD\u003e = Arc\u003cdyn TaskQueue\u003cD\u003e + Send + Sync\u003e;\n\n// Trait used for round-robin queues\npub trait HasTagKey {\n    type TagValue: ToString + PartialEq;\n    fn get_tag_value(\u0026self) -\u003e Self::TagValue;\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","capp-queue","src","task.rs"],"content":"// use chrono::{DateTime, Utc};\nuse serde::{Deserialize, Serialize};\nuse std::time::SystemTime;\nuse uuid::Uuid;\n\n#[derive(Clone, Debug, Serialize, Deserialize)]\npub enum TaskStatus {\n    Queued,\n    InProgress,\n    Completed,\n    Failed,\n    DeadLetter,\n}\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]\npub struct TaskId(Uuid);\n\n/// A `Task` struct represents a single unit of work that will be processed\n/// by a worker. It contains payload of type `D`, which is used by the worker\n/// during processing. The `Task` struct also includes fields for managing\n/// the task's lifecycle, including the task's UUID, the start and\n/// finish times, the number of retries, and any error messages.\n#[derive(Clone, Debug, Serialize, Deserialize)]\npub struct Task\u003cD: Clone\u003e {\n    pub task_id: TaskId,\n    pub payload: D,\n    pub status: TaskStatus,\n    pub queued_at: SystemTime,\n    pub started_at: Option\u003cSystemTime\u003e,\n    pub finished_at: Option\u003cSystemTime\u003e,\n    pub retries: u32,\n    pub error_msg: Option\u003cString\u003e,\n}\n\nimpl\u003cD: Clone\u003e Task\u003cD\u003e {\n    pub fn new(payload: D) -\u003e Self {\n        Task {\n            task_id: TaskId::new(),\n            payload,\n            status: TaskStatus::Queued,\n            queued_at: SystemTime::now(),\n            started_at: None,\n            finished_at: None,\n            retries: 0,\n            error_msg: None,\n        }\n    }\n\n    pub fn set_in_progress(\u0026mut self) {\n        self.status = TaskStatus::InProgress;\n        self.started_at = Some(SystemTime::now());\n    }\n\n    pub fn set_succeed(\u0026mut self) {\n        self.status = TaskStatus::Completed;\n        self.finished_at = Some(SystemTime::now());\n    }\n\n    pub fn set_retry(\u0026mut self, err_msg: \u0026str) {\n        self.status = TaskStatus::Failed;\n        self.finished_at = Some(SystemTime::now());\n        self.retries += 1;\n        self.error_msg = Some(err_msg.to_string());\n    }\n\n    pub fn set_dlq(\u0026mut self, err_msg: \u0026str) {\n        self.status = TaskStatus::DeadLetter;\n        self.finished_at = Some(SystemTime::now());\n        self.error_msg = Some(err_msg.to_string());\n    }\n\n    pub fn set_status(\u0026mut self, new_status: TaskStatus) {\n        self.status = new_status;\n    }\n\n    pub fn get_payload(\u0026self) -\u003e \u0026D {\n        \u0026self.payload\n    }\n}\n\n//*****************************************************************************\n// TaskId with ser/de traits implemented (to convert underlaying Uuid)\n//*****************************************************************************\n\nimpl TaskId {\n    pub fn new() -\u003e Self {\n        Self(Uuid::new_v4())\n    }\n\n    pub fn get(\u0026self) -\u003e Uuid {\n        self.0\n    }\n}\n\nimpl Default for TaskId {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\n// Custom serialization for TaskId.\nimpl serde::Serialize for TaskId {\n    fn serialize\u003cS\u003e(\u0026self, serializer: S) -\u003e Result\u003cS::Ok, S::Error\u003e\n    where\n        S: serde::Serializer,\n    {\n        // Directly serialize the inner Uuid.\n        self.0.serialize(serializer)\n    }\n}\n\n// Custom deserialization for TaskId.\nimpl\u003c'de\u003e serde::Deserialize\u003c'de\u003e for TaskId {\n    fn deserialize\u003cD\u003e(deserializer: D) -\u003e Result\u003cSelf, D::Error\u003e\n    where\n        D: serde::Deserializer\u003c'de\u003e,\n    {\n        // Deserialize a Uuid and then wrap it in a TaskId.\n        let uuid = Uuid::deserialize(deserializer)?;\n        Ok(TaskId(uuid))\n    }\n}\n\nimpl std::fmt::Display for TaskId {\n    fn fmt(\u0026self, f: \u0026mut std::fmt::Formatter\u003c'_\u003e) -\u003e std::fmt::Result {\n        write!(f, \"TaskId({})\", self.0)\n    }\n}\n\n//*****************************************************************************\n// Tests\n//*****************************************************************************\n\n#[cfg(test)]\nmod tests {\n    use core::panic;\n\n    use super::*;\n    use serde::{Deserialize, Serialize};\n\n    #[derive(Clone, Serialize, Deserialize, Default)]\n    struct TaskData {\n        value: u32,\n    }\n\n    #[test]\n    fn task_id_serde() {\n        let task = Task::new(TaskData { value: 1 });\n        let task_id = task.task_id.clone();\n        let serialized_task_value = serde_json::to_value(task).unwrap();\n        let serialized_task_json = serialized_task_value.to_string();\n        let desrialized_task: Task\u003cTaskData\u003e =\n            serde_json::from_str(\u0026serialized_task_json).unwrap();\n        assert_eq!(task_id, desrialized_task.task_id);\n    }\n\n    #[test]\n    fn test_task_creation() {\n        let task = Task::new(TaskData::default());\n        assert!(task.started_at.is_none());\n        assert!(task.finished_at.is_none());\n        assert_eq!(task.retries, 0);\n        assert_eq!(task.payload.value, 0);\n        match task.status {\n            TaskStatus::Queued =\u003e {}\n            _ =\u003e panic!(\"Wrong status (task.status)\"),\n        };\n    }\n\n    #[test]\n    fn test_in_progress() {\n        let mut task = Task::new(TaskData::default());\n\n        task.set_in_progress();\n        match task.status {\n            TaskStatus::InProgress =\u003e {}\n            _ =\u003e panic!(\"Wrong status (task.status)\"),\n        };\n        assert!(task.started_at.is_some());\n        assert!(task.finished_at.is_none());\n    }\n\n    #[test]\n    fn test_succeed() {\n        let mut task = Task::new(TaskData::default());\n\n        task.set_succeed();\n        match task.status {\n            TaskStatus::Completed =\u003e {}\n            _ =\u003e panic!(\"Wrong status (task.status)\"),\n        };\n        assert!(task.finished_at.is_some());\n        assert!(task.started_at.is_none());\n    }\n\n    #[test]\n    fn test_set_retry() {\n        let mut task = Task::new(TaskData::default());\n\n        task.set_retry(\"Wrong task value\");\n        match task.status {\n            TaskStatus::Failed =\u003e {}\n            _ =\u003e panic!(\"Wrong status (task.status)\"),\n        };\n        assert!(task.finished_at.is_some());\n        assert_eq!(task.retries, 1);\n        assert!(task.error_msg.is_some());\n        assert!(task.started_at.is_none());\n    }\n\n    #[test]\n    fn test_set_dlq() {\n        let mut task = Task::new(TaskData::default());\n\n        task.set_dlq(\"Wrong task value\");\n        match task.status {\n            TaskStatus::DeadLetter =\u003e {}\n            _ =\u003e panic!(\"Wrong status (task.status)\"),\n        };\n        assert!(task.finished_at.is_some());\n        assert!(task.started_at.is_none());\n        assert!(task.error_msg.is_some());\n    }\n\n    #[test]\n    fn task_flow_succeed() {\n        let mut task = Task::new(TaskData::default());\n\n        task.set_in_progress();\n        task.payload.value += 1;\n\n        std::thread::sleep(std::time::Duration::from_millis(5));\n\n        task.set_retry(\"Wrong task value\");\n        task.payload.value += 1;\n\n        task.set_in_progress();\n        std::thread::sleep(std::time::Duration::from_millis(5));\n\n        task.set_succeed();\n\n        match task.status {\n            TaskStatus::Completed =\u003e {}\n            _ =\u003e panic!(\"Wrong status (task.status)\"),\n        };\n        assert_eq!(task.retries, 1);\n        assert_eq!(task.get_payload().value, 2);\n        assert!(task.started_at.is_some());\n        assert!(task.finished_at.is_some());\n\n        // finished_at - started_at\n        assert!(\n            task.finished_at\n                .unwrap()\n                .duration_since(task.started_at.unwrap())\n                .unwrap()\n                \u003c std::time::Duration::from_millis(10)\n        );\n        // finished_at - queue_at\n        assert!(\n            task.finished_at\n                .unwrap()\n                .duration_since(task.queued_at)\n                .unwrap()\n                \u003e= std::time::Duration::from_millis(10)\n        );\n    }\n\n    #[test]\n    fn test_flow() {\n        let mut task = Task::new(TaskData::default());\n\n        task.set_in_progress();\n        task.payload.value += 1;\n\n        std::thread::sleep(std::time::Duration::from_millis(5));\n\n        task.set_retry(\"Wrong task value\");\n        task.payload.value += 1;\n\n        task.set_in_progress();\n        std::thread::sleep(std::time::Duration::from_millis(5));\n\n        task.set_dlq(\"Failed to complete task\");\n\n        match task.status {\n            TaskStatus::DeadLetter =\u003e {}\n            _ =\u003e panic!(\"Wrong status (task.status)\"),\n        };\n        assert_eq!(task.retries, 1);\n        assert_eq!(task.get_payload().value, 2);\n        assert!(task.started_at.is_some());\n        assert!(task.finished_at.is_some());\n\n        // finished_at - started_at\n        assert!(\n            task.finished_at\n                .unwrap()\n                .duration_since(task.started_at.unwrap())\n                .unwrap()\n                \u003c std::time::Duration::from_millis(10)\n        );\n        // finished_at - queue_at\n        assert!(\n            task.finished_at\n                .unwrap()\n                .duration_since(task.queued_at)\n                .unwrap()\n                \u003e= std::time::Duration::from_millis(10)\n        );\n    }\n}\n","traces":[{"line":36,"address":[],"length":0,"stats":{"Line":15}},{"line":38,"address":[],"length":0,"stats":{"Line":15}},{"line":41,"address":[],"length":0,"stats":{"Line":15}},{"line":49,"address":[],"length":0,"stats":{"Line":5}},{"line":50,"address":[],"length":0,"stats":{"Line":5}},{"line":51,"address":[],"length":0,"stats":{"Line":5}},{"line":54,"address":[],"length":0,"stats":{"Line":2}},{"line":55,"address":[],"length":0,"stats":{"Line":2}},{"line":56,"address":[],"length":0,"stats":{"Line":2}},{"line":59,"address":[],"length":0,"stats":{"Line":3}},{"line":60,"address":[],"length":0,"stats":{"Line":3}},{"line":61,"address":[],"length":0,"stats":{"Line":3}},{"line":62,"address":[],"length":0,"stats":{"Line":3}},{"line":63,"address":[],"length":0,"stats":{"Line":3}},{"line":66,"address":[],"length":0,"stats":{"Line":2}},{"line":67,"address":[],"length":0,"stats":{"Line":2}},{"line":68,"address":[],"length":0,"stats":{"Line":2}},{"line":69,"address":[],"length":0,"stats":{"Line":2}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":2}},{"line":77,"address":[],"length":0,"stats":{"Line":2}},{"line":86,"address":[],"length":0,"stats":{"Line":16}},{"line":87,"address":[],"length":0,"stats":{"Line":16}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":10}},{"line":108,"address":[],"length":0,"stats":{"Line":10}},{"line":114,"address":[],"length":0,"stats":{"Line":8}},{"line":119,"address":[],"length":0,"stats":{"Line":16}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}}],"covered":26,"coverable":35},{"path":["/","Users","alexc","code","capp-rs","examples","basic.rs"],"content":"use async_trait::async_trait;\nuse capp::prelude::{\n    Computation, ComputationError, WorkerId, WorkerOptionsBuilder,\n};\nuse capp::{\n    config::Configurable,\n    manager::{WorkersManager, WorkersManagerOptionsBuilder},\n    queue::{AbstractTaskQueue, InMemoryTaskQueue, TaskQueue},\n    task::Task,\n};\nuse serde::{Deserialize, Serialize};\nuse std::{path, sync::Arc};\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct TaskData {\n    pub domain: String,\n    pub value: u32,\n    pub finished: bool,\n}\n\n#[derive(Debug)]\npub struct DivisionComputation;\n\n#[derive(Debug)]\npub struct Context {\n    config: serde_yaml::Value,\n}\n\nimpl Configurable for Context {\n    fn config(\u0026self) -\u003e \u0026serde_yaml::Value {\n        \u0026self.config\n    }\n}\n\nimpl Context {\n    fn from_config(config_file_path: impl AsRef\u003cpath::Path\u003e) -\u003e Self {\n        let config = Self::load_config(config_file_path);\n        Self {\n            config: config.unwrap(),\n        }\n    }\n}\n\n#[async_trait]\nimpl Computation\u003cTaskData, Context\u003e for DivisionComputation {\n    /// TaskRunner will fail tasks which value can't be divided by 3\n    async fn call(\n        \u0026self,\n        worker_id: WorkerId,\n        _ctx: Arc\u003cContext\u003e,\n        _queue: AbstractTaskQueue\u003cTaskData\u003e,\n        task: \u0026mut Task\u003cTaskData\u003e,\n    ) -\u003e Result\u003c(), ComputationError\u003e {\n        tracing::info!(\n            \"[{}] Test division task: {:?}\",\n            worker_id,\n            task.get_payload()\n        );\n\n        let rem = task.payload.value % 3;\n        if rem != 0 {\n            let err_msg =\n                format!(\"[{}] Can't divide {} by 3\", worker_id, task.payload.value);\n            tokio::time::sleep(tokio::time::Duration::from_secs(rem as u64)).await;\n            return Err(ComputationError::Function(err_msg));\n        };\n\n        task.payload.finished = true;\n        tokio::time::sleep(tokio::time::Duration::from_secs(2)).await;\n        Ok(())\n    }\n}\n\n/// Make storage filled with test data.\n/// For current set following conditions should be true:\n/// total tasks = 9\n/// number of failed tasks = 4\nasync fn make_storage() -\u003e impl TaskQueue\u003cTaskData\u003e + Send + Sync {\n    let storage = InMemoryTaskQueue::new();\n\n    for i in 1..=5 {\n        let task: Task\u003cTaskData\u003e = Task::new(TaskData {\n            domain: \"one\".to_string(),\n            value: i,\n            finished: false,\n        });\n        let _ = storage.push(\u0026task).await;\n    }\n\n    for i in 1..=5 {\n        let task: Task\u003cTaskData\u003e = Task::new(TaskData {\n            domain: \"two\".to_string(),\n            value: i * 3,\n            finished: false,\n        });\n        let _ = storage.push(\u0026task).await;\n    }\n\n    for _ in 1..=10 {\n        let task: Task\u003cTaskData\u003e = Task::new(TaskData {\n            domain: \"three\".to_string(),\n            value: 2,\n            finished: false,\n        });\n        let _ = storage.push(\u0026task).await;\n    }\n    storage\n}\n\n#[tokio::main]\nasync fn main() {\n    tracing_subscriber::fmt::init();\n    let config_path = \"tests/simple_config.yml\";\n    let ctx = Context::from_config(config_path);\n    let storage = make_storage().await;\n\n    let computation = DivisionComputation {};\n    let manager_options = WorkersManagerOptionsBuilder::default()\n        .worker_options(\n            WorkerOptionsBuilder::default()\n                .task_limit(10)\n                .build()\n                .unwrap(),\n        )\n        .task_limit(30)\n        .concurrency_limit(4_usize)\n        .build()\n        .unwrap();\n\n    let mut manager =\n        WorkersManager::new(ctx, computation, storage, manager_options);\n    manager.run_workers().await;\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","examples","hackernews","main.rs"],"content":"//! Typical real world example of another one Hackernews crawler!\nuse async_trait::async_trait;\nuse base64::{engine::general_purpose::URL_SAFE, Engine as _};\nuse capp::prelude::{\n    Computation, ComputationError, InMemoryTaskQueue, Task, TaskQueue, WorkerId,\n    WorkerOptionsBuilder, WorkersManager, WorkersManagerOptionsBuilder,\n};\nuse capp::{config::Configurable, http, reqwest};\nuse capp::{tracing, tracing_subscriber};\nuse rand::{seq::SliceRandom, thread_rng};\nuse scraper::{Html, Selector};\nuse serde::{Deserialize, Serialize};\nuse std::io::Write;\nuse std::sync::LazyLock;\nuse std::{\n    collections::HashSet,\n    path,\n    sync::{Arc, Mutex},\n};\nuse url::{ParseError, Url};\n\nconst SEED_URLS: [\u0026str; 1] = [\"https://news.ycombinator.com\"];\n\nstatic URL_SET: LazyLock\u003cMutex\u003cHashSet\u003cString\u003e\u003e\u003e = LazyLock::new(|| {\n    let mut set = HashSet::new();\n    // Add some urls we do not want to add into queue\n    set.insert(\"https://news.ycombinator.com/submit\".into());\n    set.insert(\"https://news.ycombinator.com/jobs\".into());\n    set.insert(\"https://news.ycombinator.com/show\".into());\n    set.insert(\"https://news.ycombinator.com/ask\".into());\n    set.insert(\"https://news.ycombinator.com/newcomments\".into());\n    set.insert(\"https://news.ycombinator.com/front\".into());\n    set.insert(\"https://news.ycombinator.com/newest\".into());\n    Mutex::new(set)\n});\n\n#[derive(Debug)]\npub struct LinkExtractionResult {\n    pub links: Vec\u003cUrl\u003e,\n    pub errors: u32,\n}\n\npub struct CategorizedLinks {\n    general_links: Vec\u003cUrl\u003e,\n}\n\n/// Used to store crawling links\n#[derive(Debug, Clone, Serialize, Deserialize)]\nstruct SiteLink {\n    pub url: String,\n}\n\n#[derive(Debug)]\nstruct HNCrawler {}\n\nstruct Context {\n    config: serde_yaml::Value,\n    pub user_agents: Vec\u003cString\u003e,\n}\n\nimpl Configurable for Context {\n    fn config(\u0026self) -\u003e \u0026serde_yaml::Value {\n        \u0026self.config\n    }\n}\n\nimpl SiteLink {\n    fn new(url: \u0026str) -\u003e Self {\n        Self { url: url.into() }\n    }\n}\n\nimpl Context {\n    async fn from_config(config_file_path: impl AsRef\u003cpath::Path\u003e) -\u003e Self {\n        let config = Self::load_config(config_file_path)\n            .expect(\"Unable to read config file\");\n        let uas_file_path = config[\"app\"][\"user_agents_file\"].as_str().unwrap();\n        let user_agents = Self::load_text_file_lines(uas_file_path)\n            .expect(\"Unable to read user agents file\");\n        Self {\n            config,\n            user_agents,\n        }\n    }\n\n    // Get random user agent\n    pub fn get_random_ua(\u0026self) -\u003e String {\n        self.user_agents\n            .choose(\u0026mut thread_rng())\n            .unwrap()\n            .to_string()\n    }\n}\n\n#[async_trait]\nimpl Computation\u003cSiteLink, Context\u003e for HNCrawler {\n    /// Processor will fail tasks which value can be divided to 3\n    async fn call(\n        \u0026self,\n        worker_id: WorkerId,\n        ctx: Arc\u003cContext\u003e,\n        storage: Arc\u003cdyn TaskQueue\u003cSiteLink\u003e + Send + Sync + 'static\u003e,\n        task: \u0026mut Task\u003cSiteLink\u003e,\n    ) -\u003e Result\u003c(), ComputationError\u003e {\n        tracing::info!(\"[worker-{}] Processing task: {:?}\", worker_id, task);\n\n        let url = task.payload.url.clone();\n        tracing::info!(\"Fetching url: {:?}\", \u0026url);\n\n        let http_client = Self::get_http_client(\u0026ctx.clone());\n        let base_url = Self::extract_base_url(\u0026url).unwrap();\n\n        match Self::fetch_html(http_client, \u0026url).await {\n            Ok((reqwest::StatusCode::OK, text)) =\u003e {\n                tracing::info!(\"[{}] Profile data crawled.\", \u0026url);\n\n                let links = Self::extract_links(\u0026text, \u0026base_url);\n                tracing::info!(\n                    \"Links: {:?} Errors: {:?}\",\n                    links.links.len(),\n                    links.errors\n                );\n                let links = Self::filter_links(links.links);\n                tracing::info!(\"General: {}\", links.general_links.len());\n\n                let links_stored =\n                    Self::store_links_website(links.general_links, storage.clone())\n                        .await\n                        .unwrap();\n                tracing::info!(\"Links stored: {}\", links_stored);\n\n                // If we're on news page store it as file\n                if url.contains(\"item?id=\") {\n                    if let Err(e) =\n                        Self::save_page_to_file(\u0026url, \u0026text, \"target/tmp\")\n                    {\n                        tracing::error!(\"Failed to save page to file: {:?}\", e);\n                    } else {\n                        tracing::info!(\"Page saved successfully.\");\n                    };\n                }\n            }\n            Ok((code, _)) =\u003e {\n                tracing::error!(\"Wrong response code: {}\", code);\n                return Err(ComputationError::Function(\n                    \"Wrong response code\".into(),\n                ));\n            }\n            Err(err) =\u003e {\n                tracing::error!(\"Content fetching error: {}\", err);\n                return Err(ComputationError::Function(\n                    \"Content fetching error\".into(),\n                ));\n            }\n        };\n        Ok(())\n    }\n}\n\nimpl HNCrawler {\n    /// Fetch json content from response received by client\n    pub async fn fetch_html(\n        client: reqwest::Client,\n        url: \u0026str,\n    ) -\u003e reqwest::Result\u003c(reqwest::StatusCode, String)\u003e {\n        let backoff = backoff::ExponentialBackoffBuilder::new()\n            .with_randomization_factor(0.5)\n            .with_max_interval(std::time::Duration::from_secs(10))\n            .with_max_elapsed_time(Some(std::time::Duration::from_secs(30)))\n            .build();\n\n        let fetch_content = || async {\n            let response = client\n                .get(url)\n                .header(\"Accept\", \"text/html,*/*;q=0.8\")\n                .header(\"Accept-Language\", \"en-US,en;q=0.5\")\n                .header(\"Accept-Encoding\", \"gzip, deflate\")\n                .send()\n                .await?;\n            let status = response.status();\n            let text = response.text().await?;\n            Ok((status, text))\n        };\n\n        tracing::info!(\"[{}] retrieving url...\", url);\n        backoff::future::retry(backoff, fetch_content).await\n    }\n\n    // Store links to website for further crawling\n    async fn store_links_website(\n        links: Vec\u003cUrl\u003e,\n        storage: Arc\u003cdyn TaskQueue\u003cSiteLink\u003e + Send + Sync\u003e,\n    ) -\u003e Result\u003cusize, anyhow::Error\u003e {\n        let mut links_stored = 0;\n        tracing::info!(\"Adding {} links to the queue...\", links.len());\n\n        for link in links.iter() {\n            let link_str = link.as_str().to_owned();\n\n            let should_store = {\n                // Scoped lock acquisition\n                let mut url_set_guard = URL_SET.lock().unwrap();\n                url_set_guard.insert(link_str.clone())\n            };\n\n            if should_store {\n                let link_data = SiteLink { url: link_str };\n                storage.push(\u0026Task::new(link_data)).await?;\n                links_stored += 1;\n            }\n        }\n\n        Ok(links_stored)\n    }\n\n    // Extract links using: DOM Tree -\u003e CSS Selector -\u003e links\n    pub fn extract_links(content: \u0026str, base_url: \u0026Url) -\u003e LinkExtractionResult {\n        let document = Html::parse_document(content);\n        let selector = Selector::parse(\"a[href]\").unwrap();\n\n        let mut links = Vec::new();\n        let mut errors = 0;\n\n        for element in document.select(\u0026selector) {\n            if let Some(href) = element.value().attr(\"href\") {\n                let url = base_url.join(href);\n                match url {\n                    Ok(absolute_url) =\u003e links.push(absolute_url),\n                    Err(ParseError::RelativeUrlWithoutBase) =\u003e {\n                        // Attempt to parse it as an absolute URL if it\n                        // fails due to being a relative URL without a base.\n                        match Url::parse(href) {\n                            Ok(absolute_url) =\u003e links.push(absolute_url),\n                            Err(_) =\u003e errors += 1,\n                        }\n                    }\n                    Err(_) =\u003e errors += 1,\n                };\n            }\n        }\n\n        LinkExtractionResult { links, errors }\n    }\n\n    /// Filter links, left general links inside website and links to profiles\n    pub fn filter_links(links: Vec\u003cUrl\u003e) -\u003e CategorizedLinks {\n        let mut general_links = Vec::new();\n\n        for url in links {\n            match url.domain() {\n                Some(domain) if domain == \"news.ycombinator.com\" =\u003e {\n                    tracing::debug!(\"Url path: {}\", url.path());\n                    if url.path().contains(\"/user\")\n                        || url.path().contains(\"/vote\")\n                        || url.path().contains(\"/hide\")\n                    {\n                        continue;\n                    }\n\n                    general_links.push(url);\n                }\n                Some(domain) =\u003e {\n                    tracing::debug!(\"Skipping URL with domain: {}\", domain);\n                    continue;\n                }\n                None =\u003e {\n                    tracing::debug!(\"URL has no domain: {}\", url);\n                    continue;\n                }\n            };\n        }\n\n        CategorizedLinks { general_links }\n    }\n\n    pub fn get_http_client(ctx: \u0026Context) -\u003e reqwest::Client {\n        let proxy_provider = ctx.config()[\"app\"][\"proxy_provider\"]\n            .as_str()\n            .expect(\"Can't find app.proxy_provider settings\");\n        let client: reqwest::Client =\n            http::build_http_client(http::HttpClientParams::from_config(\n                \u0026ctx.config()[proxy_provider],\n                \u0026ctx.get_random_ua(),\n            ))\n            .unwrap();\n        client\n    }\n\n    // save page to file\n    fn save_page_to_file(\n        url: \u0026str,\n        text: \u0026str,\n        base_dir: \u0026str,\n    ) -\u003e Result\u003c(), anyhow::Error\u003e {\n        // Generate the MD5 hash of the URL\n        let md5_hash = md5::compute(url);\n        let hash_prefix = format!(\"{:x}\", \u0026md5_hash)[..4].to_string();\n\n        // Encode the URL to a valid filename using base64\n        let encoded_string = URL_SAFE.encode(url.as_bytes());\n\n        // Create the directory if it doesn't exist\n        let dir_path = std::path::Path::new(base_dir).join(\u0026hash_prefix);\n        std::fs::create_dir_all(\u0026dir_path)?;\n\n        // Construct the file path\n        // let encoded_filename = std::str::from_utf8(encoded_bytes)?.to_string();\n        let file_path = dir_path.join(format!(\"{}.html\", encoded_string));\n\n        // Open the file in write mode\n        let mut file = std::fs::File::create(file_path)?;\n\n        // Write the content to the file\n        file.write_all(text.as_bytes())?;\n\n        Ok(())\n    }\n\n    /// Try to extract base_url from url\n    fn extract_base_url(input_url: \u0026str) -\u003e Option\u003cUrl\u003e {\n        let parsed_url = Url::parse(input_url).ok()?;\n\n        let base_url = format!(\n            \"{}://{}{}\",\n            parsed_url.scheme(),\n            parsed_url.host_str()?, // Returns None if no host present\n            match parsed_url.port() {\n                Some(port) =\u003e format!(\":{}\", port), // Include the port if present\n                None =\u003e String::new(),\n            }\n        );\n\n        Url::parse(\u0026base_url).ok()\n    }\n}\n\n#[tokio::main]\nasync fn main() {\n    tracing_subscriber::fmt::init();\n    let ctx =\n        Arc::new(Context::from_config(\"examples/hackernews/hn_config.yml\").await);\n\n    tracing::info!(\"Starting HN crawler...\");\n\n    let manager_options = WorkersManagerOptionsBuilder::default()\n        .worker_options(\n            WorkerOptionsBuilder::default()\n                .max_retries(10_u32)\n                .build()\n                .unwrap(),\n        )\n        .concurrency_limit(4_usize)\n        .build()\n        .unwrap();\n\n    let storage: InMemoryTaskQueue\u003cSiteLink\u003e = InMemoryTaskQueue::new();\n    let tasks_queue_len = storage.list.lock().unwrap().len();\n\n    tracing::info!(\"Website links tasks in queue: {}\", tasks_queue_len);\n    // Add seed urls\n    if tasks_queue_len == 0 {\n        tracing::warn!(\"Queue is empty! Seeding urls... {}\", SEED_URLS.join(\" \"));\n        for url in SEED_URLS.iter() {\n            let initial_task = Task::new(SiteLink::new(url));\n            let _ = storage.push(\u0026initial_task).await;\n        }\n    }\n\n    let computation = Arc::new(HNCrawler {});\n    let mut manager = WorkersManager::new_from_arcs(\n        ctx.clone(),\n        computation,\n        Arc::new(storage),\n        manager_options,\n    );\n    manager.run_workers().await;\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","tests","common","http_server.rs"],"content":"use bytes::Bytes;\nuse http_body_util::Full;\nuse hyper::server::conn::http1;\nuse hyper::service::Service;\nuse hyper::{body::Incoming as IncomingBody, Request, Response};\nuse tokio::net::TcpListener;\n\nuse std::future::Future;\nuse std::net::SocketAddr;\nuse std::pin::Pin;\n\nmod support;\nuse support::TokioIo;\n\npub trait ServiceFactory {\n    type ServiceType: Service\u003c\n            Request\u003cIncomingBody\u003e,\n            Response = Response\u003cFull\u003cBytes\u003e\u003e,\n            Error = hyper::Error,\n        \u003e + Send\n        + 'static;\n\n    fn create_service(\u0026self) -\u003e Self::ServiceType;\n}\n\npub struct TestService;\npub struct TestServiceFactory;\n\nimpl ServiceFactory for TestServiceFactory {\n    type ServiceType = TestService;\n\n    fn create_service(\u0026self) -\u003e Self::ServiceType {\n        TestService::new()\n    }\n}\n\nimpl Service\u003cRequest\u003cIncomingBody\u003e\u003e for TestService {\n    type Response = Response\u003cFull\u003cBytes\u003e\u003e;\n    type Error = hyper::Error;\n    type Future =\n        Pin\u003cBox\u003cdyn Future\u003cOutput = Result\u003cSelf::Response, Self::Error\u003e\u003e + Send\u003e\u003e;\n\n    fn call(\u0026self, req: Request\u003cIncomingBody\u003e) -\u003e Self::Future {\n        fn ok_response(s: String) -\u003e Result\u003cResponse\u003cFull\u003cBytes\u003e\u003e, hyper::Error\u003e {\n            Ok(Response::builder().body(Full::new(Bytes::from(s))).unwrap())\n        }\n\n        fn fail_response(s: String) -\u003e Result\u003cResponse\u003cFull\u003cBytes\u003e\u003e, hyper::Error\u003e {\n            Ok(Response::builder()\n                .status(hyper::StatusCode::NOT_FOUND)\n                .body(Full::new(Bytes::from(s)))\n                .unwrap())\n        }\n\n        let res = match req.uri().path() {\n            \"/\" =\u003e ok_response(format!(\"here\")),\n            // Return the 404 Not Found for other routes.\n            _ =\u003e return Box::pin(async { fail_response(\"not found\".into()) }),\n        };\n\n        Box::pin(async { res })\n    }\n}\n\nimpl TestService {\n    fn new() -\u003e Self {\n        Self {}\n    }\n}\n\npub async fn run_service\u003cF\u003e(port: u16, service_factory: F) -\u003e anyhow::Result\u003c()\u003e\nwhere\n    F: ServiceFactory + Send + 'static,\n    \u003c\u003cF as ServiceFactory\u003e::ServiceType as Service\u003c\n        hyper::Request\u003chyper::body::Incoming\u003e,\n    \u003e\u003e::Future: Send,\n{\n    let addr: SocketAddr = ([127, 0, 0, 1], port).into();\n\n    let listener = TcpListener::bind(\u0026addr).await?;\n    println!(\"Listening on http://{}\", addr);\n\n    loop {\n        let (stream, _) = listener.accept().await?;\n        let io = TokioIo::new(stream);\n        let service = service_factory.create_service();\n        tokio::task::spawn(async move {\n            if let Err(err) =\n                http1::Builder::new().serve_connection(io, service).await\n            {\n                println!(\"Failed to serve connection: {:?}\", err);\n            }\n        });\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","tests","common","support.rs"],"content":"#![allow(dead_code)]\n//! Various runtimes for hyper\nuse std::{\n    future::Future,\n    pin::Pin,\n    task::{Context, Poll},\n    time::{Duration, Instant},\n};\n\nuse hyper::rt::{Sleep, Timer};\nuse pin_project_lite::pin_project;\n\n#[derive(Clone)]\n/// An Executor that uses the tokio runtime.\npub struct TokioExecutor;\n\nimpl\u003cF\u003e hyper::rt::Executor\u003cF\u003e for TokioExecutor\nwhere\n    F: std::future::Future + Send + 'static,\n    F::Output: Send + 'static,\n{\n    fn execute(\u0026self, fut: F) {\n        tokio::task::spawn(fut);\n    }\n}\n\n/// A Timer that uses the tokio runtime.\n\n#[derive(Clone, Debug)]\npub struct TokioTimer;\n\nimpl Timer for TokioTimer {\n    fn sleep(\u0026self, duration: Duration) -\u003e Pin\u003cBox\u003cdyn Sleep\u003e\u003e {\n        Box::pin(TokioSleep {\n            inner: tokio::time::sleep(duration),\n        })\n    }\n\n    fn sleep_until(\u0026self, deadline: Instant) -\u003e Pin\u003cBox\u003cdyn Sleep\u003e\u003e {\n        Box::pin(TokioSleep {\n            inner: tokio::time::sleep_until(deadline.into()),\n        })\n    }\n\n    fn reset(\u0026self, sleep: \u0026mut Pin\u003cBox\u003cdyn Sleep\u003e\u003e, new_deadline: Instant) {\n        if let Some(sleep) = sleep.as_mut().downcast_mut_pin::\u003cTokioSleep\u003e() {\n            sleep.reset(new_deadline.into())\n        }\n    }\n}\n\nstruct TokioTimeout\u003cT\u003e {\n    inner: Pin\u003cBox\u003ctokio::time::Timeout\u003cT\u003e\u003e\u003e,\n}\n\nimpl\u003cT\u003e Future for TokioTimeout\u003cT\u003e\nwhere\n    T: Future,\n{\n    type Output = Result\u003cT::Output, tokio::time::error::Elapsed\u003e;\n\n    fn poll(\n        mut self: Pin\u003c\u0026mut Self\u003e,\n        context: \u0026mut Context\u003c'_\u003e,\n    ) -\u003e Poll\u003cSelf::Output\u003e {\n        self.inner.as_mut().poll(context)\n    }\n}\n\n// Use TokioSleep to get tokio::time::Sleep to implement Unpin.\n// see https://docs.rs/tokio/latest/tokio/time/struct.Sleep.html\npin_project! {\n    pub(crate) struct TokioSleep {\n        #[pin]\n        pub(crate) inner: tokio::time::Sleep,\n    }\n}\n\nimpl Future for TokioSleep {\n    type Output = ();\n\n    fn poll(self: Pin\u003c\u0026mut Self\u003e, cx: \u0026mut Context\u003c'_\u003e) -\u003e Poll\u003cSelf::Output\u003e {\n        self.project().inner.poll(cx)\n    }\n}\n\nimpl Sleep for TokioSleep {}\n\nimpl TokioSleep {\n    pub fn reset(self: Pin\u003c\u0026mut Self\u003e, deadline: Instant) {\n        self.project().inner.as_mut().reset(deadline.into());\n    }\n}\n\npin_project! {\n    #[derive(Debug)]\n    pub struct TokioIo\u003cT\u003e {\n        #[pin]\n        inner: T,\n    }\n}\n\nimpl\u003cT\u003e TokioIo\u003cT\u003e {\n    pub fn new(inner: T) -\u003e Self {\n        Self { inner }\n    }\n\n    pub fn inner(self) -\u003e T {\n        self.inner\n    }\n}\n\nimpl\u003cT\u003e hyper::rt::Read for TokioIo\u003cT\u003e\nwhere\n    T: tokio::io::AsyncRead,\n{\n    fn poll_read(\n        self: Pin\u003c\u0026mut Self\u003e,\n        cx: \u0026mut Context\u003c'_\u003e,\n        mut buf: hyper::rt::ReadBufCursor\u003c'_\u003e,\n    ) -\u003e Poll\u003cResult\u003c(), std::io::Error\u003e\u003e {\n        let n = unsafe {\n            let mut tbuf = tokio::io::ReadBuf::uninit(buf.as_mut());\n            match tokio::io::AsyncRead::poll_read(\n                self.project().inner,\n                cx,\n                \u0026mut tbuf,\n            ) {\n                Poll::Ready(Ok(())) =\u003e tbuf.filled().len(),\n                other =\u003e return other,\n            }\n        };\n\n        unsafe {\n            buf.advance(n);\n        }\n        Poll::Ready(Ok(()))\n    }\n}\n\nimpl\u003cT\u003e hyper::rt::Write for TokioIo\u003cT\u003e\nwhere\n    T: tokio::io::AsyncWrite,\n{\n    fn poll_write(\n        self: Pin\u003c\u0026mut Self\u003e,\n        cx: \u0026mut Context\u003c'_\u003e,\n        buf: \u0026[u8],\n    ) -\u003e Poll\u003cResult\u003cusize, std::io::Error\u003e\u003e {\n        tokio::io::AsyncWrite::poll_write(self.project().inner, cx, buf)\n    }\n\n    fn poll_flush(\n        self: Pin\u003c\u0026mut Self\u003e,\n        cx: \u0026mut Context\u003c'_\u003e,\n    ) -\u003e Poll\u003cResult\u003c(), std::io::Error\u003e\u003e {\n        tokio::io::AsyncWrite::poll_flush(self.project().inner, cx)\n    }\n\n    fn poll_shutdown(\n        self: Pin\u003c\u0026mut Self\u003e,\n        cx: \u0026mut Context\u003c'_\u003e,\n    ) -\u003e Poll\u003cResult\u003c(), std::io::Error\u003e\u003e {\n        tokio::io::AsyncWrite::poll_shutdown(self.project().inner, cx)\n    }\n\n    fn is_write_vectored(\u0026self) -\u003e bool {\n        tokio::io::AsyncWrite::is_write_vectored(\u0026self.inner)\n    }\n\n    fn poll_write_vectored(\n        self: Pin\u003c\u0026mut Self\u003e,\n        cx: \u0026mut Context\u003c'_\u003e,\n        bufs: \u0026[std::io::IoSlice\u003c'_\u003e],\n    ) -\u003e Poll\u003cResult\u003cusize, std::io::Error\u003e\u003e {\n        tokio::io::AsyncWrite::poll_write_vectored(self.project().inner, cx, bufs)\n    }\n}\n\nimpl\u003cT\u003e tokio::io::AsyncRead for TokioIo\u003cT\u003e\nwhere\n    T: hyper::rt::Read,\n{\n    fn poll_read(\n        self: Pin\u003c\u0026mut Self\u003e,\n        cx: \u0026mut Context\u003c'_\u003e,\n        tbuf: \u0026mut tokio::io::ReadBuf\u003c'_\u003e,\n    ) -\u003e Poll\u003cResult\u003c(), std::io::Error\u003e\u003e {\n        //let init = tbuf.initialized().len();\n        let filled = tbuf.filled().len();\n        let sub_filled = unsafe {\n            let mut buf = hyper::rt::ReadBuf::uninit(tbuf.unfilled_mut());\n\n            match hyper::rt::Read::poll_read(\n                self.project().inner,\n                cx,\n                buf.unfilled(),\n            ) {\n                Poll::Ready(Ok(())) =\u003e buf.filled().len(),\n                other =\u003e return other,\n            }\n        };\n\n        let n_filled = filled + sub_filled;\n        // At least sub_filled bytes had to have been initialized.\n        let n_init = sub_filled;\n        unsafe {\n            tbuf.assume_init(n_init);\n            tbuf.set_filled(n_filled);\n        }\n\n        Poll::Ready(Ok(()))\n    }\n}\n\nimpl\u003cT\u003e tokio::io::AsyncWrite for TokioIo\u003cT\u003e\nwhere\n    T: hyper::rt::Write,\n{\n    fn poll_write(\n        self: Pin\u003c\u0026mut Self\u003e,\n        cx: \u0026mut Context\u003c'_\u003e,\n        buf: \u0026[u8],\n    ) -\u003e Poll\u003cResult\u003cusize, std::io::Error\u003e\u003e {\n        hyper::rt::Write::poll_write(self.project().inner, cx, buf)\n    }\n\n    fn poll_flush(\n        self: Pin\u003c\u0026mut Self\u003e,\n        cx: \u0026mut Context\u003c'_\u003e,\n    ) -\u003e Poll\u003cResult\u003c(), std::io::Error\u003e\u003e {\n        hyper::rt::Write::poll_flush(self.project().inner, cx)\n    }\n\n    fn poll_shutdown(\n        self: Pin\u003c\u0026mut Self\u003e,\n        cx: \u0026mut Context\u003c'_\u003e,\n    ) -\u003e Poll\u003cResult\u003c(), std::io::Error\u003e\u003e {\n        hyper::rt::Write::poll_shutdown(self.project().inner, cx)\n    }\n\n    fn is_write_vectored(\u0026self) -\u003e bool {\n        hyper::rt::Write::is_write_vectored(\u0026self.inner)\n    }\n\n    fn poll_write_vectored(\n        self: Pin\u003c\u0026mut Self\u003e,\n        cx: \u0026mut Context\u003c'_\u003e,\n        bufs: \u0026[std::io::IoSlice\u003c'_\u003e],\n    ) -\u003e Poll\u003cResult\u003cusize, std::io::Error\u003e\u003e {\n        hyper::rt::Write::poll_write_vectored(self.project().inner, cx, bufs)\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","tests","common.rs"],"content":"#[path = \"common/http_server.rs\"]\npub mod http_server;\n\n#[path = \"common/support.rs\"]\npub mod support;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","tests","healthcheck_tests.rs"],"content":"mod common;\n\n#[cfg(test)]\nmod tests {\n    use crate::common::http_server::{run_service, TestServiceFactory};\n    use capp::healthcheck::internet;\n\n    #[test]\n    fn ping_healthcheck_service() {\n        let rt = tokio::runtime::Runtime::new().unwrap();\n        let _server_handle = rt.spawn(run_service(3000, TestServiceFactory));\n\n        // Wait for the test server to start\n        std::thread::sleep(std::time::Duration::from_millis(100));\n\n        let rt = tokio::runtime::Runtime::new().unwrap();\n        let result =\n            rt.block_on(async { internet(\"http://127.0.0.1:3000/fail\").await });\n\n        assert_eq!(result, true);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","tests","http_tests.rs"],"content":"mod common;\n\n#[cfg(test)]\nmod tests {\n    use crate::common::http_server::{run_service, TestServiceFactory};\n    use capp::http::{\n        build_http_client, fetch_url, fetch_url_content, HttpClientParams,\n    };\n\n    // pub async fn start_test_server(addr: SocketAddr) {\n    //     let make_svc = make_service_fn(|_conn| async {\n    //         Ok::\u003c_, hyper::Error\u003e(service_fn(handle_request))\n    //     });\n\n    //     let server = Server::bind(\u0026addr).serve(make_svc);\n    //     println!(\"Test server running on http://{}\", addr);\n\n    //     if let Err(e) = server.await {\n    //         eprintln!(\"Server error: {}\", e);\n    //     }\n    // }\n\n    // async fn handle_request(\n    //     _req: Request\u003cBody\u003e,\n    // ) -\u003e Result\u003cResponse\u003cBody\u003e, hyper::Error\u003e {\n    //     let response = Response::builder()\n    //         .status(200)\n    //         .body(Body::from(\"Hello, World!\"))\n    //         .unwrap();\n    //     Ok(response)\n    // }\n\n    #[test]\n    fn test_http_request() {\n        let rt = tokio::runtime::Runtime::new().unwrap();\n        let _server_handle = rt.spawn(run_service(3000, TestServiceFactory));\n\n        // Wait for the test server to start\n        std::thread::sleep(std::time::Duration::from_millis(100));\n\n        let params = HttpClientParams {\n            proxy_provider: None,\n            timeout: 5,\n            connect_timeout: 2,\n            user_agent: \"test-client\",\n        };\n\n        let client = build_http_client(params).expect(\"Failed to build client\");\n\n        let rt = tokio::runtime::Runtime::new().unwrap();\n        let resp = rt.block_on(async {\n            fetch_url(client.clone(), \"http://127.0.0.1:3000\")\n                .await\n                .ok()\n                .unwrap()\n        });\n\n        assert_eq!(resp.status(), 200);\n\n        let rt = tokio::runtime::Runtime::new().unwrap();\n        let resp = rt.block_on(async {\n            fetch_url_content(client, \"http://127.0.0.1:3000/fail\")\n                .await\n                .ok()\n                .unwrap()\n        });\n\n        assert_eq!(\n            (reqwest::StatusCode::NOT_FOUND, \"not found\".to_string()),\n            resp\n        );\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","tests","manager_tests.rs"],"content":"#[cfg(test)]\nmod tests {\n    use async_trait::async_trait;\n    use capp::config::Configurable;\n    use capp::manager::{\n        Computation, ComputationError, WorkerId, WorkerOptionsBuilder,\n        WorkersManager, WorkersManagerOptionsBuilder,\n    };\n    use capp::queue::{AbstractTaskQueue, InMemoryTaskQueue, TaskQueue};\n    use capp::task::Task;\n    use serde::{Deserialize, Serialize};\n    use std::sync::Arc;\n    use tokio::runtime::Runtime;\n\n    #[derive(Debug, Clone, Serialize, Deserialize)]\n    pub struct TestData {\n        pub domain: String,\n        pub value: u32,\n        pub finished: bool,\n    }\n\n    #[derive(Debug)]\n    pub struct TestComputation {}\n\n    #[derive(Debug, Serialize, Deserialize)]\n    pub struct Context {\n        name: String,\n        config: serde_yaml::Value,\n        is_test: bool,\n    }\n\n    impl Configurable for Context {\n        fn config(\u0026self) -\u003e \u0026serde_yaml::Value {\n            \u0026self.config\n        }\n    }\n\n    impl Context {\n        fn from_config(config_file_path: impl AsRef\u003cstd::path::Path\u003e) -\u003e Self {\n            let config = Self::load_config(config_file_path);\n            Self {\n                name: \"test-app\".to_string(),\n                is_test: true,\n                config: config.unwrap(),\n            }\n        }\n    }\n\n    #[async_trait]\n    impl Computation\u003cTestData, Context\u003e for TestComputation {\n        /// Process will fail tasks which value can be divided to 3\n        async fn call(\n            \u0026self,\n            worker_id: WorkerId,\n            _ctx: Arc\u003cContext\u003e,\n            _storage: AbstractTaskQueue\u003cTestData\u003e,\n            task: \u0026mut Task\u003cTestData\u003e,\n        ) -\u003e Result\u003c(), ComputationError\u003e {\n            tracing::info!(\"[worker-{}] Processing task: {:?}\", worker_id, task);\n            let rem = task.payload.value % 3;\n            // fail if can be divided by 3\n            if rem == 0 {\n                return Err(ComputationError::Function(format!(\n                    \"Can be divide {} to 3\",\n                    \u0026task.payload.value\n                )));\n            };\n\n            task.payload.finished = true;\n            Ok(())\n        }\n    }\n\n    /// Make storage filled with test data.\n    /// For current set following conditions should be true:\n    /// total tasks = 9\n    /// number of failed tasks = 4\n    fn make_storage() -\u003e InMemoryTaskQueue\u003cTestData\u003e {\n        let storage = InMemoryTaskQueue::new();\n\n        let rt = Runtime::new().unwrap();\n\n        // Only 1 number can be divided by 3\n        for i in 1..=3 {\n            let task: Task\u003cTestData\u003e = Task::new(TestData {\n                domain: \"one\".to_string(),\n                value: i,\n                finished: false,\n            });\n            let _ = rt.block_on(storage.push(\u0026task));\n        }\n\n        // all 3 numbers can be divided by 3\n        for i in 1..=3 {\n            let task: Task\u003cTestData\u003e = Task::new(TestData {\n                domain: \"two\".to_string(),\n                value: i * 3,\n                finished: false,\n            });\n            let _ = rt.block_on(storage.push(\u0026task));\n        }\n\n        // No numbers can be divided by 3\n        for _ in 1..=3 {\n            let task: Task\u003cTestData\u003e = Task::new(TestData {\n                domain: \"three\".to_string(),\n                value: 2,\n                finished: false,\n            });\n            let _ = rt.block_on(storage.push(\u0026task));\n        }\n        storage\n    }\n\n    #[test]\n    fn test_storage() {\n        let storage = make_storage();\n        assert_eq!(storage.list.lock().unwrap().len(), 9);\n    }\n\n    #[test]\n    fn test_manager() {\n        let rt = Runtime::new().unwrap();\n\n        let ctx = Arc::new(Context::from_config(\"tests/simple_config.yml\"));\n        let storage = Arc::new(make_storage());\n\n        let storage_len_before = storage.list.lock().unwrap().len();\n        assert_eq!(storage_len_before, 9);\n\n        let computation = Arc::new(TestComputation {});\n        let manager_options = WorkersManagerOptionsBuilder::default()\n            .worker_options(\n                WorkerOptionsBuilder::default()\n                    .max_retries(10_u32)\n                    .task_limit(3)\n                    .no_task_found_delay(std::time::Duration::from_millis(50))\n                    .build()\n                    .unwrap(),\n            )\n            .concurrency_limit(1 as usize)\n            .task_limit(Some(9))\n            .build()\n            .unwrap();\n\n        let mut manager = WorkersManager::new_from_arcs(\n            ctx,\n            computation,\n            storage.clone(),\n            manager_options,\n        );\n        rt.block_on(manager.run_workers());\n\n        let storage_len_after = storage.list.lock().unwrap().len();\n\n        // 4 tasks should fail\n        assert_eq!(storage_len_after, 7);\n        // all successful tasks should be removed from storage\n        // 7 should left\n        let keys_len = storage.hashmap.lock().unwrap().len();\n        assert_eq!(keys_len, 7);\n\n        // dbg!(\u0026storage);\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","tests","redis_rr_tests.rs"],"content":"#[cfg(test)]\nmod tests {\n    use capp::queue::{\n        HasTagKey, RedisRoundRobinTaskQueue, TaskQueue, TaskQueueError,\n    };\n    use capp::task::Task;\n    use dotenvy::dotenv;\n    use rustis::client::Client;\n    use rustis::commands::{GenericCommands, HashCommands, ListCommands};\n    use serde::{Deserialize, Serialize};\n    use std::collections::HashSet;\n    use tokio;\n\n    #[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n    struct TestData {\n        value: u32,\n        tag: String,\n    }\n\n    impl HasTagKey for TestData {\n        type TagValue = String;\n        fn get_tag_value(\u0026self) -\u003e Self::TagValue {\n            self.tag.clone()\n        }\n    }\n\n    async fn get_redis_connection() -\u003e Client {\n        dotenv().ok();\n        let uri = std::env::var(\"REDIS_URI\").expect(\"Set REDIS_URI env variable\");\n        Client::connect(uri)\n            .await\n            .expect(\"Error while establishing redis connection\")\n    }\n\n    async fn setup_queue(test_name: \u0026str) -\u003e RedisRoundRobinTaskQueue\u003cTestData\u003e {\n        let redis = get_redis_connection().await;\n        let tags = HashSet::from([\n            \"tag1\".to_string(),\n            \"tag2\".to_string(),\n            \"tag3\".to_string(),\n        ]);\n        let unique_name = format!(\"capp-test-redis-rr-{}\", test_name);\n        RedisRoundRobinTaskQueue::new(redis, \u0026unique_name, tags)\n            .await\n            .expect(\"Failed to create RedisRoundRobinTaskQueue\")\n    }\n\n    async fn cleanup_queue(queue: \u0026RedisRoundRobinTaskQueue\u003cTestData\u003e) {\n        let mut keys_to_delete = vec![\n            queue.get_hashmap_key(),\n            queue.get_list_key(\"tag1\"),\n            queue.get_list_key(\"tag2\"),\n            queue.get_list_key(\"tag3\"),\n            queue.get_dlq_key(),\n        ];\n        // Add counter keys to the list of keys to delete\n        keys_to_delete.extend(queue.get_counter_keys());\n        queue\n            .client\n            .del(keys_to_delete)\n            .await\n            .expect(\"Failed to clean up Redis keys\");\n    }\n\n    #[tokio::test]\n    async fn test_typical_workflow() {\n        let queue = setup_queue(\"workflow\").await;\n        cleanup_queue(\u0026queue).await;\n\n        // Push tasks with different tags\n        let task1 = Task::new(TestData {\n            value: 1,\n            tag: \"tag1\".to_string(),\n        });\n        let task2 = Task::new(TestData {\n            value: 2,\n            tag: \"tag2\".to_string(),\n        });\n        let task3 = Task::new(TestData {\n            value: 3,\n            tag: \"tag3\".to_string(),\n        });\n\n        queue.push(\u0026task1).await.expect(\"Failed to push task1\");\n        queue.push(\u0026task2).await.expect(\"Failed to push task2\");\n        queue.push(\u0026task3).await.expect(\"Failed to push task3\");\n\n        // Pop tasks and check round-robin order\n        let popped_task1 = queue.pop().await.expect(\"Failed to pop task1\");\n        let popped_task2 = queue.pop().await.expect(\"Failed to pop task2\");\n        let popped_task3 = queue.pop().await.expect(\"Failed to pop task3\");\n\n        // Check that all tags are represented\n        let popped_tags: HashSet\u003cString\u003e = vec![\n            popped_task1.payload.tag.clone(),\n            popped_task2.payload.tag.clone(),\n            popped_task3.payload.tag.clone(),\n        ]\n        .into_iter()\n        .collect();\n\n        assert_eq!(\n            popped_tags,\n            HashSet::from([\n                \"tag1\".to_string(),\n                \"tag2\".to_string(),\n                \"tag3\".to_string()\n            ]),\n            \"All tags should be represented in the popped tasks\"\n        );\n\n        // Ack one task, nack another, and check queue state\n        queue\n            .ack(\u0026popped_task1.task_id)\n            .await\n            .expect(\"Failed to ack task1\");\n        queue\n            .nack(\u0026popped_task2)\n            .await\n            .expect(\"Failed to nack task2\");\n\n        let hashmap_len = queue\n            .client\n            .hlen(\u0026queue.get_hashmap_key())\n            .await\n            .expect(\"Failed to get hashmap length\");\n        assert_eq!(hashmap_len, 1, \"Only one task should remain in the hashmap\");\n\n        let dlq_len = queue\n            .client\n            .llen(\u0026queue.get_dlq_key())\n            .await\n            .expect(\"Failed to get DLQ length\");\n        assert_eq!(dlq_len, 1, \"One task should be in the DLQ\");\n\n        cleanup_queue(\u0026queue).await;\n    }\n\n    #[tokio::test]\n    async fn test_push_and_pop() {\n        let queue = setup_queue(\"push-pop\").await;\n        cleanup_queue(\u0026queue).await;\n        let task = Task::new(TestData {\n            value: 42,\n            tag: \"tag1\".to_string(),\n        });\n\n        queue.push(\u0026task).await.expect(\"Failed to push task\");\n\n        let popped_task = queue.pop().await.expect(\"Failed to pop task\");\n        assert_eq!(popped_task.payload, task.payload);\n\n        cleanup_queue(\u0026queue).await;\n    }\n\n    #[tokio::test]\n    async fn test_empty_queue() {\n        let queue = setup_queue(\"empty-queue\").await;\n        cleanup_queue(\u0026queue).await;\n\n        let task_1 = Task::new(TestData {\n            value: 1,\n            tag: \"tag1\".to_string(),\n        });\n\n        let task_2 = Task::new(TestData {\n            value: 2,\n            tag: \"tag2\".to_string(),\n        });\n\n        let task_3 = Task::new(TestData {\n            value: 3,\n            tag: \"tag2\".to_string(),\n        });\n\n        queue.push(\u0026task_1).await.expect(\"Failed to push task\");\n        queue.push(\u0026task_2).await.expect(\"Failed to push task\");\n        queue.push(\u0026task_3).await.expect(\"Failed to push task\");\n\n        queue.pop().await.expect(\"Failed to pop task\");\n        queue.pop().await.expect(\"Failed to pop task\");\n        queue.pop().await.expect(\"Failed to pop task\");\n\n        let should_be_error = queue.pop().await;\n        assert!(should_be_error.is_err());\n\n        cleanup_queue(\u0026queue).await;\n    }\n\n    #[tokio::test]\n    async fn test_round_robin_behavior() {\n        let queue = setup_queue(\"round-robin\").await;\n        cleanup_queue(\u0026queue).await;\n\n        let tasks = vec![\n            Task::new(TestData {\n                value: 1,\n                tag: \"tag1\".to_string(),\n            }),\n            Task::new(TestData {\n                value: 2,\n                tag: \"tag2\".to_string(),\n            }),\n            Task::new(TestData {\n                value: 3,\n                tag: \"tag3\".to_string(),\n            }),\n            Task::new(TestData {\n                value: 4,\n                tag: \"tag1\".to_string(),\n            }),\n            Task::new(TestData {\n                value: 5,\n                tag: \"tag2\".to_string(),\n            }),\n            Task::new(TestData {\n                value: 6,\n                tag: \"tag3\".to_string(),\n            }),\n        ];\n\n        for task in \u0026tasks {\n            queue.push(task).await.expect(\"Failed to push task\");\n        }\n\n        let mut popped_values = Vec::new();\n        for _ in 0..6 {\n            let popped_task = queue.pop().await.expect(\"Failed to pop task\");\n            popped_values.push(popped_task.payload.value);\n        }\n\n        assert_eq!(popped_values.len(), 6, \"Should have popped 6 tasks\");\n        assert!(\n            popped_values.contains(\u00261) \u0026\u0026 popped_values.contains(\u00264),\n            \"Should contain both tag1 tasks\"\n        );\n        assert!(\n            popped_values.contains(\u00262) \u0026\u0026 popped_values.contains(\u00265),\n            \"Should contain both tag2 tasks\"\n        );\n        assert!(\n            popped_values.contains(\u00263) \u0026\u0026 popped_values.contains(\u00266),\n            \"Should contain both tag3 tasks\"\n        );\n\n        // Attempt to pop again, should be empty\n        match queue.pop().await {\n            Err(TaskQueueError::QueueEmpty) =\u003e (),\n            _ =\u003e panic!(\"Queue not empty!\"),\n        }\n        cleanup_queue(\u0026queue).await;\n    }\n\n    #[tokio::test]\n    async fn test_ack() {\n        let queue = setup_queue(\"ack\").await;\n        cleanup_queue(\u0026queue).await;\n        let task = Task::new(TestData {\n            value: 42,\n            tag: \"tag1\".to_string(),\n        });\n\n        queue.push(\u0026task).await.expect(\"Failed to push task\");\n        let popped_task = queue.pop().await.expect(\"Failed to pop task\");\n        queue\n            .ack(\u0026popped_task.task_id)\n            .await\n            .expect(\"Failed to ack task\");\n\n        let task_exists: bool = queue\n            .client\n            .hexists(\u0026queue.get_hashmap_key(), popped_task.task_id.to_string())\n            .await\n            .expect(\"Failed to check task existence\");\n        assert!(!task_exists, \"Task should have been removed after ack\");\n\n        cleanup_queue(\u0026queue).await;\n    }\n\n    #[tokio::test]\n    async fn test_nack() {\n        let queue = setup_queue(\"nack\").await;\n        let task = Task::new(TestData {\n            value: 42,\n            tag: \"tag1\".to_string(),\n        });\n\n        queue.push(\u0026task).await.expect(\"Failed to push task\");\n        let popped_task = queue.pop().await.expect(\"Failed to pop task\");\n        queue.nack(\u0026popped_task).await.expect(\"Failed to nack task\");\n\n        let task_exists: bool = queue\n            .client\n            .hexists(\u0026queue.get_hashmap_key(), popped_task.task_id.to_string())\n            .await\n            .expect(\"Failed to check task existence\");\n        assert!(\n            !task_exists,\n            \"Task should have been removed from hashmap after nack\"\n        );\n\n        let dlq_len = queue\n            .client\n            .llen(\u0026queue.get_dlq_key())\n            .await\n            .expect(\"Failed to read DLQ\");\n        assert_eq!(dlq_len, 1, \"Task should have been added to DLQ\");\n\n        cleanup_queue(\u0026queue).await;\n    }\n\n    #[tokio::test]\n    async fn test_set() {\n        let queue = setup_queue(\"set\").await;\n        let mut task = Task::new(TestData {\n            value: 42,\n            tag: \"tag1\".to_string(),\n        });\n\n        queue.push(\u0026task).await.expect(\"Failed to push task\");\n        task.payload.value = 43;\n        queue.set(\u0026task).await.expect(\"Failed to set task\");\n\n        let updated_task_json: String = queue\n            .client\n            .hget(\u0026queue.get_hashmap_key(), task.task_id.to_string())\n            .await\n            .expect(\"Failed to get updated task\");\n        let updated_task: Task\u003cTestData\u003e = serde_json::from_str(\u0026updated_task_json)\n            .expect(\"Failed to deserialize updated task\");\n\n        assert_eq!(updated_task.payload.value, 43);\n\n        cleanup_queue(\u0026queue).await;\n    }\n\n    #[tokio::test]\n    async fn test_queue_empty() {\n        let queue = setup_queue(\"empty\").await;\n        cleanup_queue(\u0026queue).await;\n\n        match queue.pop().await {\n            Err(TaskQueueError::QueueEmpty) =\u003e (),\n            _ =\u003e panic!(\"Expected QueueEmpty error\"),\n        }\n    }\n\n    #[tokio::test]\n    async fn test_purge() {\n        let queue = setup_queue(\"purge-test\").await;\n\n        // Push some tasks\n        let tasks = vec![\n            Task::new(TestData {\n                value: 1,\n                tag: \"tag1\".to_string(),\n            }),\n            Task::new(TestData {\n                value: 2,\n                tag: \"tag2\".to_string(),\n            }),\n            Task::new(TestData {\n                value: 3,\n                tag: \"tag3\".to_string(),\n            }),\n        ];\n\n        for task in \u0026tasks {\n            queue.push(task).await.expect(\"Failed to push task\");\n        }\n\n        // Verify that tasks are in the queue\n        for _ in 0..3 {\n            assert!(queue.pop().await.is_ok(), \"Should be able to pop a task\");\n        }\n\n        // Purge the queue\n        queue.purge().await.expect(\"Failed to purge queue\");\n\n        // Verify that all queues are empty\n        assert!(\n            matches!(queue.pop().await, Err(TaskQueueError::QueueEmpty)),\n            \"Queue should be empty after purge\"\n        );\n\n        // Verify that all keys have been deleted\n        let mut keys_to_check = vec![\n            queue.get_hashmap_key(),\n            queue.get_list_key(\"tag1\"),\n            queue.get_list_key(\"tag2\"),\n            queue.get_list_key(\"tag3\"),\n            queue.get_dlq_key(),\n        ];\n        keys_to_check.extend(queue.get_counter_keys());\n\n        for key in keys_to_check {\n            let exists: usize = queue\n                .client\n                .exists(\u0026key)\n                .await\n                .expect(\"Failed to check key existence\");\n            assert!(exists == 0, \"Key {} should not exist after purge\", key);\n        }\n\n        // Clean up any remaining keys (though there shouldn't be any)\n        cleanup_queue(\u0026queue).await;\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","tests","redis_tests.rs"],"content":"#[cfg(test)]\nmod tests {\n    use capp::queue::{RedisTaskQueue, TaskQueue, TaskQueueError};\n    use capp::task::Task;\n    use dotenvy::dotenv;\n    use rustis::client::Client;\n    use rustis::commands::{GenericCommands, HashCommands, ListCommands};\n    use serde::{Deserialize, Serialize};\n    use tokio;\n\n    #[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\n    struct TestData {\n        value: u32,\n    }\n\n    async fn get_redis_connection() -\u003e Client {\n        dotenv().ok();\n        let uri = std::env::var(\"REDIS_URI\").expect(\"Set REDIS_URI env variable\");\n        Client::connect(uri)\n            .await\n            .expect(\"Error while establishing redis connection\")\n    }\n\n    async fn setup_queue(name: \u0026str) -\u003e RedisTaskQueue\u003cTestData\u003e {\n        let redis = get_redis_connection().await;\n        RedisTaskQueue::new(redis, name)\n            .await\n            .expect(\"Failed to create RedisTaskQueue\")\n    }\n\n    async fn cleanup_queue(queue: \u0026RedisTaskQueue\u003cTestData\u003e) {\n        queue\n            .client\n            .del([\u0026queue.list_key, \u0026queue.hashmap_key, \u0026queue.dlq_key])\n            .await\n            .expect(\"Failed to clean up Redis keys\");\n    }\n\n    #[tokio::test]\n    async fn test_typical_workflow() {\n        let redis = get_redis_connection().await;\n        let queue: RedisTaskQueue\u003cTestData\u003e =\n            RedisTaskQueue::new(redis, \"capp-test-workflow\")\n                .await\n                .expect(\"Failed to create RedisTaskQueue\");\n        // clean queue\n        queue\n            .client\n            .del([\u0026queue.list_key, \u0026queue.hashmap_key, \u0026queue.dlq_key])\n            .await\n            .expect(\"Failed to clean up Redis keys\");\n\n        // check push\n        let task = Task::new(TestData { value: 42 });\n        let result = queue.push(\u0026task).await;\n        assert!(result.is_ok());\n\n        // check pop\n        let task_from_queue = queue.pop().await;\n        assert!(!\u0026task_from_queue.is_err());\n        let task_from_queue = task_from_queue.unwrap();\n        assert!(task_from_queue.get_payload().value == 42);\n\n        // ack task and check queue is empty\n        let acked = queue.ack(\u0026task_from_queue.task_id).await;\n        assert!(acked.is_ok());\n        let queue_list_len = queue.client.llen(\u0026queue.list_key).await;\n        assert_eq!(queue_list_len.unwrap(), 0);\n        let queue_hashmap_len = queue.client.hlen(\u0026queue.hashmap_key).await;\n        assert_eq!(queue_hashmap_len.unwrap(), 0);\n\n        // check how ack/nack working and check ordering\n        let task_1 = Task::new(TestData { value: 1 });\n        let task_2 = Task::new(TestData { value: 2 });\n        let _ = queue.push(\u0026task_1).await;\n        let _ = queue.push(\u0026task_2).await;\n        let queue_list_len = queue.client.llen(\u0026queue.list_key).await;\n        assert_eq!(queue_list_len.unwrap(), 2);\n        let queue_hashmap_len = queue.client.hlen(\u0026queue.hashmap_key).await;\n        assert_eq!(queue_hashmap_len.unwrap(), 2);\n\n        let task_1_from_queue = queue.pop().await.unwrap();\n        assert_eq!(task_1_from_queue.payload.value, 1);\n        let acked = queue.ack(\u0026task_1_from_queue.task_id).await;\n        assert!(acked.is_ok());\n\n        let task_2_from_queue = queue.pop().await.unwrap();\n        assert_eq!(task_2_from_queue.payload.value, 2);\n        let nacked = queue.nack(\u0026task_2_from_queue).await;\n        assert!(nacked.is_ok());\n        let dlq_len = queue.client.llen(\u0026queue.dlq_key).await.unwrap();\n        assert_eq!(dlq_len, 1);\n\n        queue\n            .client\n            .del([\u0026queue.list_key, \u0026queue.hashmap_key, \u0026queue.dlq_key])\n            .await\n            .expect(\"Failed to clean up Redis keys\");\n    }\n\n    #[tokio::test]\n    async fn test_push_and_pop() {\n        let queue = setup_queue(\"capp-test-push-pop\").await;\n        let task = Task::new(TestData { value: 42 });\n\n        queue.push(\u0026task).await.expect(\"Failed to push task\");\n\n        let popped_task = queue.pop().await.expect(\"Failed to pop task\");\n        assert_eq!(popped_task.payload, task.payload);\n\n        cleanup_queue(\u0026queue).await;\n    }\n\n    #[tokio::test]\n    async fn test_push_multiple_and_pop_order() {\n        let queue = setup_queue(\"capp-test-push-pop-order\").await;\n        let tasks = vec![\n            Task::new(TestData { value: 1 }),\n            Task::new(TestData { value: 2 }),\n            Task::new(TestData { value: 3 }),\n        ];\n\n        for task in \u0026tasks {\n            queue.push(task).await.expect(\"Failed to push task\");\n        }\n\n        for expected_value in 1..=3 {\n            let popped_task = queue.pop().await.expect(\"Failed to pop task\");\n            assert_eq!(popped_task.payload.value, expected_value);\n        }\n\n        assert!(matches!(queue.pop().await, Err(TaskQueueError::QueueEmpty)));\n\n        cleanup_queue(\u0026queue).await;\n    }\n\n    #[tokio::test]\n    async fn test_ack() {\n        let queue = setup_queue(\"capp-test-ack\").await;\n        let task = Task::new(TestData { value: 42 });\n\n        queue.push(\u0026task).await.expect(\"Failed to push task\");\n        let popped_task = queue.pop().await.expect(\"Failed to pop task\");\n        dbg!(\u0026popped_task);\n        queue\n            .ack(\u0026popped_task.task_id)\n            .await\n            .expect(\"Failed to ack task\");\n\n        let task_exists: bool = queue\n            .client\n            .hexists(\u0026queue.hashmap_key, popped_task.task_id.to_string())\n            .await\n            .expect(\"Failed to check task existence\");\n        assert!(!task_exists, \"Task should have been removed after ack\");\n\n        cleanup_queue(\u0026queue).await;\n    }\n\n    #[tokio::test]\n    async fn test_nack() {\n        let queue = setup_queue(\"capp-test-nack\").await;\n        let task = Task::new(TestData { value: 42 });\n\n        queue.push(\u0026task).await.expect(\"Failed to push task\");\n        let popped_task = queue.pop().await.expect(\"Failed to pop task\");\n        queue.nack(\u0026popped_task).await.expect(\"Failed to nack task\");\n\n        let task_exists: bool = queue\n            .client\n            .hexists(\u0026queue.hashmap_key, popped_task.task_id.to_string())\n            .await\n            .expect(\"Failed to check task existence\");\n        assert!(\n            !task_exists,\n            \"Task should have been removed from hashmap after nack\"\n        );\n\n        let dlq_len = queue\n            .client\n            .llen(\u0026queue.dlq_key)\n            .await\n            .expect(\"Failed to read DLQ\");\n        assert_eq!(dlq_len, 1, \"Task should have been added to DLQ\");\n\n        let dlq_task: Vec\u003cString\u003e =\n            queue.client.rpop(\u0026queue.dlq_key, 1).await.unwrap();\n\n        let dlq_task: Task\u003cTestData\u003e = serde_json::from_str(\u0026dlq_task[0])\n            .expect(\"Failed to deserialize task from DLQ\");\n        assert_eq!(dlq_task.payload.value, popped_task.payload.value);\n\n        cleanup_queue(\u0026queue).await;\n    }\n\n    #[tokio::test]\n    async fn test_set() {\n        let queue = setup_queue(\"capp-test-set\").await;\n        let mut task = Task::new(TestData { value: 42 });\n\n        queue.push(\u0026task).await.expect(\"Failed to push task\");\n        task.payload.value = 43;\n        queue.set(\u0026task).await.expect(\"Failed to set task\");\n\n        let updated_task_json: String = queue\n            .client\n            .hget(\u0026queue.hashmap_key, task.task_id.to_string())\n            .await\n            .expect(\"Failed to get updated task\");\n        let updated_task: Task\u003cTestData\u003e = serde_json::from_str(\u0026updated_task_json)\n            .expect(\"Failed to deserialize updated task\");\n\n        assert_eq!(updated_task.payload.value, 43);\n\n        cleanup_queue(\u0026queue).await;\n    }\n\n    #[tokio::test]\n    async fn test_queue_empty() {\n        let queue = setup_queue(\"capp-test-empty\").await;\n        cleanup_queue(\u0026queue).await;\n\n        match queue.pop().await {\n            Err(TaskQueueError::QueueEmpty) =\u003e (),\n            _ =\u003e panic!(\"Expected QueueEmpty error\"),\n        }\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","tmp","storage","backends","memory.rs"],"content":"//! In-memory implementation of TaskStorage trait. The storage allows tasks to be\n//! pushed to and popped from a queue, and also allows tasks to be set and\n//! retrieved by their UUID.\nuse crate::prelude::{Task, TaskId, TaskStorage, TaskStorageError};\nuse async_trait::async_trait;\nuse serde::de::DeserializeOwned;\nuse serde::Serialize;\nuse std::collections::{HashMap, VecDeque};\nuse std::marker::PhantomData;\nuse std::sync::Mutex;\n\n/// A simple in-memory implementation of the `TaskStorage` trait.\n/// The `InMemoryTaskStorage` struct includes a hashmap for storing tasks by\n/// their TaskId's, and a list for maintaining the order of the tasks.\npub struct InMemoryTaskStorage\u003cD\u003e {\n    pub hashmap: Mutex\u003cHashMap\u003cTaskId, String\u003e\u003e,\n    pub list: Mutex\u003cVecDeque\u003cTaskId\u003e\u003e,\n    pub dlq: Mutex\u003cHashMap\u003cTaskId, String\u003e\u003e,\n    _marker1: PhantomData\u003cD\u003e,\n}\n\nimpl\u003cData\u003e InMemoryTaskStorage\u003cData\u003e {\n    /// Construct a new empty in-memory task storage\n    pub fn new() -\u003e Self {\n        Self {\n            hashmap: Mutex::new(HashMap::new()),\n            list: Mutex::new(VecDeque::new()),\n            dlq: Mutex::new(HashMap::new()),\n            _marker1: PhantomData,\n        }\n    }\n}\n\nimpl\u003cData\u003e Default for InMemoryTaskStorage\u003cData\u003e {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\nimpl\u003cData\u003e std::fmt::Debug for InMemoryTaskStorage\u003cData\u003e {\n    fn fmt(\u0026self, f: \u0026mut std::fmt::Formatter\u003c'_\u003e) -\u003e std::fmt::Result {\n        // Lock the mutexes to access the data.\n        let hashmap = self.hashmap.lock().unwrap();\n        let list = self.list.lock().unwrap();\n\n        // Use the debug builders to format the output.\n        f.debug_struct(\"InMemoryTaskStorage\")\n            .field(\"hashmap\", \u0026*hashmap)\n            .field(\"list\", \u0026*list)\n            .finish()\n    }\n}\n\n#[async_trait]\nimpl\u003cData\u003e TaskStorage\u003cData\u003e for InMemoryTaskStorage\u003cData\u003e\nwhere\n    Data: std::fmt::Debug\n        + Clone\n        + Serialize\n        + DeserializeOwned\n        + Send\n        + Sync\n        + 'static,\n{\n    async fn task_ack(\n        \u0026self,\n        task_id: \u0026TaskId,\n    ) -\u003e Result\u003cTask\u003cData\u003e, TaskStorageError\u003e {\n        let mut hashmap = self.hashmap.lock().map_err(|_| {\n            TaskStorageError::StorageError(format!(\"Mutex lock error: {}\", task_id))\n        })?;\n        let task_value =\n            hashmap\n                .remove(task_id)\n                .ok_or(TaskStorageError::StorageError(format!(\n                    \"Error removing task from HashMap: {}\",\n                    task_id\n                )))?;\n        let task = serde_json::from_str(\u0026task_value)\n            .map_err(|err| TaskStorageError::SerializationError(err.to_string()))?;\n        Ok(task)\n    }\n\n    async fn task_get(\n        \u0026self,\n        task_id: \u0026TaskId,\n    ) -\u003e Result\u003cTask\u003cData\u003e, TaskStorageError\u003e {\n        let hashmap = self.hashmap.lock().map_err(|_| {\n            TaskStorageError::StorageError(format!(\"Mutex lock error: {}\", task_id))\n        })?;\n        let task_value =\n            hashmap\n                .get(task_id)\n                .ok_or(TaskStorageError::StorageError(format!(\n                    \"Error getting task from HashMap: {}\",\n                    task_id\n                )))?;\n        let task: Task\u003cData\u003e = serde_json::from_str(task_value)\n            .map_err(|err| TaskStorageError::SerializationError(err.to_string()))?;\n        Ok(task)\n    }\n\n    async fn task_set(\u0026self, task: \u0026Task\u003cData\u003e) -\u003e Result\u003c(), TaskStorageError\u003e {\n        let mut hashmap = self.hashmap.lock().map_err(|_| {\n            TaskStorageError::StorageError(\"Lock error on task hashmap\".to_string())\n        })?;\n        let task_value = serde_json::to_string(task)\n            .map_err(|err| TaskStorageError::SerializationError(err.to_string()))?;\n        hashmap.insert(task.task_id, task_value);\n        Ok(())\n    }\n\n    async fn task_pop(\u0026self) -\u003e Result\u003cTask\u003cData\u003e, TaskStorageError\u003e {\n        let mut list = self.list.lock().map_err(|_| {\n            TaskStorageError::StorageError(\"Lock error\".to_string())\n        })?;\n        let hashmap = self.hashmap.lock().map_err(|_| {\n            TaskStorageError::StorageError(\"Lock error on task hashmap\".to_string())\n        })?;\n\n        if let Some(task_id) = list.pop_front() {\n            let task_value = hashmap.get(\u0026task_id).unwrap();\n            let task: Task\u003cData\u003e = serde_json::from_str(task_value)\n                .map_err(|err| TaskStorageError::StorageError(err.to_string()))?;\n            return Ok(task);\n        }\n        Err(TaskStorageError::StorageIsEmptyError)\n    }\n\n    async fn task_push(\u0026self, task: \u0026Task\u003cData\u003e) -\u003e Result\u003c(), TaskStorageError\u003e {\n        let mut list = self.list.lock().map_err(|_| {\n            TaskStorageError::StorageError(\"Lock error on task list\".to_string())\n        })?;\n        let mut hashmap = self.hashmap.lock().map_err(|_| {\n            TaskStorageError::StorageError(\"Lock error on task hashmap\".to_string())\n        })?;\n\n        let task_value = serde_json::to_string(task)\n            .map_err(|err| TaskStorageError::SerializationError(err.to_string()))?;\n        hashmap.insert(task.task_id, task_value);\n        list.push_back(task.task_id);\n        Ok(())\n    }\n\n    async fn task_to_dlq(\u0026self, task: \u0026Task\u003cData\u003e) -\u003e Result\u003c(), TaskStorageError\u003e {\n        let mut dlq = self.hashmap.lock().map_err(|_| {\n            TaskStorageError::StorageError(\"Lock error on task hashmap\".to_string())\n        })?;\n        let task_value = serde_json::to_string(task)\n            .map_err(|err| TaskStorageError::StorageError(err.to_string()))?;\n        dlq.insert(task.task_id, task_value);\n        Ok(())\n    }\n\n    // general storage operations\n    async fn purge(\u0026self) -\u003e Result\u003c(), TaskStorageError\u003e {\n        let mut list = self.list.lock().map_err(|_| {\n            TaskStorageError::StorageError(\"Lock error on task list\".to_string())\n        })?;\n        let mut hashmap = self.hashmap.lock().map_err(|_| {\n            TaskStorageError::StorageError(\"Lock error on task hashmap\".to_string())\n        })?;\n        let mut dlq = self.hashmap.lock().map_err(|_| {\n            TaskStorageError::StorageError(\"Lock error on task hashmap\".to_string())\n        })?;\n        list.clear();\n        hashmap.clear();\n        dlq.clear();\n        Ok(())\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use std::assert_eq;\n\n    use super::*;\n    use crate::prelude::Task;\n    use serde::{Deserialize, Serialize};\n    use tokio::runtime::Runtime;\n\n    #[derive(Debug, Clone, Serialize, Deserialize)]\n    struct TaskData {\n        value: u32,\n    }\n\n    #[test]\n    fn storage_init() {\n        let storage: InMemoryTaskStorage\u003cTaskData\u003e = InMemoryTaskStorage::new();\n        assert_eq!(storage.list.lock().unwrap().len(), 0);\n    }\n\n    #[test]\n    fn storage_push_pop_ops() {\n        let rt = Runtime::new().unwrap();\n        let storage: InMemoryTaskStorage\u003cTaskData\u003e = InMemoryTaskStorage::new();\n\n        let task = Task::new(TaskData { value: 42 });\n        let push_result = rt.block_on(storage.task_push(\u0026task));\n        assert!(push_result.is_ok());\n        assert_eq!(storage.list.lock().unwrap().len(), 1);\n        assert_eq!(storage.hashmap.lock().unwrap().keys().len(), 1);\n\n        let task = Task::new(TaskData { value: 33 });\n        let _ = rt.block_on(storage.task_push(\u0026task));\n\n        let task = rt.block_on(storage.task_pop()).unwrap();\n        // let task = rt.block_on(storage.task_pop()).unwrap().unwrap();\n        assert_eq!(task.payload.value, 42);\n        assert_eq!(storage.list.lock().unwrap().len(), 1);\n        assert_eq!(storage.hashmap.lock().unwrap().keys().len(), 2);\n    }\n\n    #[test]\n    fn storage_get_set_ops() {\n        let rt = Runtime::new().unwrap();\n        let storage: InMemoryTaskStorage\u003cTaskData\u003e = InMemoryTaskStorage::new();\n\n        let mut task = Task::new(TaskData { value: 42 });\n        let _ = rt.block_on(storage.task_push(\u0026task));\n        let result = rt.block_on(storage.task_get(\u0026task.task_id)).unwrap();\n        assert_eq!(result.payload.value, 42);\n\n        task.payload.value = 11;\n        let _ = rt.block_on(storage.task_set(\u0026task));\n\n        let task = rt.block_on(storage.task_pop()).unwrap();\n        let task_acked = rt.block_on(storage.task_ack(\u0026task.task_id)).unwrap();\n        assert_eq!(task_acked.payload.value, 11);\n        assert_eq!(task_acked.task_id, task.task_id);\n\n        assert_eq!(storage.hashmap.lock().unwrap().keys().len(), 0);\n        assert_eq!(storage.list.lock().unwrap().len(), 0);\n    }\n\n    #[test]\n    fn storage_ack() {\n        let rt = Runtime::new().unwrap();\n        let storage: InMemoryTaskStorage\u003cTaskData\u003e = InMemoryTaskStorage::new();\n\n        let task = Task::new(TaskData { value: 42 });\n        let _ = rt.block_on(storage.task_push(\u0026task));\n        let task = Task::new(TaskData { value: 33 });\n        let _ = rt.block_on(storage.task_push(\u0026task));\n\n        let task = rt.block_on(storage.task_pop()).unwrap();\n        let task = rt.block_on(storage.task_ack(\u0026task.task_id)).unwrap();\n        assert_eq!(task.payload.value, 42);\n\n        assert_eq!(storage.hashmap.lock().unwrap().keys().len(), 1);\n        assert_eq!(storage.list.lock().unwrap().len(), 1);\n    }\n}\n","traces":[{"line":24,"address":[],"length":0,"stats":{"Line":0}},{"line":26,"address":[],"length":0,"stats":{"Line":0}},{"line":27,"address":[],"length":0,"stats":{"Line":0}},{"line":28,"address":[],"length":0,"stats":{"Line":0}},{"line":35,"address":[],"length":0,"stats":{"Line":0}},{"line":36,"address":[],"length":0,"stats":{"Line":0}},{"line":41,"address":[],"length":0,"stats":{"Line":0}},{"line":43,"address":[],"length":0,"stats":{"Line":0}},{"line":44,"address":[],"length":0,"stats":{"Line":0}},{"line":47,"address":[],"length":0,"stats":{"Line":0}},{"line":48,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":147,"address":[],"length":0,"stats":{"Line":0}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":150,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":152,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":160,"address":[],"length":0,"stats":{"Line":0}},{"line":161,"address":[],"length":0,"stats":{"Line":0}},{"line":163,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":169,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":80},{"path":["/","Users","alexc","code","capp-rs","tmp","storage","backends","redis.rs"],"content":"//! Provides implementation of trait to store task into redis\n//! TODO: make sequental ops into atomic transaction\nuse crate::prelude::*;\nuse async_trait::async_trait;\nuse rustis::commands::{GenericCommands, HashCommands, ListCommands};\nuse serde::de::DeserializeOwned;\nuse serde::Serialize;\nuse std::marker::PhantomData;\n\n/// A simple implementation of the `TaskStorage` trait on top of redis\npub struct RedisTaskStorage\u003cD\u003e {\n    pub key: String,\n    pub redis: rustis::client::Client,\n    _marker1: PhantomData\u003cD\u003e,\n}\n\nimpl\u003cD\u003e RedisTaskStorage\u003cD\u003e {\n    /// Construct a new empty redis task storage\n    pub fn new(key: \u0026str, redis: rustis::client::Client) -\u003e Self {\n        Self {\n            key: key.to_string(),\n            redis,\n            _marker1: PhantomData,\n        }\n    }\n\n    pub fn get_hashmap_key(\u0026self) -\u003e String {\n        format!(\"{}:{}\", self.key, \"hm\")\n    }\n\n    pub fn get_list_key(\u0026self) -\u003e String {\n        format!(\"{}:{}\", self.key, \"ls\")\n    }\n\n    pub fn get_dlq_key(\u0026self) -\u003e String {\n        format!(\"{}:{}\", self.key, \"dlq\")\n    }\n}\n\nimpl\u003cD\u003e std::fmt::Debug for RedisTaskStorage\u003cD\u003e {\n    fn fmt(\u0026self, f: \u0026mut std::fmt::Formatter\u003c'_\u003e) -\u003e std::fmt::Result {\n        // TODO: implement debug output for data in redis\n        // Use the debug builders to format the output.\n        // NOTE: here i will need to do actual queries to redis\n        f.debug_struct(\"RedisTaskStorage\")\n            // .field(\"hashmap\", \u0026*hashmap)\n            // .field(\"list\", \u0026*list)\n            .finish()\n    }\n}\n\n#[async_trait]\nimpl\u003cD\u003e TaskStorage\u003cD\u003e for RedisTaskStorage\u003cD\u003e\nwhere\n    D: std::fmt::Debug\n        + Clone\n        + Serialize\n        + DeserializeOwned\n        + Send\n        + Sync\n        + 'static,\n{\n    async fn task_ack(\n        \u0026self,\n        task_id: \u0026TaskId,\n    ) -\u003e Result\u003cTask\u003cD\u003e, TaskStorageError\u003e {\n        let hashmap_key = self.get_hashmap_key();\n        let uuid_as_str = task_id.to_string();\n        let task_value: String =\n            self.redis.hget(\u0026hashmap_key, \u0026uuid_as_str).await?;\n        let _ = self.redis.hdel(hashmap_key, \u0026uuid_as_str).await;\n        let task = serde_json::from_str(\u0026task_value).map_err(|err| {\n            TaskStorageError::DeserializationError(err.to_string())\n        })?;\n        Ok(task)\n    }\n\n    async fn task_get(\n        \u0026self,\n        task_id: \u0026TaskId,\n    ) -\u003e Result\u003cTask\u003cD\u003e, TaskStorageError\u003e {\n        let hashmap_key = self.get_hashmap_key();\n        let uuid_as_str = task_id.to_string();\n        let task_value: String =\n            self.redis.hget(\u0026hashmap_key, \u0026uuid_as_str).await?;\n        let task_data: Task\u003cD\u003e =\n            serde_json::from_str(\u0026task_value).map_err(|err| {\n                TaskStorageError::DeserializationError(err.to_string())\n            })?;\n        Ok(task_data)\n    }\n\n    async fn task_set(\u0026self, task: \u0026Task\u003cD\u003e) -\u003e Result\u003c(), TaskStorageError\u003e {\n        let hashmap_key = self.get_hashmap_key();\n        let task_value: String = serde_json::to_string(task)\n            .map_err(|err| TaskStorageError::SerializationError(err.to_string()))?;\n        let uuid_as_str = task.task_id.to_string();\n        let _ = self\n            .redis\n            .hset(\u0026hashmap_key, [(\u0026uuid_as_str, \u0026task_value)])\n            .await;\n        Ok(())\n    }\n\n    async fn task_pop(\u0026self) -\u003e Result\u003cTask\u003cD\u003e, TaskStorageError\u003e {\n        let list_key = self.get_list_key();\n        let hashmap_key = self.get_hashmap_key();\n        let task_ids: Vec\u003cString\u003e = self.redis.rpop(\u0026list_key, 1).await?;\n        if task_ids.len() \u003e 0 {\n            let task_id = task_ids.first().unwrap();\n            let task_value: String = self.redis.hget(\u0026hashmap_key, task_id).await?;\n            let task: Task\u003cD\u003e =\n                serde_json::from_str(\u0026task_value).map_err(|err| {\n                    TaskStorageError::DeserializationError(err.to_string())\n                })?;\n            return Ok(task);\n        }\n\n        Err(TaskStorageError::StorageIsEmptyError)\n    }\n\n    async fn task_push(\u0026self, task: \u0026Task\u003cD\u003e) -\u003e Result\u003c(), TaskStorageError\u003e {\n        let task_value = serde_json::to_string(task)\n            .map_err(|err| TaskStorageError::SerializationError(err.to_string()))?;\n        let list_key = self.get_list_key();\n        let hashmap_key = self.get_hashmap_key();\n        let uuid_as_str = task.task_id.to_string();\n\n        let _ = self.redis.lpush(\u0026list_key, \u0026uuid_as_str).await?;\n        let _ = self\n            .redis\n            .hset(\u0026hashmap_key, [(\u0026uuid_as_str, \u0026task_value)])\n            .await?;\n        Ok(())\n    }\n\n    async fn task_to_dlq(\u0026self, task: \u0026Task\u003cD\u003e) -\u003e Result\u003c(), TaskStorageError\u003e {\n        let task_value = serde_json::to_string(task)\n            .map_err(|err| TaskStorageError::SerializationError(err.to_string()))?;\n        let dlq_key = self.get_dlq_key();\n        let uuid_as_str = task.task_id.to_string();\n\n        let _ = self\n            .redis\n            .hset(\u0026dlq_key, [(\u0026uuid_as_str, \u0026task_value)])\n            .await?;\n        Ok(())\n    }\n\n    async fn purge(\u0026self) -\u003e Result\u003c(), TaskStorageError\u003e {\n        let _ = self.redis.del(self.get_hashmap_key()).await?;\n        let _ = self.redis.del(self.get_list_key()).await?;\n        let _ = self.redis.del(self.get_dlq_key()).await?;\n        Ok(())\n    }\n}\n","traces":[{"line":19,"address":[],"length":0,"stats":{"Line":0}},{"line":21,"address":[],"length":0,"stats":{"Line":0}},{"line":27,"address":[],"length":0,"stats":{"Line":0}},{"line":28,"address":[],"length":0,"stats":{"Line":0}},{"line":31,"address":[],"length":0,"stats":{"Line":0}},{"line":32,"address":[],"length":0,"stats":{"Line":0}},{"line":35,"address":[],"length":0,"stats":{"Line":0}},{"line":36,"address":[],"length":0,"stats":{"Line":0}},{"line":41,"address":[],"length":0,"stats":{"Line":0}},{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":147,"address":[],"length":0,"stats":{"Line":0}},{"line":150,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":152,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":75},{"path":["/","Users","alexc","code","capp-rs","tmp","storage","backends","redis_rr.rs"],"content":"//! `RedisRoundRobinTaskStorage` provides an asynchronous task storage mechanism\n//! built on top of Redis, with a round-robin approach to accessing tasks across\n//! different queues.\n//!\n//! This storage structure maintains domain-specific queues, allowing for tasks\n//! to be categorized and processed based on their associated key. The round-robin\n//! mechanism ensures that tasks from one domain do not dominate the queue, allowing\n//! for balanced task processing across all domains.\n//!\n//! Features:\n//! - **Tag-based Queues**: Tasks are enqueued and dequeued based on their\n//!   tag, preventing any single tag from monopolizing worker resources.\n//! - **Round Robin Access**: The storage fetches tasks in a round-robin manner\n//!   across the tags, ensuring fair access and processing for all tags.\n//! - **Asynchronous Operations**: All task operations, including enqueueing,\n//!   dequeueing, and acknowledging, are performed asynchronously for optimal\n//!   performance.\n//!\n//! # Examples\n//!\n//! ```rust\n//! // TODO: Insert basic usage example here.\n//! ```\n//!\n//! Note: The exact tag key for each task is determined from the `TaskData`\n//! field, and can be configured during the storage initialization.\n\nuse crate::prelude::{HasTagKey, Task, TaskId, TaskStorage, TaskStorageError};\nuse async_trait::async_trait;\nuse rustis::commands::{GenericCommands, HashCommands, ListCommands};\nuse serde::{de::DeserializeOwned, Serialize};\nuse std::{\n    marker::PhantomData,\n    sync::{\n        atomic::{AtomicUsize, Ordering},\n        Arc, Mutex,\n    },\n};\n\npub struct RedisRoundRobinTaskStorage\u003cD\u003e {\n    pub key: String,\n    pub redis: rustis::client::Client,\n    pub tags: Arc\u003cMutex\u003cstd::collections::HashSet\u003cString\u003e\u003e\u003e,\n    pub current_tag_index: Arc\u003cAtomicUsize\u003e,\n    pub tag_field_name: String,\n    _marker1: PhantomData\u003cD\u003e,\n}\n\n#[async_trait]\nimpl\u003cD\u003e TaskStorage\u003cD\u003e for RedisRoundRobinTaskStorage\u003cD\u003e\nwhere\n    D: std::fmt::Debug\n        + Clone\n        + HasTagKey\n        + Serialize\n        + DeserializeOwned\n        + Send\n        + Sync\n        + 'static,\n{\n    async fn task_ack(\n        \u0026self,\n        task_id: \u0026TaskId,\n    ) -\u003e Result\u003cTask\u003cD\u003e, TaskStorageError\u003e {\n        let hashmap_key = self.get_hashmap_key();\n        let uuid_as_str = task_id.to_string();\n        let task_value: String =\n            self.redis.hget(\u0026hashmap_key, \u0026uuid_as_str).await?;\n        let _ = self.redis.hdel(hashmap_key, \u0026uuid_as_str).await;\n        let task = serde_json::from_str(\u0026task_value).map_err(|err| {\n            TaskStorageError::DeserializationError(err.to_string())\n        })?;\n        Ok(task)\n    }\n\n    async fn task_get(\n        \u0026self,\n        task_id: \u0026TaskId,\n    ) -\u003e Result\u003cTask\u003cD\u003e, TaskStorageError\u003e {\n        let hashmap_key = self.get_hashmap_key();\n        let uuid_as_str = task_id.to_string();\n        let task_value: String =\n            self.redis.hget(\u0026hashmap_key, \u0026uuid_as_str).await?;\n        let task_data: Task\u003cD\u003e =\n            serde_json::from_str(\u0026task_value).map_err(|err| {\n                TaskStorageError::DeserializationError(err.to_string())\n            })?;\n        Ok(task_data)\n    }\n\n    async fn task_set(\u0026self, task: \u0026Task\u003cD\u003e) -\u003e Result\u003c(), TaskStorageError\u003e {\n        let hashmap_key = self.get_hashmap_key();\n        let task_value: String = serde_json::to_string(task)\n            .map_err(|err| TaskStorageError::SerializationError(err.to_string()))?;\n        let uuid_as_str = task.task_id.to_string();\n        let _ = self\n            .redis\n            .hset(\u0026hashmap_key, [(\u0026uuid_as_str, \u0026task_value)])\n            .await;\n        Ok(())\n    }\n\n    async fn task_pop(\u0026self) -\u003e Result\u003cTask\u003cD\u003e, TaskStorageError\u003e {\n        let queue_name = self.get_next_queue()?;\n        let list_key = self.get_list_key(\u0026queue_name);\n        let hashmap_key = self.get_hashmap_key();\n        let task_ids: Vec\u003cString\u003e = self.redis.rpop(\u0026list_key, 1).await?;\n        if task_ids.len() \u003e 0 {\n            let task_id = task_ids.first().unwrap();\n            let task_value: String = self.redis.hget(\u0026hashmap_key, task_id).await?;\n            let task: Task\u003cD\u003e =\n                serde_json::from_str(\u0026task_value).map_err(|err| {\n                    TaskStorageError::DeserializationError(err.to_string())\n                })?;\n            return Ok(task);\n        }\n\n        Err(TaskStorageError::StorageIsEmptyError)\n    }\n\n    async fn task_push(\u0026self, task: \u0026Task\u003cD\u003e) -\u003e Result\u003c(), TaskStorageError\u003e {\n        let queue_name = task.payload.get_tag_value().to_string();\n        let task_value = serde_json::to_string(task)\n            .map_err(|err| TaskStorageError::SerializationError(err.to_string()))?;\n        let list_key = self.get_list_key(\u0026queue_name);\n        let hashmap_key = self.get_hashmap_key();\n        let uuid_as_str = task.task_id.to_string();\n\n        let _ = self.redis.lpush(\u0026list_key, \u0026uuid_as_str).await?;\n        let _ = self\n            .redis\n            .hset(\u0026hashmap_key, [(\u0026uuid_as_str, \u0026task_value)])\n            .await?;\n        Ok(())\n    }\n\n    async fn task_to_dlq(\u0026self, task: \u0026Task\u003cD\u003e) -\u003e Result\u003c(), TaskStorageError\u003e {\n        let task_value = serde_json::to_string(task)\n            .map_err(|err| TaskStorageError::SerializationError(err.to_string()))?;\n        let dlq_key = self.get_dlq_key();\n        let uuid_as_str = task.task_id.to_string();\n\n        let _ = self\n            .redis\n            .hset(\u0026dlq_key, [(\u0026uuid_as_str, \u0026task_value)])\n            .await?;\n        Ok(())\n    }\n\n    async fn purge(\u0026self) -\u003e Result\u003c(), TaskStorageError\u003e {\n        let _ = self.redis.del(self.get_hashmap_key()).await?;\n        // TODO: can do better\n        let tags: Vec\u003cString\u003e =\n            self.tags.lock().unwrap().iter().map(|t| t.into()).collect();\n        for tag in tags {\n            let _ = self.redis.del(self.get_list_key(\u0026tag)).await?;\n        }\n        let _ = self.redis.del(self.get_dlq_key()).await?;\n        Ok(())\n    }\n}\n\nimpl\u003cD\u003e RedisRoundRobinTaskStorage\u003cD\u003e {\n    /// Construct a new empty redis task storage\n    pub fn new(\n        key: \u0026str,\n        tags: std::collections::HashSet\u003cString\u003e,\n        tag_field_name: \u0026str,\n        redis: rustis::client::Client,\n    ) -\u003e Self {\n        Self {\n            key: key.to_string(),\n            redis,\n            tags: Arc::new(Mutex::new(tags)),\n            current_tag_index: Arc::new(AtomicUsize::new(0)),\n            tag_field_name: tag_field_name.to_string(),\n            _marker1: PhantomData,\n        }\n    }\n\n    pub fn get_hashmap_key(\u0026self) -\u003e String {\n        format!(\"{}:{}\", self.key, \"hm\")\n    }\n\n    pub fn get_list_key(\u0026self, queue_key: \u0026str) -\u003e String {\n        format!(\"{}:{}:{}\", self.key, queue_key, \"ls\")\n    }\n\n    pub fn get_dlq_key(\u0026self) -\u003e String {\n        format!(\"{}:{}\", self.key, \"dlq\")\n    }\n\n    fn get_next_queue(\u0026self) -\u003e Result\u003cString, TaskStorageError\u003e {\n        let queues = self.tags.lock().unwrap();\n        let len = queues.len();\n        if queues.is_empty() {\n            return Err(TaskStorageError::EmptyValueError(\n                \"self.tags is empty\".to_string(),\n            ));\n        }\n\n        let index = self.current_tag_index.fetch_add(1, Ordering::Relaxed) % len;\n        Ok(queues.iter().nth(index).unwrap().clone())\n    }\n}\n\nimpl\u003cD\u003e std::fmt::Debug for RedisRoundRobinTaskStorage\u003cD\u003e {\n    fn fmt(\u0026self, f: \u0026mut std::fmt::Formatter\u003c'_\u003e) -\u003e std::fmt::Result {\n        // TODO: implement debug output for data in redis\n        // Use the debug builders to format the output.\n        f.debug_struct(\"RedisRoundRobinTaskStorage\")\n            // .field(\"hashmap\", \u0026*hashmap)\n            // .field(\"list\", \u0026*list)\n            .finish()\n    }\n}\n","traces":[{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":147,"address":[],"length":0,"stats":{"Line":0}},{"line":150,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":0}},{"line":172,"address":[],"length":0,"stats":{"Line":0}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":0}},{"line":176,"address":[],"length":0,"stats":{"Line":0}},{"line":181,"address":[],"length":0,"stats":{"Line":0}},{"line":182,"address":[],"length":0,"stats":{"Line":0}},{"line":185,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":189,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":0}},{"line":193,"address":[],"length":0,"stats":{"Line":0}},{"line":194,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":202,"address":[],"length":0,"stats":{"Line":0}},{"line":203,"address":[],"length":0,"stats":{"Line":0}},{"line":208,"address":[],"length":0,"stats":{"Line":0}},{"line":211,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":90},{"path":["/","Users","alexc","code","capp-rs","tmp","storage","backends.rs"],"content":"pub mod memory;\n#[cfg(feature = \"redis\")]\npub mod redis;\n#[cfg(feature = \"redis\")]\npub mod redis_rr;\n\npub use memory::InMemoryTaskStorage;\n#[cfg(feature = \"redis\")]\npub use redis::RedisTaskStorage;\n#[cfg(feature = \"redis\")]\npub use redis_rr::RedisRoundRobinTaskStorage;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","alexc","code","capp-rs","tmp","storage.rs"],"content":"//! This module provides a trait for interacting with task storage.\n//! The storage allows tasks to be pushed to and popped from a queue,\n//! and also allows tasks to be set and retrieved by their UUID.\nuse async_trait::async_trait;\nuse serde::{de::DeserializeOwned, Serialize};\nuse thiserror::Error;\n\npub mod backends;\npub mod task;\n\npub use backends::InMemoryTaskStorage;\n#[cfg(feature = \"redis\")]\npub use backends::{RedisRoundRobinTaskStorage, RedisTaskStorage};\npub use task::{Task, TaskId, TaskStatus};\n\npub type AbstractTaskStorage\u003cD\u003e = std::sync::Arc\u003cdyn TaskStorage\u003cD\u003e + Send + Sync\u003e;\n\n#[derive(Error, Debug)]\npub enum TaskStorageError {\n    #[error(\"Storage error: {0}\")]\n    StorageError(String),\n    #[error(\"Serialization error: {0}\")]\n    SerializationError(String),\n    #[error(\"Deserialization error: {0}\")]\n    DeserializationError(String),\n    #[error(\"Task not found {0}\")]\n    TaskNotFound(TaskId),\n    #[error(\"Empty value \")]\n    EmptyValueError(String),\n    #[error(\"Storage is empty\")]\n    StorageIsEmptyError,\n    #[cfg(feature = \"redis\")]\n    #[error(\"Redis error\")]\n    RedisError(#[from] rustis::Error),\n}\n\n/// A trait that describes the necessary methods for task storage. This includes\n/// methods for acknowledging a task, getting a task by its UUID, setting a task,\n/// popping a task from the queue, and pushing a task into the queue.\n/// Whole functions should be non blocking. I.e. task_push should return None\n/// to be able to process situation when there is no tasks in queue on worker side.\n#[async_trait]\npub trait TaskStorage\u003cData\u003e\nwhere\n    Data: std::fmt::Debug\n        + Clone\n        + Serialize\n        + DeserializeOwned\n        + Send\n        + Sync\n        + 'static,\n{\n    // task operations\n    async fn task_ack(\n        \u0026self,\n        task_id: \u0026TaskId,\n    ) -\u003e Result\u003cTask\u003cData\u003e, TaskStorageError\u003e;\n    async fn task_get(\n        \u0026self,\n        task_id: \u0026TaskId,\n    ) -\u003e Result\u003cTask\u003cData\u003e, TaskStorageError\u003e;\n    async fn task_set(\u0026self, task: \u0026Task\u003cData\u003e) -\u003e Result\u003c(), TaskStorageError\u003e;\n    async fn task_pop(\u0026self) -\u003e Result\u003cTask\u003cData\u003e, TaskStorageError\u003e;\n    async fn task_push(\u0026self, task: \u0026Task\u003cData\u003e) -\u003e Result\u003c(), TaskStorageError\u003e;\n    async fn task_to_dlq(\u0026self, task: \u0026Task\u003cData\u003e) -\u003e Result\u003c(), TaskStorageError\u003e;\n\n    // general storage operations\n    async fn purge(\u0026self) -\u003e Result\u003c(), TaskStorageError\u003e;\n}\n\n// Used for round robin queue\npub trait HasTagKey {\n    type TagValue: ToString + PartialEq;\n    fn get_tag_value(\u0026self) -\u003e Self::TagValue;\n}\n","traces":[],"covered":0,"coverable":0}]};
    </script>
    <script crossorigin>/** @license React v16.13.1
 * react.production.min.js
 *
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */
'use strict';(function(d,r){"object"===typeof exports&&"undefined"!==typeof module?r(exports):"function"===typeof define&&define.amd?define(["exports"],r):(d=d||self,r(d.React={}))})(this,function(d){function r(a){for(var b="https://reactjs.org/docs/error-decoder.html?invariant="+a,c=1;c<arguments.length;c++)b+="&args[]="+encodeURIComponent(arguments[c]);return"Minified React error #"+a+"; visit "+b+" for the full message or use the non-minified dev environment for full errors and additional helpful warnings."}
function w(a,b,c){this.props=a;this.context=b;this.refs=ba;this.updater=c||ca}function da(){}function L(a,b,c){this.props=a;this.context=b;this.refs=ba;this.updater=c||ca}function ea(a,b,c){var g,e={},fa=null,d=null;if(null!=b)for(g in void 0!==b.ref&&(d=b.ref),void 0!==b.key&&(fa=""+b.key),b)ha.call(b,g)&&!ia.hasOwnProperty(g)&&(e[g]=b[g]);var h=arguments.length-2;if(1===h)e.children=c;else if(1<h){for(var k=Array(h),f=0;f<h;f++)k[f]=arguments[f+2];e.children=k}if(a&&a.defaultProps)for(g in h=a.defaultProps,
h)void 0===e[g]&&(e[g]=h[g]);return{$$typeof:x,type:a,key:fa,ref:d,props:e,_owner:M.current}}function va(a,b){return{$$typeof:x,type:a.type,key:b,ref:a.ref,props:a.props,_owner:a._owner}}function N(a){return"object"===typeof a&&null!==a&&a.$$typeof===x}function wa(a){var b={"=":"=0",":":"=2"};return"$"+(""+a).replace(/[=:]/g,function(a){return b[a]})}function ja(a,b,c,g){if(C.length){var e=C.pop();e.result=a;e.keyPrefix=b;e.func=c;e.context=g;e.count=0;return e}return{result:a,keyPrefix:b,func:c,
context:g,count:0}}function ka(a){a.result=null;a.keyPrefix=null;a.func=null;a.context=null;a.count=0;10>C.length&&C.push(a)}function O(a,b,c,g){var e=typeof a;if("undefined"===e||"boolean"===e)a=null;var d=!1;if(null===a)d=!0;else switch(e){case "string":case "number":d=!0;break;case "object":switch(a.$$typeof){case x:case xa:d=!0}}if(d)return c(g,a,""===b?"."+P(a,0):b),1;d=0;b=""===b?".":b+":";if(Array.isArray(a))for(var f=0;f<a.length;f++){e=a[f];var h=b+P(e,f);d+=O(e,h,c,g)}else if(null===a||
"object"!==typeof a?h=null:(h=la&&a[la]||a["@@iterator"],h="function"===typeof h?h:null),"function"===typeof h)for(a=h.call(a),f=0;!(e=a.next()).done;)e=e.value,h=b+P(e,f++),d+=O(e,h,c,g);else if("object"===e)throw c=""+a,Error(r(31,"[object Object]"===c?"object with keys {"+Object.keys(a).join(", ")+"}":c,""));return d}function Q(a,b,c){return null==a?0:O(a,"",b,c)}function P(a,b){return"object"===typeof a&&null!==a&&null!=a.key?wa(a.key):b.toString(36)}function ya(a,b,c){a.func.call(a.context,b,
a.count++)}function za(a,b,c){var g=a.result,e=a.keyPrefix;a=a.func.call(a.context,b,a.count++);Array.isArray(a)?R(a,g,c,function(a){return a}):null!=a&&(N(a)&&(a=va(a,e+(!a.key||b&&b.key===a.key?"":(""+a.key).replace(ma,"$&/")+"/")+c)),g.push(a))}function R(a,b,c,g,e){var d="";null!=c&&(d=(""+c).replace(ma,"$&/")+"/");b=ja(b,d,g,e);Q(a,za,b);ka(b)}function t(){var a=na.current;if(null===a)throw Error(r(321));return a}function S(a,b){var c=a.length;a.push(b);a:for(;;){var g=c-1>>>1,e=a[g];if(void 0!==
e&&0<D(e,b))a[g]=b,a[c]=e,c=g;else break a}}function n(a){a=a[0];return void 0===a?null:a}function E(a){var b=a[0];if(void 0!==b){var c=a.pop();if(c!==b){a[0]=c;a:for(var g=0,e=a.length;g<e;){var d=2*(g+1)-1,f=a[d],h=d+1,k=a[h];if(void 0!==f&&0>D(f,c))void 0!==k&&0>D(k,f)?(a[g]=k,a[h]=c,g=h):(a[g]=f,a[d]=c,g=d);else if(void 0!==k&&0>D(k,c))a[g]=k,a[h]=c,g=h;else break a}}return b}return null}function D(a,b){var c=a.sortIndex-b.sortIndex;return 0!==c?c:a.id-b.id}function F(a){for(var b=n(u);null!==
b;){if(null===b.callback)E(u);else if(b.startTime<=a)E(u),b.sortIndex=b.expirationTime,S(p,b);else break;b=n(u)}}function T(a){y=!1;F(a);if(!v)if(null!==n(p))v=!0,z(U);else{var b=n(u);null!==b&&G(T,b.startTime-a)}}function U(a,b){v=!1;y&&(y=!1,V());H=!0;var c=m;try{F(b);for(l=n(p);null!==l&&(!(l.expirationTime>b)||a&&!W());){var g=l.callback;if(null!==g){l.callback=null;m=l.priorityLevel;var e=g(l.expirationTime<=b);b=q();"function"===typeof e?l.callback=e:l===n(p)&&E(p);F(b)}else E(p);l=n(p)}if(null!==
l)var d=!0;else{var f=n(u);null!==f&&G(T,f.startTime-b);d=!1}return d}finally{l=null,m=c,H=!1}}function oa(a){switch(a){case 1:return-1;case 2:return 250;case 5:return 1073741823;case 4:return 1E4;default:return 5E3}}var f="function"===typeof Symbol&&Symbol.for,x=f?Symbol.for("react.element"):60103,xa=f?Symbol.for("react.portal"):60106,Aa=f?Symbol.for("react.fragment"):60107,Ba=f?Symbol.for("react.strict_mode"):60108,Ca=f?Symbol.for("react.profiler"):60114,Da=f?Symbol.for("react.provider"):60109,
Ea=f?Symbol.for("react.context"):60110,Fa=f?Symbol.for("react.forward_ref"):60112,Ga=f?Symbol.for("react.suspense"):60113,Ha=f?Symbol.for("react.memo"):60115,Ia=f?Symbol.for("react.lazy"):60116,la="function"===typeof Symbol&&Symbol.iterator,pa=Object.getOwnPropertySymbols,Ja=Object.prototype.hasOwnProperty,Ka=Object.prototype.propertyIsEnumerable,I=function(){try{if(!Object.assign)return!1;var a=new String("abc");a[5]="de";if("5"===Object.getOwnPropertyNames(a)[0])return!1;var b={};for(a=0;10>a;a++)b["_"+
String.fromCharCode(a)]=a;if("0123456789"!==Object.getOwnPropertyNames(b).map(function(a){return b[a]}).join(""))return!1;var c={};"abcdefghijklmnopqrst".split("").forEach(function(a){c[a]=a});return"abcdefghijklmnopqrst"!==Object.keys(Object.assign({},c)).join("")?!1:!0}catch(g){return!1}}()?Object.assign:function(a,b){if(null===a||void 0===a)throw new TypeError("Object.assign cannot be called with null or undefined");var c=Object(a);for(var g,e=1;e<arguments.length;e++){var d=Object(arguments[e]);
for(var f in d)Ja.call(d,f)&&(c[f]=d[f]);if(pa){g=pa(d);for(var h=0;h<g.length;h++)Ka.call(d,g[h])&&(c[g[h]]=d[g[h]])}}return c},ca={isMounted:function(a){return!1},enqueueForceUpdate:function(a,b,c){},enqueueReplaceState:function(a,b,c,d){},enqueueSetState:function(a,b,c,d){}},ba={};w.prototype.isReactComponent={};w.prototype.setState=function(a,b){if("object"!==typeof a&&"function"!==typeof a&&null!=a)throw Error(r(85));this.updater.enqueueSetState(this,a,b,"setState")};w.prototype.forceUpdate=
function(a){this.updater.enqueueForceUpdate(this,a,"forceUpdate")};da.prototype=w.prototype;f=L.prototype=new da;f.constructor=L;I(f,w.prototype);f.isPureReactComponent=!0;var M={current:null},ha=Object.prototype.hasOwnProperty,ia={key:!0,ref:!0,__self:!0,__source:!0},ma=/\/+/g,C=[],na={current:null},X;if("undefined"===typeof window||"function"!==typeof MessageChannel){var A=null,qa=null,ra=function(){if(null!==A)try{var a=q();A(!0,a);A=null}catch(b){throw setTimeout(ra,0),b;}},La=Date.now();var q=
function(){return Date.now()-La};var z=function(a){null!==A?setTimeout(z,0,a):(A=a,setTimeout(ra,0))};var G=function(a,b){qa=setTimeout(a,b)};var V=function(){clearTimeout(qa)};var W=function(){return!1};f=X=function(){}}else{var Y=window.performance,sa=window.Date,Ma=window.setTimeout,Na=window.clearTimeout;"undefined"!==typeof console&&(f=window.cancelAnimationFrame,"function"!==typeof window.requestAnimationFrame&&console.error("This browser doesn't support requestAnimationFrame. Make sure that you load a polyfill in older browsers. https://fb.me/react-polyfills"),
"function"!==typeof f&&console.error("This browser doesn't support cancelAnimationFrame. Make sure that you load a polyfill in older browsers. https://fb.me/react-polyfills"));if("object"===typeof Y&&"function"===typeof Y.now)q=function(){return Y.now()};else{var Oa=sa.now();q=function(){return sa.now()-Oa}}var J=!1,K=null,Z=-1,ta=5,ua=0;W=function(){return q()>=ua};f=function(){};X=function(a){0>a||125<a?console.error("forceFrameRate takes a positive int between 0 and 125, forcing framerates higher than 125 fps is not unsupported"):
ta=0<a?Math.floor(1E3/a):5};var B=new MessageChannel,aa=B.port2;B.port1.onmessage=function(){if(null!==K){var a=q();ua=a+ta;try{K(!0,a)?aa.postMessage(null):(J=!1,K=null)}catch(b){throw aa.postMessage(null),b;}}else J=!1};z=function(a){K=a;J||(J=!0,aa.postMessage(null))};G=function(a,b){Z=Ma(function(){a(q())},b)};V=function(){Na(Z);Z=-1}}var p=[],u=[],Pa=1,l=null,m=3,H=!1,v=!1,y=!1,Qa=0;B={ReactCurrentDispatcher:na,ReactCurrentOwner:M,IsSomeRendererActing:{current:!1},assign:I};I(B,{Scheduler:{__proto__:null,
unstable_ImmediatePriority:1,unstable_UserBlockingPriority:2,unstable_NormalPriority:3,unstable_IdlePriority:5,unstable_LowPriority:4,unstable_runWithPriority:function(a,b){switch(a){case 1:case 2:case 3:case 4:case 5:break;default:a=3}var c=m;m=a;try{return b()}finally{m=c}},unstable_next:function(a){switch(m){case 1:case 2:case 3:var b=3;break;default:b=m}var c=m;m=b;try{return a()}finally{m=c}},unstable_scheduleCallback:function(a,b,c){var d=q();if("object"===typeof c&&null!==c){var e=c.delay;
e="number"===typeof e&&0<e?d+e:d;c="number"===typeof c.timeout?c.timeout:oa(a)}else c=oa(a),e=d;c=e+c;a={id:Pa++,callback:b,priorityLevel:a,startTime:e,expirationTime:c,sortIndex:-1};e>d?(a.sortIndex=e,S(u,a),null===n(p)&&a===n(u)&&(y?V():y=!0,G(T,e-d))):(a.sortIndex=c,S(p,a),v||H||(v=!0,z(U)));return a},unstable_cancelCallback:function(a){a.callback=null},unstable_wrapCallback:function(a){var b=m;return function(){var c=m;m=b;try{return a.apply(this,arguments)}finally{m=c}}},unstable_getCurrentPriorityLevel:function(){return m},
unstable_shouldYield:function(){var a=q();F(a);var b=n(p);return b!==l&&null!==l&&null!==b&&null!==b.callback&&b.startTime<=a&&b.expirationTime<l.expirationTime||W()},unstable_requestPaint:f,unstable_continueExecution:function(){v||H||(v=!0,z(U))},unstable_pauseExecution:function(){},unstable_getFirstCallbackNode:function(){return n(p)},get unstable_now(){return q},get unstable_forceFrameRate(){return X},unstable_Profiling:null},SchedulerTracing:{__proto__:null,__interactionsRef:null,__subscriberRef:null,
unstable_clear:function(a){return a()},unstable_getCurrent:function(){return null},unstable_getThreadID:function(){return++Qa},unstable_trace:function(a,b,c){return c()},unstable_wrap:function(a){return a},unstable_subscribe:function(a){},unstable_unsubscribe:function(a){}}});d.Children={map:function(a,b,c){if(null==a)return a;var d=[];R(a,d,null,b,c);return d},forEach:function(a,b,c){if(null==a)return a;b=ja(null,null,b,c);Q(a,ya,b);ka(b)},count:function(a){return Q(a,function(){return null},null)},
toArray:function(a){var b=[];R(a,b,null,function(a){return a});return b},only:function(a){if(!N(a))throw Error(r(143));return a}};d.Component=w;d.Fragment=Aa;d.Profiler=Ca;d.PureComponent=L;d.StrictMode=Ba;d.Suspense=Ga;d.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED=B;d.cloneElement=function(a,b,c){if(null===a||void 0===a)throw Error(r(267,a));var d=I({},a.props),e=a.key,f=a.ref,m=a._owner;if(null!=b){void 0!==b.ref&&(f=b.ref,m=M.current);void 0!==b.key&&(e=""+b.key);if(a.type&&a.type.defaultProps)var h=
a.type.defaultProps;for(k in b)ha.call(b,k)&&!ia.hasOwnProperty(k)&&(d[k]=void 0===b[k]&&void 0!==h?h[k]:b[k])}var k=arguments.length-2;if(1===k)d.children=c;else if(1<k){h=Array(k);for(var l=0;l<k;l++)h[l]=arguments[l+2];d.children=h}return{$$typeof:x,type:a.type,key:e,ref:f,props:d,_owner:m}};d.createContext=function(a,b){void 0===b&&(b=null);a={$$typeof:Ea,_calculateChangedBits:b,_currentValue:a,_currentValue2:a,_threadCount:0,Provider:null,Consumer:null};a.Provider={$$typeof:Da,_context:a};return a.Consumer=
a};d.createElement=ea;d.createFactory=function(a){var b=ea.bind(null,a);b.type=a;return b};d.createRef=function(){return{current:null}};d.forwardRef=function(a){return{$$typeof:Fa,render:a}};d.isValidElement=N;d.lazy=function(a){return{$$typeof:Ia,_ctor:a,_status:-1,_result:null}};d.memo=function(a,b){return{$$typeof:Ha,type:a,compare:void 0===b?null:b}};d.useCallback=function(a,b){return t().useCallback(a,b)};d.useContext=function(a,b){return t().useContext(a,b)};d.useDebugValue=function(a,b){};
d.useEffect=function(a,b){return t().useEffect(a,b)};d.useImperativeHandle=function(a,b,c){return t().useImperativeHandle(a,b,c)};d.useLayoutEffect=function(a,b){return t().useLayoutEffect(a,b)};d.useMemo=function(a,b){return t().useMemo(a,b)};d.useReducer=function(a,b,c){return t().useReducer(a,b,c)};d.useRef=function(a){return t().useRef(a)};d.useState=function(a){return t().useState(a)};d.version="16.13.1"});
</script>
    <script crossorigin>/** @license React v16.13.1
 * react-dom.production.min.js
 *
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */
/*
 Modernizr 3.0.0pre (Custom Build) | MIT
*/
'use strict';(function(I,ea){"object"===typeof exports&&"undefined"!==typeof module?ea(exports,require("react")):"function"===typeof define&&define.amd?define(["exports","react"],ea):(I=I||self,ea(I.ReactDOM={},I.React))})(this,function(I,ea){function k(a){for(var b="https://reactjs.org/docs/error-decoder.html?invariant="+a,c=1;c<arguments.length;c++)b+="&args[]="+encodeURIComponent(arguments[c]);return"Minified React error #"+a+"; visit "+b+" for the full message or use the non-minified dev environment for full errors and additional helpful warnings."}
function ji(a,b,c,d,e,f,g,h,m){yb=!1;gc=null;ki.apply(li,arguments)}function mi(a,b,c,d,e,f,g,h,m){ji.apply(this,arguments);if(yb){if(yb){var n=gc;yb=!1;gc=null}else throw Error(k(198));hc||(hc=!0,pd=n)}}function lf(a,b,c){var d=a.type||"unknown-event";a.currentTarget=mf(c);mi(d,b,void 0,a);a.currentTarget=null}function nf(){if(ic)for(var a in cb){var b=cb[a],c=ic.indexOf(a);if(!(-1<c))throw Error(k(96,a));if(!jc[c]){if(!b.extractEvents)throw Error(k(97,a));jc[c]=b;c=b.eventTypes;for(var d in c){var e=
void 0;var f=c[d],g=b,h=d;if(qd.hasOwnProperty(h))throw Error(k(99,h));qd[h]=f;var m=f.phasedRegistrationNames;if(m){for(e in m)m.hasOwnProperty(e)&&of(m[e],g,h);e=!0}else f.registrationName?(of(f.registrationName,g,h),e=!0):e=!1;if(!e)throw Error(k(98,d,a));}}}}function of(a,b,c){if(db[a])throw Error(k(100,a));db[a]=b;rd[a]=b.eventTypes[c].dependencies}function pf(a){var b=!1,c;for(c in a)if(a.hasOwnProperty(c)){var d=a[c];if(!cb.hasOwnProperty(c)||cb[c]!==d){if(cb[c])throw Error(k(102,c));cb[c]=
d;b=!0}}b&&nf()}function qf(a){if(a=rf(a)){if("function"!==typeof sd)throw Error(k(280));var b=a.stateNode;b&&(b=td(b),sd(a.stateNode,a.type,b))}}function sf(a){eb?fb?fb.push(a):fb=[a]:eb=a}function tf(){if(eb){var a=eb,b=fb;fb=eb=null;qf(a);if(b)for(a=0;a<b.length;a++)qf(b[a])}}function ud(){if(null!==eb||null!==fb)vd(),tf()}function uf(a,b,c){if(wd)return a(b,c);wd=!0;try{return vf(a,b,c)}finally{wd=!1,ud()}}function ni(a){if(wf.call(xf,a))return!0;if(wf.call(yf,a))return!1;if(oi.test(a))return xf[a]=
!0;yf[a]=!0;return!1}function pi(a,b,c,d){if(null!==c&&0===c.type)return!1;switch(typeof b){case "function":case "symbol":return!0;case "boolean":if(d)return!1;if(null!==c)return!c.acceptsBooleans;a=a.toLowerCase().slice(0,5);return"data-"!==a&&"aria-"!==a;default:return!1}}function qi(a,b,c,d){if(null===b||"undefined"===typeof b||pi(a,b,c,d))return!0;if(d)return!1;if(null!==c)switch(c.type){case 3:return!b;case 4:return!1===b;case 5:return isNaN(b);case 6:return isNaN(b)||1>b}return!1}function L(a,
b,c,d,e,f){this.acceptsBooleans=2===b||3===b||4===b;this.attributeName=d;this.attributeNamespace=e;this.mustUseProperty=c;this.propertyName=a;this.type=b;this.sanitizeURL=f}function xd(a,b,c,d){var e=E.hasOwnProperty(b)?E[b]:null;var f=null!==e?0===e.type:d?!1:!(2<b.length)||"o"!==b[0]&&"O"!==b[0]||"n"!==b[1]&&"N"!==b[1]?!1:!0;f||(qi(b,c,e,d)&&(c=null),d||null===e?ni(b)&&(null===c?a.removeAttribute(b):a.setAttribute(b,""+c)):e.mustUseProperty?a[e.propertyName]=null===c?3===e.type?!1:"":c:(b=e.attributeName,
d=e.attributeNamespace,null===c?a.removeAttribute(b):(e=e.type,c=3===e||4===e&&!0===c?"":""+c,d?a.setAttributeNS(d,b,c):a.setAttribute(b,c))))}function zb(a){if(null===a||"object"!==typeof a)return null;a=zf&&a[zf]||a["@@iterator"];return"function"===typeof a?a:null}function ri(a){if(-1===a._status){a._status=0;var b=a._ctor;b=b();a._result=b;b.then(function(b){0===a._status&&(b=b.default,a._status=1,a._result=b)},function(b){0===a._status&&(a._status=2,a._result=b)})}}function na(a){if(null==a)return null;
if("function"===typeof a)return a.displayName||a.name||null;if("string"===typeof a)return a;switch(a){case Ma:return"Fragment";case gb:return"Portal";case kc:return"Profiler";case Af:return"StrictMode";case lc:return"Suspense";case yd:return"SuspenseList"}if("object"===typeof a)switch(a.$$typeof){case Bf:return"Context.Consumer";case Cf:return"Context.Provider";case zd:var b=a.render;b=b.displayName||b.name||"";return a.displayName||(""!==b?"ForwardRef("+b+")":"ForwardRef");case Ad:return na(a.type);
case Df:return na(a.render);case Ef:if(a=1===a._status?a._result:null)return na(a)}return null}function Bd(a){var b="";do{a:switch(a.tag){case 3:case 4:case 6:case 7:case 10:case 9:var c="";break a;default:var d=a._debugOwner,e=a._debugSource,f=na(a.type);c=null;d&&(c=na(d.type));d=f;f="";e?f=" (at "+e.fileName.replace(si,"")+":"+e.lineNumber+")":c&&(f=" (created by "+c+")");c="\n    in "+(d||"Unknown")+f}b+=c;a=a.return}while(a);return b}function va(a){switch(typeof a){case "boolean":case "number":case "object":case "string":case "undefined":return a;
default:return""}}function Ff(a){var b=a.type;return(a=a.nodeName)&&"input"===a.toLowerCase()&&("checkbox"===b||"radio"===b)}function ti(a){var b=Ff(a)?"checked":"value",c=Object.getOwnPropertyDescriptor(a.constructor.prototype,b),d=""+a[b];if(!a.hasOwnProperty(b)&&"undefined"!==typeof c&&"function"===typeof c.get&&"function"===typeof c.set){var e=c.get,f=c.set;Object.defineProperty(a,b,{configurable:!0,get:function(){return e.call(this)},set:function(a){d=""+a;f.call(this,a)}});Object.defineProperty(a,
b,{enumerable:c.enumerable});return{getValue:function(){return d},setValue:function(a){d=""+a},stopTracking:function(){a._valueTracker=null;delete a[b]}}}}function mc(a){a._valueTracker||(a._valueTracker=ti(a))}function Gf(a){if(!a)return!1;var b=a._valueTracker;if(!b)return!0;var c=b.getValue();var d="";a&&(d=Ff(a)?a.checked?"true":"false":a.value);a=d;return a!==c?(b.setValue(a),!0):!1}function Cd(a,b){var c=b.checked;return M({},b,{defaultChecked:void 0,defaultValue:void 0,value:void 0,checked:null!=
c?c:a._wrapperState.initialChecked})}function Hf(a,b){var c=null==b.defaultValue?"":b.defaultValue,d=null!=b.checked?b.checked:b.defaultChecked;c=va(null!=b.value?b.value:c);a._wrapperState={initialChecked:d,initialValue:c,controlled:"checkbox"===b.type||"radio"===b.type?null!=b.checked:null!=b.value}}function If(a,b){b=b.checked;null!=b&&xd(a,"checked",b,!1)}function Dd(a,b){If(a,b);var c=va(b.value),d=b.type;if(null!=c)if("number"===d){if(0===c&&""===a.value||a.value!=c)a.value=""+c}else a.value!==
""+c&&(a.value=""+c);else if("submit"===d||"reset"===d){a.removeAttribute("value");return}b.hasOwnProperty("value")?Ed(a,b.type,c):b.hasOwnProperty("defaultValue")&&Ed(a,b.type,va(b.defaultValue));null==b.checked&&null!=b.defaultChecked&&(a.defaultChecked=!!b.defaultChecked)}function Jf(a,b,c){if(b.hasOwnProperty("value")||b.hasOwnProperty("defaultValue")){var d=b.type;if(!("submit"!==d&&"reset"!==d||void 0!==b.value&&null!==b.value))return;b=""+a._wrapperState.initialValue;c||b===a.value||(a.value=
b);a.defaultValue=b}c=a.name;""!==c&&(a.name="");a.defaultChecked=!!a._wrapperState.initialChecked;""!==c&&(a.name=c)}function Ed(a,b,c){if("number"!==b||a.ownerDocument.activeElement!==a)null==c?a.defaultValue=""+a._wrapperState.initialValue:a.defaultValue!==""+c&&(a.defaultValue=""+c)}function ui(a){var b="";ea.Children.forEach(a,function(a){null!=a&&(b+=a)});return b}function Fd(a,b){a=M({children:void 0},b);if(b=ui(b.children))a.children=b;return a}function hb(a,b,c,d){a=a.options;if(b){b={};
for(var e=0;e<c.length;e++)b["$"+c[e]]=!0;for(c=0;c<a.length;c++)e=b.hasOwnProperty("$"+a[c].value),a[c].selected!==e&&(a[c].selected=e),e&&d&&(a[c].defaultSelected=!0)}else{c=""+va(c);b=null;for(e=0;e<a.length;e++){if(a[e].value===c){a[e].selected=!0;d&&(a[e].defaultSelected=!0);return}null!==b||a[e].disabled||(b=a[e])}null!==b&&(b.selected=!0)}}function Gd(a,b){if(null!=b.dangerouslySetInnerHTML)throw Error(k(91));return M({},b,{value:void 0,defaultValue:void 0,children:""+a._wrapperState.initialValue})}
function Kf(a,b){var c=b.value;if(null==c){c=b.children;b=b.defaultValue;if(null!=c){if(null!=b)throw Error(k(92));if(Array.isArray(c)){if(!(1>=c.length))throw Error(k(93));c=c[0]}b=c}null==b&&(b="");c=b}a._wrapperState={initialValue:va(c)}}function Lf(a,b){var c=va(b.value),d=va(b.defaultValue);null!=c&&(c=""+c,c!==a.value&&(a.value=c),null==b.defaultValue&&a.defaultValue!==c&&(a.defaultValue=c));null!=d&&(a.defaultValue=""+d)}function Mf(a,b){b=a.textContent;b===a._wrapperState.initialValue&&""!==
b&&null!==b&&(a.value=b)}function Nf(a){switch(a){case "svg":return"http://www.w3.org/2000/svg";case "math":return"http://www.w3.org/1998/Math/MathML";default:return"http://www.w3.org/1999/xhtml"}}function Hd(a,b){return null==a||"http://www.w3.org/1999/xhtml"===a?Nf(b):"http://www.w3.org/2000/svg"===a&&"foreignObject"===b?"http://www.w3.org/1999/xhtml":a}function nc(a,b){var c={};c[a.toLowerCase()]=b.toLowerCase();c["Webkit"+a]="webkit"+b;c["Moz"+a]="moz"+b;return c}function oc(a){if(Id[a])return Id[a];
if(!ib[a])return a;var b=ib[a],c;for(c in b)if(b.hasOwnProperty(c)&&c in Of)return Id[a]=b[c];return a}function Jd(a){var b=Pf.get(a);void 0===b&&(b=new Map,Pf.set(a,b));return b}function Na(a){var b=a,c=a;if(a.alternate)for(;b.return;)b=b.return;else{a=b;do b=a,0!==(b.effectTag&1026)&&(c=b.return),a=b.return;while(a)}return 3===b.tag?c:null}function Qf(a){if(13===a.tag){var b=a.memoizedState;null===b&&(a=a.alternate,null!==a&&(b=a.memoizedState));if(null!==b)return b.dehydrated}return null}function Rf(a){if(Na(a)!==
a)throw Error(k(188));}function vi(a){var b=a.alternate;if(!b){b=Na(a);if(null===b)throw Error(k(188));return b!==a?null:a}for(var c=a,d=b;;){var e=c.return;if(null===e)break;var f=e.alternate;if(null===f){d=e.return;if(null!==d){c=d;continue}break}if(e.child===f.child){for(f=e.child;f;){if(f===c)return Rf(e),a;if(f===d)return Rf(e),b;f=f.sibling}throw Error(k(188));}if(c.return!==d.return)c=e,d=f;else{for(var g=!1,h=e.child;h;){if(h===c){g=!0;c=e;d=f;break}if(h===d){g=!0;d=e;c=f;break}h=h.sibling}if(!g){for(h=
f.child;h;){if(h===c){g=!0;c=f;d=e;break}if(h===d){g=!0;d=f;c=e;break}h=h.sibling}if(!g)throw Error(k(189));}}if(c.alternate!==d)throw Error(k(190));}if(3!==c.tag)throw Error(k(188));return c.stateNode.current===c?a:b}function Sf(a){a=vi(a);if(!a)return null;for(var b=a;;){if(5===b.tag||6===b.tag)return b;if(b.child)b.child.return=b,b=b.child;else{if(b===a)break;for(;!b.sibling;){if(!b.return||b.return===a)return null;b=b.return}b.sibling.return=b.return;b=b.sibling}}return null}function jb(a,b){if(null==
b)throw Error(k(30));if(null==a)return b;if(Array.isArray(a)){if(Array.isArray(b))return a.push.apply(a,b),a;a.push(b);return a}return Array.isArray(b)?[a].concat(b):[a,b]}function Kd(a,b,c){Array.isArray(a)?a.forEach(b,c):a&&b.call(c,a)}function pc(a){null!==a&&(Ab=jb(Ab,a));a=Ab;Ab=null;if(a){Kd(a,wi);if(Ab)throw Error(k(95));if(hc)throw a=pd,hc=!1,pd=null,a;}}function Ld(a){a=a.target||a.srcElement||window;a.correspondingUseElement&&(a=a.correspondingUseElement);return 3===a.nodeType?a.parentNode:
a}function Tf(a){if(!wa)return!1;a="on"+a;var b=a in document;b||(b=document.createElement("div"),b.setAttribute(a,"return;"),b="function"===typeof b[a]);return b}function Uf(a){a.topLevelType=null;a.nativeEvent=null;a.targetInst=null;a.ancestors.length=0;10>qc.length&&qc.push(a)}function Vf(a,b,c,d){if(qc.length){var e=qc.pop();e.topLevelType=a;e.eventSystemFlags=d;e.nativeEvent=b;e.targetInst=c;return e}return{topLevelType:a,eventSystemFlags:d,nativeEvent:b,targetInst:c,ancestors:[]}}function Wf(a){var b=
a.targetInst,c=b;do{if(!c){a.ancestors.push(c);break}var d=c;if(3===d.tag)d=d.stateNode.containerInfo;else{for(;d.return;)d=d.return;d=3!==d.tag?null:d.stateNode.containerInfo}if(!d)break;b=c.tag;5!==b&&6!==b||a.ancestors.push(c);c=Bb(d)}while(c);for(c=0;c<a.ancestors.length;c++){b=a.ancestors[c];var e=Ld(a.nativeEvent);d=a.topLevelType;var f=a.nativeEvent,g=a.eventSystemFlags;0===c&&(g|=64);for(var h=null,m=0;m<jc.length;m++){var n=jc[m];n&&(n=n.extractEvents(d,b,f,e,g))&&(h=jb(h,n))}pc(h)}}function Md(a,
b,c){if(!c.has(a)){switch(a){case "scroll":Cb(b,"scroll",!0);break;case "focus":case "blur":Cb(b,"focus",!0);Cb(b,"blur",!0);c.set("blur",null);c.set("focus",null);break;case "cancel":case "close":Tf(a)&&Cb(b,a,!0);break;case "invalid":case "submit":case "reset":break;default:-1===Db.indexOf(a)&&w(a,b)}c.set(a,null)}}function xi(a,b){var c=Jd(b);Nd.forEach(function(a){Md(a,b,c)});yi.forEach(function(a){Md(a,b,c)})}function Od(a,b,c,d,e){return{blockedOn:a,topLevelType:b,eventSystemFlags:c|32,nativeEvent:e,
container:d}}function Xf(a,b){switch(a){case "focus":case "blur":xa=null;break;case "dragenter":case "dragleave":ya=null;break;case "mouseover":case "mouseout":za=null;break;case "pointerover":case "pointerout":Eb.delete(b.pointerId);break;case "gotpointercapture":case "lostpointercapture":Fb.delete(b.pointerId)}}function Gb(a,b,c,d,e,f){if(null===a||a.nativeEvent!==f)return a=Od(b,c,d,e,f),null!==b&&(b=Hb(b),null!==b&&Yf(b)),a;a.eventSystemFlags|=d;return a}function zi(a,b,c,d,e){switch(b){case "focus":return xa=
Gb(xa,a,b,c,d,e),!0;case "dragenter":return ya=Gb(ya,a,b,c,d,e),!0;case "mouseover":return za=Gb(za,a,b,c,d,e),!0;case "pointerover":var f=e.pointerId;Eb.set(f,Gb(Eb.get(f)||null,a,b,c,d,e));return!0;case "gotpointercapture":return f=e.pointerId,Fb.set(f,Gb(Fb.get(f)||null,a,b,c,d,e)),!0}return!1}function Ai(a){var b=Bb(a.target);if(null!==b){var c=Na(b);if(null!==c)if(b=c.tag,13===b){if(b=Qf(c),null!==b){a.blockedOn=b;Pd(a.priority,function(){Bi(c)});return}}else if(3===b&&c.stateNode.hydrate){a.blockedOn=
3===c.tag?c.stateNode.containerInfo:null;return}}a.blockedOn=null}function rc(a){if(null!==a.blockedOn)return!1;var b=Qd(a.topLevelType,a.eventSystemFlags,a.container,a.nativeEvent);if(null!==b){var c=Hb(b);null!==c&&Yf(c);a.blockedOn=b;return!1}return!0}function Zf(a,b,c){rc(a)&&c.delete(b)}function Ci(){for(Rd=!1;0<fa.length;){var a=fa[0];if(null!==a.blockedOn){a=Hb(a.blockedOn);null!==a&&Di(a);break}var b=Qd(a.topLevelType,a.eventSystemFlags,a.container,a.nativeEvent);null!==b?a.blockedOn=b:fa.shift()}null!==
xa&&rc(xa)&&(xa=null);null!==ya&&rc(ya)&&(ya=null);null!==za&&rc(za)&&(za=null);Eb.forEach(Zf);Fb.forEach(Zf)}function Ib(a,b){a.blockedOn===b&&(a.blockedOn=null,Rd||(Rd=!0,$f(ag,Ci)))}function bg(a){if(0<fa.length){Ib(fa[0],a);for(var b=1;b<fa.length;b++){var c=fa[b];c.blockedOn===a&&(c.blockedOn=null)}}null!==xa&&Ib(xa,a);null!==ya&&Ib(ya,a);null!==za&&Ib(za,a);b=function(b){return Ib(b,a)};Eb.forEach(b);Fb.forEach(b);for(b=0;b<Jb.length;b++)c=Jb[b],c.blockedOn===a&&(c.blockedOn=null);for(;0<Jb.length&&
(b=Jb[0],null===b.blockedOn);)Ai(b),null===b.blockedOn&&Jb.shift()}function Sd(a,b){for(var c=0;c<a.length;c+=2){var d=a[c],e=a[c+1],f="on"+(e[0].toUpperCase()+e.slice(1));f={phasedRegistrationNames:{bubbled:f,captured:f+"Capture"},dependencies:[d],eventPriority:b};Td.set(d,b);cg.set(d,f);dg[e]=f}}function w(a,b){Cb(b,a,!1)}function Cb(a,b,c){var d=Td.get(b);switch(void 0===d?2:d){case 0:d=Ei.bind(null,b,1,a);break;case 1:d=Fi.bind(null,b,1,a);break;default:d=sc.bind(null,b,1,a)}c?a.addEventListener(b,
d,!0):a.addEventListener(b,d,!1)}function Ei(a,b,c,d){Oa||vd();var e=sc,f=Oa;Oa=!0;try{eg(e,a,b,c,d)}finally{(Oa=f)||ud()}}function Fi(a,b,c,d){Gi(Hi,sc.bind(null,a,b,c,d))}function sc(a,b,c,d){if(tc)if(0<fa.length&&-1<Nd.indexOf(a))a=Od(null,a,b,c,d),fa.push(a);else{var e=Qd(a,b,c,d);if(null===e)Xf(a,d);else if(-1<Nd.indexOf(a))a=Od(e,a,b,c,d),fa.push(a);else if(!zi(e,a,b,c,d)){Xf(a,d);a=Vf(a,d,null,b);try{uf(Wf,a)}finally{Uf(a)}}}}function Qd(a,b,c,d){c=Ld(d);c=Bb(c);if(null!==c){var e=Na(c);if(null===
e)c=null;else{var f=e.tag;if(13===f){c=Qf(e);if(null!==c)return c;c=null}else if(3===f){if(e.stateNode.hydrate)return 3===e.tag?e.stateNode.containerInfo:null;c=null}else e!==c&&(c=null)}}a=Vf(a,d,c,b);try{uf(Wf,a)}finally{Uf(a)}return null}function fg(a,b,c){return null==b||"boolean"===typeof b||""===b?"":c||"number"!==typeof b||0===b||Kb.hasOwnProperty(a)&&Kb[a]?(""+b).trim():b+"px"}function gg(a,b){a=a.style;for(var c in b)if(b.hasOwnProperty(c)){var d=0===c.indexOf("--"),e=fg(c,b[c],d);"float"===
c&&(c="cssFloat");d?a.setProperty(c,e):a[c]=e}}function Ud(a,b){if(b){if(Ii[a]&&(null!=b.children||null!=b.dangerouslySetInnerHTML))throw Error(k(137,a,""));if(null!=b.dangerouslySetInnerHTML){if(null!=b.children)throw Error(k(60));if(!("object"===typeof b.dangerouslySetInnerHTML&&"__html"in b.dangerouslySetInnerHTML))throw Error(k(61));}if(null!=b.style&&"object"!==typeof b.style)throw Error(k(62,""));}}function Vd(a,b){if(-1===a.indexOf("-"))return"string"===typeof b.is;switch(a){case "annotation-xml":case "color-profile":case "font-face":case "font-face-src":case "font-face-uri":case "font-face-format":case "font-face-name":case "missing-glyph":return!1;
default:return!0}}function oa(a,b){a=9===a.nodeType||11===a.nodeType?a:a.ownerDocument;var c=Jd(a);b=rd[b];for(var d=0;d<b.length;d++)Md(b[d],a,c)}function uc(){}function Wd(a){a=a||("undefined"!==typeof document?document:void 0);if("undefined"===typeof a)return null;try{return a.activeElement||a.body}catch(b){return a.body}}function hg(a){for(;a&&a.firstChild;)a=a.firstChild;return a}function ig(a,b){var c=hg(a);a=0;for(var d;c;){if(3===c.nodeType){d=a+c.textContent.length;if(a<=b&&d>=b)return{node:c,
offset:b-a};a=d}a:{for(;c;){if(c.nextSibling){c=c.nextSibling;break a}c=c.parentNode}c=void 0}c=hg(c)}}function jg(a,b){return a&&b?a===b?!0:a&&3===a.nodeType?!1:b&&3===b.nodeType?jg(a,b.parentNode):"contains"in a?a.contains(b):a.compareDocumentPosition?!!(a.compareDocumentPosition(b)&16):!1:!1}function kg(){for(var a=window,b=Wd();b instanceof a.HTMLIFrameElement;){try{var c="string"===typeof b.contentWindow.location.href}catch(d){c=!1}if(c)a=b.contentWindow;else break;b=Wd(a.document)}return b}
function Xd(a){var b=a&&a.nodeName&&a.nodeName.toLowerCase();return b&&("input"===b&&("text"===a.type||"search"===a.type||"tel"===a.type||"url"===a.type||"password"===a.type)||"textarea"===b||"true"===a.contentEditable)}function lg(a,b){switch(a){case "button":case "input":case "select":case "textarea":return!!b.autoFocus}return!1}function Yd(a,b){return"textarea"===a||"option"===a||"noscript"===a||"string"===typeof b.children||"number"===typeof b.children||"object"===typeof b.dangerouslySetInnerHTML&&
null!==b.dangerouslySetInnerHTML&&null!=b.dangerouslySetInnerHTML.__html}function kb(a){for(;null!=a;a=a.nextSibling){var b=a.nodeType;if(1===b||3===b)break}return a}function mg(a){a=a.previousSibling;for(var b=0;a;){if(8===a.nodeType){var c=a.data;if(c===ng||c===Zd||c===$d){if(0===b)return a;b--}else c===og&&b++}a=a.previousSibling}return null}function Bb(a){var b=a[Aa];if(b)return b;for(var c=a.parentNode;c;){if(b=c[Lb]||c[Aa]){c=b.alternate;if(null!==b.child||null!==c&&null!==c.child)for(a=mg(a);null!==
a;){if(c=a[Aa])return c;a=mg(a)}return b}a=c;c=a.parentNode}return null}function Hb(a){a=a[Aa]||a[Lb];return!a||5!==a.tag&&6!==a.tag&&13!==a.tag&&3!==a.tag?null:a}function Pa(a){if(5===a.tag||6===a.tag)return a.stateNode;throw Error(k(33));}function ae(a){return a[vc]||null}function pa(a){do a=a.return;while(a&&5!==a.tag);return a?a:null}function pg(a,b){var c=a.stateNode;if(!c)return null;var d=td(c);if(!d)return null;c=d[b];a:switch(b){case "onClick":case "onClickCapture":case "onDoubleClick":case "onDoubleClickCapture":case "onMouseDown":case "onMouseDownCapture":case "onMouseMove":case "onMouseMoveCapture":case "onMouseUp":case "onMouseUpCapture":case "onMouseEnter":(d=
!d.disabled)||(a=a.type,d=!("button"===a||"input"===a||"select"===a||"textarea"===a));a=!d;break a;default:a=!1}if(a)return null;if(c&&"function"!==typeof c)throw Error(k(231,b,typeof c));return c}function qg(a,b,c){if(b=pg(a,c.dispatchConfig.phasedRegistrationNames[b]))c._dispatchListeners=jb(c._dispatchListeners,b),c._dispatchInstances=jb(c._dispatchInstances,a)}function Ji(a){if(a&&a.dispatchConfig.phasedRegistrationNames){for(var b=a._targetInst,c=[];b;)c.push(b),b=pa(b);for(b=c.length;0<b--;)qg(c[b],
"captured",a);for(b=0;b<c.length;b++)qg(c[b],"bubbled",a)}}function be(a,b,c){a&&c&&c.dispatchConfig.registrationName&&(b=pg(a,c.dispatchConfig.registrationName))&&(c._dispatchListeners=jb(c._dispatchListeners,b),c._dispatchInstances=jb(c._dispatchInstances,a))}function Ki(a){a&&a.dispatchConfig.registrationName&&be(a._targetInst,null,a)}function lb(a){Kd(a,Ji)}function rg(){if(wc)return wc;var a,b=ce,c=b.length,d,e="value"in Ba?Ba.value:Ba.textContent,f=e.length;for(a=0;a<c&&b[a]===e[a];a++);var g=
c-a;for(d=1;d<=g&&b[c-d]===e[f-d];d++);return wc=e.slice(a,1<d?1-d:void 0)}function xc(){return!0}function yc(){return!1}function R(a,b,c,d){this.dispatchConfig=a;this._targetInst=b;this.nativeEvent=c;a=this.constructor.Interface;for(var e in a)a.hasOwnProperty(e)&&((b=a[e])?this[e]=b(c):"target"===e?this.target=d:this[e]=c[e]);this.isDefaultPrevented=(null!=c.defaultPrevented?c.defaultPrevented:!1===c.returnValue)?xc:yc;this.isPropagationStopped=yc;return this}function Li(a,b,c,d){if(this.eventPool.length){var e=
this.eventPool.pop();this.call(e,a,b,c,d);return e}return new this(a,b,c,d)}function Mi(a){if(!(a instanceof this))throw Error(k(279));a.destructor();10>this.eventPool.length&&this.eventPool.push(a)}function sg(a){a.eventPool=[];a.getPooled=Li;a.release=Mi}function tg(a,b){switch(a){case "keyup":return-1!==Ni.indexOf(b.keyCode);case "keydown":return 229!==b.keyCode;case "keypress":case "mousedown":case "blur":return!0;default:return!1}}function ug(a){a=a.detail;return"object"===typeof a&&"data"in
a?a.data:null}function Oi(a,b){switch(a){case "compositionend":return ug(b);case "keypress":if(32!==b.which)return null;vg=!0;return wg;case "textInput":return a=b.data,a===wg&&vg?null:a;default:return null}}function Pi(a,b){if(mb)return"compositionend"===a||!de&&tg(a,b)?(a=rg(),wc=ce=Ba=null,mb=!1,a):null;switch(a){case "paste":return null;case "keypress":if(!(b.ctrlKey||b.altKey||b.metaKey)||b.ctrlKey&&b.altKey){if(b.char&&1<b.char.length)return b.char;if(b.which)return String.fromCharCode(b.which)}return null;
case "compositionend":return xg&&"ko"!==b.locale?null:b.data;default:return null}}function yg(a){var b=a&&a.nodeName&&a.nodeName.toLowerCase();return"input"===b?!!Qi[a.type]:"textarea"===b?!0:!1}function zg(a,b,c){a=R.getPooled(Ag.change,a,b,c);a.type="change";sf(c);lb(a);return a}function Ri(a){pc(a)}function zc(a){var b=Pa(a);if(Gf(b))return a}function Si(a,b){if("change"===a)return b}function Bg(){Mb&&(Mb.detachEvent("onpropertychange",Cg),Nb=Mb=null)}function Cg(a){if("value"===a.propertyName&&
zc(Nb))if(a=zg(Nb,a,Ld(a)),Oa)pc(a);else{Oa=!0;try{ee(Ri,a)}finally{Oa=!1,ud()}}}function Ti(a,b,c){"focus"===a?(Bg(),Mb=b,Nb=c,Mb.attachEvent("onpropertychange",Cg)):"blur"===a&&Bg()}function Ui(a,b){if("selectionchange"===a||"keyup"===a||"keydown"===a)return zc(Nb)}function Vi(a,b){if("click"===a)return zc(b)}function Wi(a,b){if("input"===a||"change"===a)return zc(b)}function Xi(a){var b=this.nativeEvent;return b.getModifierState?b.getModifierState(a):(a=Yi[a])?!!b[a]:!1}function fe(a){return Xi}
function Zi(a,b){return a===b&&(0!==a||1/a===1/b)||a!==a&&b!==b}function Ob(a,b){if(Qa(a,b))return!0;if("object"!==typeof a||null===a||"object"!==typeof b||null===b)return!1;var c=Object.keys(a),d=Object.keys(b);if(c.length!==d.length)return!1;for(d=0;d<c.length;d++)if(!$i.call(b,c[d])||!Qa(a[c[d]],b[c[d]]))return!1;return!0}function Dg(a,b){var c=b.window===b?b.document:9===b.nodeType?b:b.ownerDocument;if(ge||null==nb||nb!==Wd(c))return null;c=nb;"selectionStart"in c&&Xd(c)?c={start:c.selectionStart,
end:c.selectionEnd}:(c=(c.ownerDocument&&c.ownerDocument.defaultView||window).getSelection(),c={anchorNode:c.anchorNode,anchorOffset:c.anchorOffset,focusNode:c.focusNode,focusOffset:c.focusOffset});return Pb&&Ob(Pb,c)?null:(Pb=c,a=R.getPooled(Eg.select,he,a,b),a.type="select",a.target=nb,lb(a),a)}function Ac(a){var b=a.keyCode;"charCode"in a?(a=a.charCode,0===a&&13===b&&(a=13)):a=b;10===a&&(a=13);return 32<=a||13===a?a:0}function q(a,b){0>ob||(a.current=ie[ob],ie[ob]=null,ob--)}function y(a,b,c){ob++;
ie[ob]=a.current;a.current=b}function pb(a,b){var c=a.type.contextTypes;if(!c)return Ca;var d=a.stateNode;if(d&&d.__reactInternalMemoizedUnmaskedChildContext===b)return d.__reactInternalMemoizedMaskedChildContext;var e={},f;for(f in c)e[f]=b[f];d&&(a=a.stateNode,a.__reactInternalMemoizedUnmaskedChildContext=b,a.__reactInternalMemoizedMaskedChildContext=e);return e}function N(a){a=a.childContextTypes;return null!==a&&void 0!==a}function Fg(a,b,c){if(B.current!==Ca)throw Error(k(168));y(B,b);y(G,c)}
function Gg(a,b,c){var d=a.stateNode;a=b.childContextTypes;if("function"!==typeof d.getChildContext)return c;d=d.getChildContext();for(var e in d)if(!(e in a))throw Error(k(108,na(b)||"Unknown",e));return M({},c,{},d)}function Bc(a){a=(a=a.stateNode)&&a.__reactInternalMemoizedMergedChildContext||Ca;Ra=B.current;y(B,a);y(G,G.current);return!0}function Hg(a,b,c){var d=a.stateNode;if(!d)throw Error(k(169));c?(a=Gg(a,b,Ra),d.__reactInternalMemoizedMergedChildContext=a,q(G),q(B),y(B,a)):q(G);y(G,c)}function Cc(){switch(aj()){case Dc:return 99;
case Ig:return 98;case Jg:return 97;case Kg:return 96;case Lg:return 95;default:throw Error(k(332));}}function Mg(a){switch(a){case 99:return Dc;case 98:return Ig;case 97:return Jg;case 96:return Kg;case 95:return Lg;default:throw Error(k(332));}}function Da(a,b){a=Mg(a);return bj(a,b)}function Ng(a,b,c){a=Mg(a);return je(a,b,c)}function Og(a){null===qa?(qa=[a],Ec=je(Dc,Pg)):qa.push(a);return Qg}function ha(){if(null!==Ec){var a=Ec;Ec=null;Rg(a)}Pg()}function Pg(){if(!ke&&null!==qa){ke=!0;var a=0;
try{var b=qa;Da(99,function(){for(;a<b.length;a++){var c=b[a];do c=c(!0);while(null!==c)}});qa=null}catch(c){throw null!==qa&&(qa=qa.slice(a+1)),je(Dc,ha),c;}finally{ke=!1}}}function Fc(a,b,c){c/=10;return 1073741821-(((1073741821-a+b/10)/c|0)+1)*c}function aa(a,b){if(a&&a.defaultProps){b=M({},b);a=a.defaultProps;for(var c in a)void 0===b[c]&&(b[c]=a[c])}return b}function le(){Gc=qb=Hc=null}function me(a){var b=Ic.current;q(Ic);a.type._context._currentValue=b}function Sg(a,b){for(;null!==a;){var c=
a.alternate;if(a.childExpirationTime<b)a.childExpirationTime=b,null!==c&&c.childExpirationTime<b&&(c.childExpirationTime=b);else if(null!==c&&c.childExpirationTime<b)c.childExpirationTime=b;else break;a=a.return}}function rb(a,b){Hc=a;Gc=qb=null;a=a.dependencies;null!==a&&null!==a.firstContext&&(a.expirationTime>=b&&(ia=!0),a.firstContext=null)}function W(a,b){if(Gc!==a&&!1!==b&&0!==b){if("number"!==typeof b||1073741823===b)Gc=a,b=1073741823;b={context:a,observedBits:b,next:null};if(null===qb){if(null===
Hc)throw Error(k(308));qb=b;Hc.dependencies={expirationTime:0,firstContext:b,responders:null}}else qb=qb.next=b}return a._currentValue}function ne(a){a.updateQueue={baseState:a.memoizedState,baseQueue:null,shared:{pending:null},effects:null}}function oe(a,b){a=a.updateQueue;b.updateQueue===a&&(b.updateQueue={baseState:a.baseState,baseQueue:a.baseQueue,shared:a.shared,effects:a.effects})}function Ea(a,b){a={expirationTime:a,suspenseConfig:b,tag:Tg,payload:null,callback:null,next:null};return a.next=
a}function Fa(a,b){a=a.updateQueue;if(null!==a){a=a.shared;var c=a.pending;null===c?b.next=b:(b.next=c.next,c.next=b);a.pending=b}}function Ug(a,b){var c=a.alternate;null!==c&&oe(c,a);a=a.updateQueue;c=a.baseQueue;null===c?(a.baseQueue=b.next=b,b.next=b):(b.next=c.next,c.next=b)}function Qb(a,b,c,d){var e=a.updateQueue;Ga=!1;var f=e.baseQueue,g=e.shared.pending;if(null!==g){if(null!==f){var h=f.next;f.next=g.next;g.next=h}f=g;e.shared.pending=null;h=a.alternate;null!==h&&(h=h.updateQueue,null!==h&&
(h.baseQueue=g))}if(null!==f){h=f.next;var m=e.baseState,n=0,k=null,ba=null,l=null;if(null!==h){var p=h;do{g=p.expirationTime;if(g<d){var t={expirationTime:p.expirationTime,suspenseConfig:p.suspenseConfig,tag:p.tag,payload:p.payload,callback:p.callback,next:null};null===l?(ba=l=t,k=m):l=l.next=t;g>n&&(n=g)}else{null!==l&&(l=l.next={expirationTime:1073741823,suspenseConfig:p.suspenseConfig,tag:p.tag,payload:p.payload,callback:p.callback,next:null});Vg(g,p.suspenseConfig);a:{var q=a,r=p;g=b;t=c;switch(r.tag){case 1:q=
r.payload;if("function"===typeof q){m=q.call(t,m,g);break a}m=q;break a;case 3:q.effectTag=q.effectTag&-4097|64;case Tg:q=r.payload;g="function"===typeof q?q.call(t,m,g):q;if(null===g||void 0===g)break a;m=M({},m,g);break a;case Jc:Ga=!0}}null!==p.callback&&(a.effectTag|=32,g=e.effects,null===g?e.effects=[p]:g.push(p))}p=p.next;if(null===p||p===h)if(g=e.shared.pending,null===g)break;else p=f.next=g.next,g.next=h,e.baseQueue=f=g,e.shared.pending=null}while(1)}null===l?k=m:l.next=ba;e.baseState=k;e.baseQueue=
l;Kc(n);a.expirationTime=n;a.memoizedState=m}}function Wg(a,b,c){a=b.effects;b.effects=null;if(null!==a)for(b=0;b<a.length;b++){var d=a[b],e=d.callback;if(null!==e){d.callback=null;d=e;e=c;if("function"!==typeof d)throw Error(k(191,d));d.call(e)}}}function Lc(a,b,c,d){b=a.memoizedState;c=c(d,b);c=null===c||void 0===c?b:M({},b,c);a.memoizedState=c;0===a.expirationTime&&(a.updateQueue.baseState=c)}function Xg(a,b,c,d,e,f,g){a=a.stateNode;return"function"===typeof a.shouldComponentUpdate?a.shouldComponentUpdate(d,
f,g):b.prototype&&b.prototype.isPureReactComponent?!Ob(c,d)||!Ob(e,f):!0}function Yg(a,b,c){var d=!1,e=Ca;var f=b.contextType;"object"===typeof f&&null!==f?f=W(f):(e=N(b)?Ra:B.current,d=b.contextTypes,f=(d=null!==d&&void 0!==d)?pb(a,e):Ca);b=new b(c,f);a.memoizedState=null!==b.state&&void 0!==b.state?b.state:null;b.updater=Mc;a.stateNode=b;b._reactInternalFiber=a;d&&(a=a.stateNode,a.__reactInternalMemoizedUnmaskedChildContext=e,a.__reactInternalMemoizedMaskedChildContext=f);return b}function Zg(a,
b,c,d){a=b.state;"function"===typeof b.componentWillReceiveProps&&b.componentWillReceiveProps(c,d);"function"===typeof b.UNSAFE_componentWillReceiveProps&&b.UNSAFE_componentWillReceiveProps(c,d);b.state!==a&&Mc.enqueueReplaceState(b,b.state,null)}function pe(a,b,c,d){var e=a.stateNode;e.props=c;e.state=a.memoizedState;e.refs=$g;ne(a);var f=b.contextType;"object"===typeof f&&null!==f?e.context=W(f):(f=N(b)?Ra:B.current,e.context=pb(a,f));Qb(a,c,e,d);e.state=a.memoizedState;f=b.getDerivedStateFromProps;
"function"===typeof f&&(Lc(a,b,f,c),e.state=a.memoizedState);"function"===typeof b.getDerivedStateFromProps||"function"===typeof e.getSnapshotBeforeUpdate||"function"!==typeof e.UNSAFE_componentWillMount&&"function"!==typeof e.componentWillMount||(b=e.state,"function"===typeof e.componentWillMount&&e.componentWillMount(),"function"===typeof e.UNSAFE_componentWillMount&&e.UNSAFE_componentWillMount(),b!==e.state&&Mc.enqueueReplaceState(e,e.state,null),Qb(a,c,e,d),e.state=a.memoizedState);"function"===
typeof e.componentDidMount&&(a.effectTag|=4)}function Rb(a,b,c){a=c.ref;if(null!==a&&"function"!==typeof a&&"object"!==typeof a){if(c._owner){c=c._owner;if(c){if(1!==c.tag)throw Error(k(309));var d=c.stateNode}if(!d)throw Error(k(147,a));var e=""+a;if(null!==b&&null!==b.ref&&"function"===typeof b.ref&&b.ref._stringRef===e)return b.ref;b=function(a){var b=d.refs;b===$g&&(b=d.refs={});null===a?delete b[e]:b[e]=a};b._stringRef=e;return b}if("string"!==typeof a)throw Error(k(284));if(!c._owner)throw Error(k(290,
a));}return a}function Nc(a,b){if("textarea"!==a.type)throw Error(k(31,"[object Object]"===Object.prototype.toString.call(b)?"object with keys {"+Object.keys(b).join(", ")+"}":b,""));}function ah(a){function b(b,c){if(a){var d=b.lastEffect;null!==d?(d.nextEffect=c,b.lastEffect=c):b.firstEffect=b.lastEffect=c;c.nextEffect=null;c.effectTag=8}}function c(c,d){if(!a)return null;for(;null!==d;)b(c,d),d=d.sibling;return null}function d(a,b){for(a=new Map;null!==b;)null!==b.key?a.set(b.key,b):a.set(b.index,
b),b=b.sibling;return a}function e(a,b){a=Sa(a,b);a.index=0;a.sibling=null;return a}function f(b,c,d){b.index=d;if(!a)return c;d=b.alternate;if(null!==d)return d=d.index,d<c?(b.effectTag=2,c):d;b.effectTag=2;return c}function g(b){a&&null===b.alternate&&(b.effectTag=2);return b}function h(a,b,c,d){if(null===b||6!==b.tag)return b=qe(c,a.mode,d),b.return=a,b;b=e(b,c);b.return=a;return b}function m(a,b,c,d){if(null!==b&&b.elementType===c.type)return d=e(b,c.props),d.ref=Rb(a,b,c),d.return=a,d;d=Oc(c.type,
c.key,c.props,null,a.mode,d);d.ref=Rb(a,b,c);d.return=a;return d}function n(a,b,c,d){if(null===b||4!==b.tag||b.stateNode.containerInfo!==c.containerInfo||b.stateNode.implementation!==c.implementation)return b=re(c,a.mode,d),b.return=a,b;b=e(b,c.children||[]);b.return=a;return b}function l(a,b,c,d,f){if(null===b||7!==b.tag)return b=Ha(c,a.mode,d,f),b.return=a,b;b=e(b,c);b.return=a;return b}function ba(a,b,c){if("string"===typeof b||"number"===typeof b)return b=qe(""+b,a.mode,c),b.return=a,b;if("object"===
typeof b&&null!==b){switch(b.$$typeof){case Pc:return c=Oc(b.type,b.key,b.props,null,a.mode,c),c.ref=Rb(a,null,b),c.return=a,c;case gb:return b=re(b,a.mode,c),b.return=a,b}if(Qc(b)||zb(b))return b=Ha(b,a.mode,c,null),b.return=a,b;Nc(a,b)}return null}function p(a,b,c,d){var e=null!==b?b.key:null;if("string"===typeof c||"number"===typeof c)return null!==e?null:h(a,b,""+c,d);if("object"===typeof c&&null!==c){switch(c.$$typeof){case Pc:return c.key===e?c.type===Ma?l(a,b,c.props.children,d,e):m(a,b,c,
d):null;case gb:return c.key===e?n(a,b,c,d):null}if(Qc(c)||zb(c))return null!==e?null:l(a,b,c,d,null);Nc(a,c)}return null}function t(a,b,c,d,e){if("string"===typeof d||"number"===typeof d)return a=a.get(c)||null,h(b,a,""+d,e);if("object"===typeof d&&null!==d){switch(d.$$typeof){case Pc:return a=a.get(null===d.key?c:d.key)||null,d.type===Ma?l(b,a,d.props.children,e,d.key):m(b,a,d,e);case gb:return a=a.get(null===d.key?c:d.key)||null,n(b,a,d,e)}if(Qc(d)||zb(d))return a=a.get(c)||null,l(b,a,d,e,null);
Nc(b,d)}return null}function q(e,g,h,m){for(var n=null,k=null,l=g,r=g=0,C=null;null!==l&&r<h.length;r++){l.index>r?(C=l,l=null):C=l.sibling;var O=p(e,l,h[r],m);if(null===O){null===l&&(l=C);break}a&&l&&null===O.alternate&&b(e,l);g=f(O,g,r);null===k?n=O:k.sibling=O;k=O;l=C}if(r===h.length)return c(e,l),n;if(null===l){for(;r<h.length;r++)l=ba(e,h[r],m),null!==l&&(g=f(l,g,r),null===k?n=l:k.sibling=l,k=l);return n}for(l=d(e,l);r<h.length;r++)C=t(l,e,r,h[r],m),null!==C&&(a&&null!==C.alternate&&l.delete(null===
C.key?r:C.key),g=f(C,g,r),null===k?n=C:k.sibling=C,k=C);a&&l.forEach(function(a){return b(e,a)});return n}function w(e,g,h,n){var m=zb(h);if("function"!==typeof m)throw Error(k(150));h=m.call(h);if(null==h)throw Error(k(151));for(var l=m=null,r=g,C=g=0,O=null,v=h.next();null!==r&&!v.done;C++,v=h.next()){r.index>C?(O=r,r=null):O=r.sibling;var q=p(e,r,v.value,n);if(null===q){null===r&&(r=O);break}a&&r&&null===q.alternate&&b(e,r);g=f(q,g,C);null===l?m=q:l.sibling=q;l=q;r=O}if(v.done)return c(e,r),m;
if(null===r){for(;!v.done;C++,v=h.next())v=ba(e,v.value,n),null!==v&&(g=f(v,g,C),null===l?m=v:l.sibling=v,l=v);return m}for(r=d(e,r);!v.done;C++,v=h.next())v=t(r,e,C,v.value,n),null!==v&&(a&&null!==v.alternate&&r.delete(null===v.key?C:v.key),g=f(v,g,C),null===l?m=v:l.sibling=v,l=v);a&&r.forEach(function(a){return b(e,a)});return m}return function(a,d,f,h){var m="object"===typeof f&&null!==f&&f.type===Ma&&null===f.key;m&&(f=f.props.children);var n="object"===typeof f&&null!==f;if(n)switch(f.$$typeof){case Pc:a:{n=
f.key;for(m=d;null!==m;){if(m.key===n){switch(m.tag){case 7:if(f.type===Ma){c(a,m.sibling);d=e(m,f.props.children);d.return=a;a=d;break a}break;default:if(m.elementType===f.type){c(a,m.sibling);d=e(m,f.props);d.ref=Rb(a,m,f);d.return=a;a=d;break a}}c(a,m);break}else b(a,m);m=m.sibling}f.type===Ma?(d=Ha(f.props.children,a.mode,h,f.key),d.return=a,a=d):(h=Oc(f.type,f.key,f.props,null,a.mode,h),h.ref=Rb(a,d,f),h.return=a,a=h)}return g(a);case gb:a:{for(m=f.key;null!==d;){if(d.key===m)if(4===d.tag&&d.stateNode.containerInfo===
f.containerInfo&&d.stateNode.implementation===f.implementation){c(a,d.sibling);d=e(d,f.children||[]);d.return=a;a=d;break a}else{c(a,d);break}else b(a,d);d=d.sibling}d=re(f,a.mode,h);d.return=a;a=d}return g(a)}if("string"===typeof f||"number"===typeof f)return f=""+f,null!==d&&6===d.tag?(c(a,d.sibling),d=e(d,f),d.return=a,a=d):(c(a,d),d=qe(f,a.mode,h),d.return=a,a=d),g(a);if(Qc(f))return q(a,d,f,h);if(zb(f))return w(a,d,f,h);n&&Nc(a,f);if("undefined"===typeof f&&!m)switch(a.tag){case 1:case 0:throw a=
a.type,Error(k(152,a.displayName||a.name||"Component"));}return c(a,d)}}function Ta(a){if(a===Sb)throw Error(k(174));return a}function se(a,b){y(Tb,b);y(Ub,a);y(ja,Sb);a=b.nodeType;switch(a){case 9:case 11:b=(b=b.documentElement)?b.namespaceURI:Hd(null,"");break;default:a=8===a?b.parentNode:b,b=a.namespaceURI||null,a=a.tagName,b=Hd(b,a)}q(ja);y(ja,b)}function tb(a){q(ja);q(Ub);q(Tb)}function bh(a){Ta(Tb.current);var b=Ta(ja.current);var c=Hd(b,a.type);b!==c&&(y(Ub,a),y(ja,c))}function te(a){Ub.current===
a&&(q(ja),q(Ub))}function Rc(a){for(var b=a;null!==b;){if(13===b.tag){var c=b.memoizedState;if(null!==c&&(c=c.dehydrated,null===c||c.data===$d||c.data===Zd))return b}else if(19===b.tag&&void 0!==b.memoizedProps.revealOrder){if(0!==(b.effectTag&64))return b}else if(null!==b.child){b.child.return=b;b=b.child;continue}if(b===a)break;for(;null===b.sibling;){if(null===b.return||b.return===a)return null;b=b.return}b.sibling.return=b.return;b=b.sibling}return null}function ue(a,b){return{responder:a,props:b}}
function S(){throw Error(k(321));}function ve(a,b){if(null===b)return!1;for(var c=0;c<b.length&&c<a.length;c++)if(!Qa(a[c],b[c]))return!1;return!0}function we(a,b,c,d,e,f){Ia=f;z=b;b.memoizedState=null;b.updateQueue=null;b.expirationTime=0;Sc.current=null===a||null===a.memoizedState?dj:ej;a=c(d,e);if(b.expirationTime===Ia){f=0;do{b.expirationTime=0;if(!(25>f))throw Error(k(301));f+=1;J=K=null;b.updateQueue=null;Sc.current=fj;a=c(d,e)}while(b.expirationTime===Ia)}Sc.current=Tc;b=null!==K&&null!==K.next;
Ia=0;J=K=z=null;Uc=!1;if(b)throw Error(k(300));return a}function ub(){var a={memoizedState:null,baseState:null,baseQueue:null,queue:null,next:null};null===J?z.memoizedState=J=a:J=J.next=a;return J}function vb(){if(null===K){var a=z.alternate;a=null!==a?a.memoizedState:null}else a=K.next;var b=null===J?z.memoizedState:J.next;if(null!==b)J=b,K=a;else{if(null===a)throw Error(k(310));K=a;a={memoizedState:K.memoizedState,baseState:K.baseState,baseQueue:K.baseQueue,queue:K.queue,next:null};null===J?z.memoizedState=
J=a:J=J.next=a}return J}function Ua(a,b){return"function"===typeof b?b(a):b}function Vc(a,b,c){b=vb();c=b.queue;if(null===c)throw Error(k(311));c.lastRenderedReducer=a;var d=K,e=d.baseQueue,f=c.pending;if(null!==f){if(null!==e){var g=e.next;e.next=f.next;f.next=g}d.baseQueue=e=f;c.pending=null}if(null!==e){e=e.next;d=d.baseState;var h=g=f=null,m=e;do{var n=m.expirationTime;if(n<Ia){var l={expirationTime:m.expirationTime,suspenseConfig:m.suspenseConfig,action:m.action,eagerReducer:m.eagerReducer,eagerState:m.eagerState,
next:null};null===h?(g=h=l,f=d):h=h.next=l;n>z.expirationTime&&(z.expirationTime=n,Kc(n))}else null!==h&&(h=h.next={expirationTime:1073741823,suspenseConfig:m.suspenseConfig,action:m.action,eagerReducer:m.eagerReducer,eagerState:m.eagerState,next:null}),Vg(n,m.suspenseConfig),d=m.eagerReducer===a?m.eagerState:a(d,m.action);m=m.next}while(null!==m&&m!==e);null===h?f=d:h.next=g;Qa(d,b.memoizedState)||(ia=!0);b.memoizedState=d;b.baseState=f;b.baseQueue=h;c.lastRenderedState=d}return[b.memoizedState,
c.dispatch]}function Wc(a,b,c){b=vb();c=b.queue;if(null===c)throw Error(k(311));c.lastRenderedReducer=a;var d=c.dispatch,e=c.pending,f=b.memoizedState;if(null!==e){c.pending=null;var g=e=e.next;do f=a(f,g.action),g=g.next;while(g!==e);Qa(f,b.memoizedState)||(ia=!0);b.memoizedState=f;null===b.baseQueue&&(b.baseState=f);c.lastRenderedState=f}return[f,d]}function xe(a){var b=ub();"function"===typeof a&&(a=a());b.memoizedState=b.baseState=a;a=b.queue={pending:null,dispatch:null,lastRenderedReducer:Ua,
lastRenderedState:a};a=a.dispatch=ch.bind(null,z,a);return[b.memoizedState,a]}function ye(a,b,c,d){a={tag:a,create:b,destroy:c,deps:d,next:null};b=z.updateQueue;null===b?(b={lastEffect:null},z.updateQueue=b,b.lastEffect=a.next=a):(c=b.lastEffect,null===c?b.lastEffect=a.next=a:(d=c.next,c.next=a,a.next=d,b.lastEffect=a));return a}function dh(a){return vb().memoizedState}function ze(a,b,c,d){var e=ub();z.effectTag|=a;e.memoizedState=ye(1|b,c,void 0,void 0===d?null:d)}function Ae(a,b,c,d){var e=vb();
d=void 0===d?null:d;var f=void 0;if(null!==K){var g=K.memoizedState;f=g.destroy;if(null!==d&&ve(d,g.deps)){ye(b,c,f,d);return}}z.effectTag|=a;e.memoizedState=ye(1|b,c,f,d)}function eh(a,b){return ze(516,4,a,b)}function Xc(a,b){return Ae(516,4,a,b)}function fh(a,b){return Ae(4,2,a,b)}function gh(a,b){if("function"===typeof b)return a=a(),b(a),function(){b(null)};if(null!==b&&void 0!==b)return a=a(),b.current=a,function(){b.current=null}}function hh(a,b,c){c=null!==c&&void 0!==c?c.concat([a]):null;
return Ae(4,2,gh.bind(null,b,a),c)}function Be(a,b){}function ih(a,b){ub().memoizedState=[a,void 0===b?null:b];return a}function Yc(a,b){var c=vb();b=void 0===b?null:b;var d=c.memoizedState;if(null!==d&&null!==b&&ve(b,d[1]))return d[0];c.memoizedState=[a,b];return a}function jh(a,b){var c=vb();b=void 0===b?null:b;var d=c.memoizedState;if(null!==d&&null!==b&&ve(b,d[1]))return d[0];a=a();c.memoizedState=[a,b];return a}function Ce(a,b,c){var d=Cc();Da(98>d?98:d,function(){a(!0)});Da(97<d?97:d,function(){var d=
X.suspense;X.suspense=void 0===b?null:b;try{a(!1),c()}finally{X.suspense=d}})}function ch(a,b,c){var d=ka(),e=Vb.suspense;d=Va(d,a,e);e={expirationTime:d,suspenseConfig:e,action:c,eagerReducer:null,eagerState:null,next:null};var f=b.pending;null===f?e.next=e:(e.next=f.next,f.next=e);b.pending=e;f=a.alternate;if(a===z||null!==f&&f===z)Uc=!0,e.expirationTime=Ia,z.expirationTime=Ia;else{if(0===a.expirationTime&&(null===f||0===f.expirationTime)&&(f=b.lastRenderedReducer,null!==f))try{var g=b.lastRenderedState,
h=f(g,c);e.eagerReducer=f;e.eagerState=h;if(Qa(h,g))return}catch(m){}finally{}Ja(a,d)}}function kh(a,b){var c=la(5,null,null,0);c.elementType="DELETED";c.type="DELETED";c.stateNode=b;c.return=a;c.effectTag=8;null!==a.lastEffect?(a.lastEffect.nextEffect=c,a.lastEffect=c):a.firstEffect=a.lastEffect=c}function lh(a,b){switch(a.tag){case 5:var c=a.type;b=1!==b.nodeType||c.toLowerCase()!==b.nodeName.toLowerCase()?null:b;return null!==b?(a.stateNode=b,!0):!1;case 6:return b=""===a.pendingProps||3!==b.nodeType?
null:b,null!==b?(a.stateNode=b,!0):!1;case 13:return!1;default:return!1}}function De(a){if(Wa){var b=Ka;if(b){var c=b;if(!lh(a,b)){b=kb(c.nextSibling);if(!b||!lh(a,b)){a.effectTag=a.effectTag&-1025|2;Wa=!1;ra=a;return}kh(ra,c)}ra=a;Ka=kb(b.firstChild)}else a.effectTag=a.effectTag&-1025|2,Wa=!1,ra=a}}function mh(a){for(a=a.return;null!==a&&5!==a.tag&&3!==a.tag&&13!==a.tag;)a=a.return;ra=a}function Zc(a){if(a!==ra)return!1;if(!Wa)return mh(a),Wa=!0,!1;var b=a.type;if(5!==a.tag||"head"!==b&&"body"!==
b&&!Yd(b,a.memoizedProps))for(b=Ka;b;)kh(a,b),b=kb(b.nextSibling);mh(a);if(13===a.tag){a=a.memoizedState;a=null!==a?a.dehydrated:null;if(!a)throw Error(k(317));a:{a=a.nextSibling;for(b=0;a;){if(8===a.nodeType){var c=a.data;if(c===og){if(0===b){Ka=kb(a.nextSibling);break a}b--}else c!==ng&&c!==Zd&&c!==$d||b++}a=a.nextSibling}Ka=null}}else Ka=ra?kb(a.stateNode.nextSibling):null;return!0}function Ee(){Ka=ra=null;Wa=!1}function T(a,b,c,d){b.child=null===a?Fe(b,null,c,d):wb(b,a.child,c,d)}function nh(a,
b,c,d,e){c=c.render;var f=b.ref;rb(b,e);d=we(a,b,c,d,f,e);if(null!==a&&!ia)return b.updateQueue=a.updateQueue,b.effectTag&=-517,a.expirationTime<=e&&(a.expirationTime=0),sa(a,b,e);b.effectTag|=1;T(a,b,d,e);return b.child}function oh(a,b,c,d,e,f){if(null===a){var g=c.type;if("function"===typeof g&&!Ge(g)&&void 0===g.defaultProps&&null===c.compare&&void 0===c.defaultProps)return b.tag=15,b.type=g,ph(a,b,g,d,e,f);a=Oc(c.type,null,d,null,b.mode,f);a.ref=b.ref;a.return=b;return b.child=a}g=a.child;if(e<
f&&(e=g.memoizedProps,c=c.compare,c=null!==c?c:Ob,c(e,d)&&a.ref===b.ref))return sa(a,b,f);b.effectTag|=1;a=Sa(g,d);a.ref=b.ref;a.return=b;return b.child=a}function ph(a,b,c,d,e,f){return null!==a&&Ob(a.memoizedProps,d)&&a.ref===b.ref&&(ia=!1,e<f)?(b.expirationTime=a.expirationTime,sa(a,b,f)):He(a,b,c,d,f)}function qh(a,b){var c=b.ref;if(null===a&&null!==c||null!==a&&a.ref!==c)b.effectTag|=128}function He(a,b,c,d,e){var f=N(c)?Ra:B.current;f=pb(b,f);rb(b,e);c=we(a,b,c,d,f,e);if(null!==a&&!ia)return b.updateQueue=
a.updateQueue,b.effectTag&=-517,a.expirationTime<=e&&(a.expirationTime=0),sa(a,b,e);b.effectTag|=1;T(a,b,c,e);return b.child}function rh(a,b,c,d,e){if(N(c)){var f=!0;Bc(b)}else f=!1;rb(b,e);if(null===b.stateNode)null!==a&&(a.alternate=null,b.alternate=null,b.effectTag|=2),Yg(b,c,d),pe(b,c,d,e),d=!0;else if(null===a){var g=b.stateNode,h=b.memoizedProps;g.props=h;var m=g.context,n=c.contextType;"object"===typeof n&&null!==n?n=W(n):(n=N(c)?Ra:B.current,n=pb(b,n));var l=c.getDerivedStateFromProps,k="function"===
typeof l||"function"===typeof g.getSnapshotBeforeUpdate;k||"function"!==typeof g.UNSAFE_componentWillReceiveProps&&"function"!==typeof g.componentWillReceiveProps||(h!==d||m!==n)&&Zg(b,g,d,n);Ga=!1;var p=b.memoizedState;g.state=p;Qb(b,d,g,e);m=b.memoizedState;h!==d||p!==m||G.current||Ga?("function"===typeof l&&(Lc(b,c,l,d),m=b.memoizedState),(h=Ga||Xg(b,c,h,d,p,m,n))?(k||"function"!==typeof g.UNSAFE_componentWillMount&&"function"!==typeof g.componentWillMount||("function"===typeof g.componentWillMount&&
g.componentWillMount(),"function"===typeof g.UNSAFE_componentWillMount&&g.UNSAFE_componentWillMount()),"function"===typeof g.componentDidMount&&(b.effectTag|=4)):("function"===typeof g.componentDidMount&&(b.effectTag|=4),b.memoizedProps=d,b.memoizedState=m),g.props=d,g.state=m,g.context=n,d=h):("function"===typeof g.componentDidMount&&(b.effectTag|=4),d=!1)}else g=b.stateNode,oe(a,b),h=b.memoizedProps,g.props=b.type===b.elementType?h:aa(b.type,h),m=g.context,n=c.contextType,"object"===typeof n&&null!==
n?n=W(n):(n=N(c)?Ra:B.current,n=pb(b,n)),l=c.getDerivedStateFromProps,(k="function"===typeof l||"function"===typeof g.getSnapshotBeforeUpdate)||"function"!==typeof g.UNSAFE_componentWillReceiveProps&&"function"!==typeof g.componentWillReceiveProps||(h!==d||m!==n)&&Zg(b,g,d,n),Ga=!1,m=b.memoizedState,g.state=m,Qb(b,d,g,e),p=b.memoizedState,h!==d||m!==p||G.current||Ga?("function"===typeof l&&(Lc(b,c,l,d),p=b.memoizedState),(l=Ga||Xg(b,c,h,d,m,p,n))?(k||"function"!==typeof g.UNSAFE_componentWillUpdate&&
"function"!==typeof g.componentWillUpdate||("function"===typeof g.componentWillUpdate&&g.componentWillUpdate(d,p,n),"function"===typeof g.UNSAFE_componentWillUpdate&&g.UNSAFE_componentWillUpdate(d,p,n)),"function"===typeof g.componentDidUpdate&&(b.effectTag|=4),"function"===typeof g.getSnapshotBeforeUpdate&&(b.effectTag|=256)):("function"!==typeof g.componentDidUpdate||h===a.memoizedProps&&m===a.memoizedState||(b.effectTag|=4),"function"!==typeof g.getSnapshotBeforeUpdate||h===a.memoizedProps&&m===
a.memoizedState||(b.effectTag|=256),b.memoizedProps=d,b.memoizedState=p),g.props=d,g.state=p,g.context=n,d=l):("function"!==typeof g.componentDidUpdate||h===a.memoizedProps&&m===a.memoizedState||(b.effectTag|=4),"function"!==typeof g.getSnapshotBeforeUpdate||h===a.memoizedProps&&m===a.memoizedState||(b.effectTag|=256),d=!1);return Ie(a,b,c,d,f,e)}function Ie(a,b,c,d,e,f){qh(a,b);var g=0!==(b.effectTag&64);if(!d&&!g)return e&&Hg(b,c,!1),sa(a,b,f);d=b.stateNode;gj.current=b;var h=g&&"function"!==typeof c.getDerivedStateFromError?
null:d.render();b.effectTag|=1;null!==a&&g?(b.child=wb(b,a.child,null,f),b.child=wb(b,null,h,f)):T(a,b,h,f);b.memoizedState=d.state;e&&Hg(b,c,!0);return b.child}function sh(a){var b=a.stateNode;b.pendingContext?Fg(a,b.pendingContext,b.pendingContext!==b.context):b.context&&Fg(a,b.context,!1);se(a,b.containerInfo)}function th(a,b,c){var d=b.mode,e=b.pendingProps,f=D.current,g=!1,h;(h=0!==(b.effectTag&64))||(h=0!==(f&2)&&(null===a||null!==a.memoizedState));h?(g=!0,b.effectTag&=-65):null!==a&&null===
a.memoizedState||void 0===e.fallback||!0===e.unstable_avoidThisFallback||(f|=1);y(D,f&1);if(null===a){void 0!==e.fallback&&De(b);if(g){g=e.fallback;e=Ha(null,d,0,null);e.return=b;if(0===(b.mode&2))for(a=null!==b.memoizedState?b.child.child:b.child,e.child=a;null!==a;)a.return=e,a=a.sibling;c=Ha(g,d,c,null);c.return=b;e.sibling=c;b.memoizedState=Je;b.child=e;return c}d=e.children;b.memoizedState=null;return b.child=Fe(b,null,d,c)}if(null!==a.memoizedState){a=a.child;d=a.sibling;if(g){e=e.fallback;
c=Sa(a,a.pendingProps);c.return=b;if(0===(b.mode&2)&&(g=null!==b.memoizedState?b.child.child:b.child,g!==a.child))for(c.child=g;null!==g;)g.return=c,g=g.sibling;d=Sa(d,e);d.return=b;c.sibling=d;c.childExpirationTime=0;b.memoizedState=Je;b.child=c;return d}c=wb(b,a.child,e.children,c);b.memoizedState=null;return b.child=c}a=a.child;if(g){g=e.fallback;e=Ha(null,d,0,null);e.return=b;e.child=a;null!==a&&(a.return=e);if(0===(b.mode&2))for(a=null!==b.memoizedState?b.child.child:b.child,e.child=a;null!==
a;)a.return=e,a=a.sibling;c=Ha(g,d,c,null);c.return=b;e.sibling=c;c.effectTag|=2;e.childExpirationTime=0;b.memoizedState=Je;b.child=e;return c}b.memoizedState=null;return b.child=wb(b,a,e.children,c)}function uh(a,b){a.expirationTime<b&&(a.expirationTime=b);var c=a.alternate;null!==c&&c.expirationTime<b&&(c.expirationTime=b);Sg(a.return,b)}function Ke(a,b,c,d,e,f){var g=a.memoizedState;null===g?a.memoizedState={isBackwards:b,rendering:null,renderingStartTime:0,last:d,tail:c,tailExpiration:0,tailMode:e,
lastEffect:f}:(g.isBackwards=b,g.rendering=null,g.renderingStartTime=0,g.last=d,g.tail=c,g.tailExpiration=0,g.tailMode=e,g.lastEffect=f)}function vh(a,b,c){var d=b.pendingProps,e=d.revealOrder,f=d.tail;T(a,b,d.children,c);d=D.current;if(0!==(d&2))d=d&1|2,b.effectTag|=64;else{if(null!==a&&0!==(a.effectTag&64))a:for(a=b.child;null!==a;){if(13===a.tag)null!==a.memoizedState&&uh(a,c);else if(19===a.tag)uh(a,c);else if(null!==a.child){a.child.return=a;a=a.child;continue}if(a===b)break a;for(;null===a.sibling;){if(null===
a.return||a.return===b)break a;a=a.return}a.sibling.return=a.return;a=a.sibling}d&=1}y(D,d);if(0===(b.mode&2))b.memoizedState=null;else switch(e){case "forwards":c=b.child;for(e=null;null!==c;)a=c.alternate,null!==a&&null===Rc(a)&&(e=c),c=c.sibling;c=e;null===c?(e=b.child,b.child=null):(e=c.sibling,c.sibling=null);Ke(b,!1,e,c,f,b.lastEffect);break;case "backwards":c=null;e=b.child;for(b.child=null;null!==e;){a=e.alternate;if(null!==a&&null===Rc(a)){b.child=e;break}a=e.sibling;e.sibling=c;c=e;e=a}Ke(b,
!0,c,null,f,b.lastEffect);break;case "together":Ke(b,!1,null,null,void 0,b.lastEffect);break;default:b.memoizedState=null}return b.child}function sa(a,b,c){null!==a&&(b.dependencies=a.dependencies);var d=b.expirationTime;0!==d&&Kc(d);if(b.childExpirationTime<c)return null;if(null!==a&&b.child!==a.child)throw Error(k(153));if(null!==b.child){a=b.child;c=Sa(a,a.pendingProps);b.child=c;for(c.return=b;null!==a.sibling;)a=a.sibling,c=c.sibling=Sa(a,a.pendingProps),c.return=b;c.sibling=null}return b.child}
function $c(a,b){switch(a.tailMode){case "hidden":b=a.tail;for(var c=null;null!==b;)null!==b.alternate&&(c=b),b=b.sibling;null===c?a.tail=null:c.sibling=null;break;case "collapsed":c=a.tail;for(var d=null;null!==c;)null!==c.alternate&&(d=c),c=c.sibling;null===d?b||null===a.tail?a.tail=null:a.tail.sibling=null:d.sibling=null}}function hj(a,b,c){var d=b.pendingProps;switch(b.tag){case 2:case 16:case 15:case 0:case 11:case 7:case 8:case 12:case 9:case 14:return null;case 1:return N(b.type)&&(q(G),q(B)),
null;case 3:return tb(),q(G),q(B),c=b.stateNode,c.pendingContext&&(c.context=c.pendingContext,c.pendingContext=null),null!==a&&null!==a.child||!Zc(b)||(b.effectTag|=4),wh(b),null;case 5:te(b);c=Ta(Tb.current);var e=b.type;if(null!==a&&null!=b.stateNode)ij(a,b,e,d,c),a.ref!==b.ref&&(b.effectTag|=128);else{if(!d){if(null===b.stateNode)throw Error(k(166));return null}a=Ta(ja.current);if(Zc(b)){d=b.stateNode;e=b.type;var f=b.memoizedProps;d[Aa]=b;d[vc]=f;switch(e){case "iframe":case "object":case "embed":w("load",
d);break;case "video":case "audio":for(a=0;a<Db.length;a++)w(Db[a],d);break;case "source":w("error",d);break;case "img":case "image":case "link":w("error",d);w("load",d);break;case "form":w("reset",d);w("submit",d);break;case "details":w("toggle",d);break;case "input":Hf(d,f);w("invalid",d);oa(c,"onChange");break;case "select":d._wrapperState={wasMultiple:!!f.multiple};w("invalid",d);oa(c,"onChange");break;case "textarea":Kf(d,f),w("invalid",d),oa(c,"onChange")}Ud(e,f);a=null;for(var g in f)if(f.hasOwnProperty(g)){var h=
f[g];"children"===g?"string"===typeof h?d.textContent!==h&&(a=["children",h]):"number"===typeof h&&d.textContent!==""+h&&(a=["children",""+h]):db.hasOwnProperty(g)&&null!=h&&oa(c,g)}switch(e){case "input":mc(d);Jf(d,f,!0);break;case "textarea":mc(d);Mf(d);break;case "select":case "option":break;default:"function"===typeof f.onClick&&(d.onclick=uc)}c=a;b.updateQueue=c;null!==c&&(b.effectTag|=4)}else{g=9===c.nodeType?c:c.ownerDocument;"http://www.w3.org/1999/xhtml"===a&&(a=Nf(e));"http://www.w3.org/1999/xhtml"===
a?"script"===e?(a=g.createElement("div"),a.innerHTML="<script>\x3c/script>",a=a.removeChild(a.firstChild)):"string"===typeof d.is?a=g.createElement(e,{is:d.is}):(a=g.createElement(e),"select"===e&&(g=a,d.multiple?g.multiple=!0:d.size&&(g.size=d.size))):a=g.createElementNS(a,e);a[Aa]=b;a[vc]=d;jj(a,b,!1,!1);b.stateNode=a;g=Vd(e,d);switch(e){case "iframe":case "object":case "embed":w("load",a);h=d;break;case "video":case "audio":for(h=0;h<Db.length;h++)w(Db[h],a);h=d;break;case "source":w("error",a);
h=d;break;case "img":case "image":case "link":w("error",a);w("load",a);h=d;break;case "form":w("reset",a);w("submit",a);h=d;break;case "details":w("toggle",a);h=d;break;case "input":Hf(a,d);h=Cd(a,d);w("invalid",a);oa(c,"onChange");break;case "option":h=Fd(a,d);break;case "select":a._wrapperState={wasMultiple:!!d.multiple};h=M({},d,{value:void 0});w("invalid",a);oa(c,"onChange");break;case "textarea":Kf(a,d);h=Gd(a,d);w("invalid",a);oa(c,"onChange");break;default:h=d}Ud(e,h);var m=h;for(f in m)if(m.hasOwnProperty(f)){var n=
m[f];"style"===f?gg(a,n):"dangerouslySetInnerHTML"===f?(n=n?n.__html:void 0,null!=n&&xh(a,n)):"children"===f?"string"===typeof n?("textarea"!==e||""!==n)&&Wb(a,n):"number"===typeof n&&Wb(a,""+n):"suppressContentEditableWarning"!==f&&"suppressHydrationWarning"!==f&&"autoFocus"!==f&&(db.hasOwnProperty(f)?null!=n&&oa(c,f):null!=n&&xd(a,f,n,g))}switch(e){case "input":mc(a);Jf(a,d,!1);break;case "textarea":mc(a);Mf(a);break;case "option":null!=d.value&&a.setAttribute("value",""+va(d.value));break;case "select":a.multiple=
!!d.multiple;c=d.value;null!=c?hb(a,!!d.multiple,c,!1):null!=d.defaultValue&&hb(a,!!d.multiple,d.defaultValue,!0);break;default:"function"===typeof h.onClick&&(a.onclick=uc)}lg(e,d)&&(b.effectTag|=4)}null!==b.ref&&(b.effectTag|=128)}return null;case 6:if(a&&null!=b.stateNode)kj(a,b,a.memoizedProps,d);else{if("string"!==typeof d&&null===b.stateNode)throw Error(k(166));c=Ta(Tb.current);Ta(ja.current);Zc(b)?(c=b.stateNode,d=b.memoizedProps,c[Aa]=b,c.nodeValue!==d&&(b.effectTag|=4)):(c=(9===c.nodeType?
c:c.ownerDocument).createTextNode(d),c[Aa]=b,b.stateNode=c)}return null;case 13:q(D);d=b.memoizedState;if(0!==(b.effectTag&64))return b.expirationTime=c,b;c=null!==d;d=!1;null===a?void 0!==b.memoizedProps.fallback&&Zc(b):(e=a.memoizedState,d=null!==e,c||null===e||(e=a.child.sibling,null!==e&&(f=b.firstEffect,null!==f?(b.firstEffect=e,e.nextEffect=f):(b.firstEffect=b.lastEffect=e,e.nextEffect=null),e.effectTag=8)));if(c&&!d&&0!==(b.mode&2))if(null===a&&!0!==b.memoizedProps.unstable_avoidThisFallback||
0!==(D.current&1))F===Xa&&(F=ad);else{if(F===Xa||F===ad)F=bd;0!==Xb&&null!==U&&(Ya(U,P),yh(U,Xb))}if(c||d)b.effectTag|=4;return null;case 4:return tb(),wh(b),null;case 10:return me(b),null;case 17:return N(b.type)&&(q(G),q(B)),null;case 19:q(D);d=b.memoizedState;if(null===d)return null;e=0!==(b.effectTag&64);f=d.rendering;if(null===f)if(e)$c(d,!1);else{if(F!==Xa||null!==a&&0!==(a.effectTag&64))for(f=b.child;null!==f;){a=Rc(f);if(null!==a){b.effectTag|=64;$c(d,!1);e=a.updateQueue;null!==e&&(b.updateQueue=
e,b.effectTag|=4);null===d.lastEffect&&(b.firstEffect=null);b.lastEffect=d.lastEffect;for(d=b.child;null!==d;)e=d,f=c,e.effectTag&=2,e.nextEffect=null,e.firstEffect=null,e.lastEffect=null,a=e.alternate,null===a?(e.childExpirationTime=0,e.expirationTime=f,e.child=null,e.memoizedProps=null,e.memoizedState=null,e.updateQueue=null,e.dependencies=null):(e.childExpirationTime=a.childExpirationTime,e.expirationTime=a.expirationTime,e.child=a.child,e.memoizedProps=a.memoizedProps,e.memoizedState=a.memoizedState,
e.updateQueue=a.updateQueue,f=a.dependencies,e.dependencies=null===f?null:{expirationTime:f.expirationTime,firstContext:f.firstContext,responders:f.responders}),d=d.sibling;y(D,D.current&1|2);return b.child}f=f.sibling}}else{if(!e)if(a=Rc(f),null!==a){if(b.effectTag|=64,e=!0,c=a.updateQueue,null!==c&&(b.updateQueue=c,b.effectTag|=4),$c(d,!0),null===d.tail&&"hidden"===d.tailMode&&!f.alternate)return b=b.lastEffect=d.lastEffect,null!==b&&(b.nextEffect=null),null}else 2*Y()-d.renderingStartTime>d.tailExpiration&&
1<c&&(b.effectTag|=64,e=!0,$c(d,!1),b.expirationTime=b.childExpirationTime=c-1);d.isBackwards?(f.sibling=b.child,b.child=f):(c=d.last,null!==c?c.sibling=f:b.child=f,d.last=f)}return null!==d.tail?(0===d.tailExpiration&&(d.tailExpiration=Y()+500),c=d.tail,d.rendering=c,d.tail=c.sibling,d.lastEffect=b.lastEffect,d.renderingStartTime=Y(),c.sibling=null,b=D.current,y(D,e?b&1|2:b&1),c):null}throw Error(k(156,b.tag));}function lj(a,b){switch(a.tag){case 1:return N(a.type)&&(q(G),q(B)),b=a.effectTag,b&4096?
(a.effectTag=b&-4097|64,a):null;case 3:tb();q(G);q(B);b=a.effectTag;if(0!==(b&64))throw Error(k(285));a.effectTag=b&-4097|64;return a;case 5:return te(a),null;case 13:return q(D),b=a.effectTag,b&4096?(a.effectTag=b&-4097|64,a):null;case 19:return q(D),null;case 4:return tb(),null;case 10:return me(a),null;default:return null}}function Le(a,b){return{value:a,source:b,stack:Bd(b)}}function Me(a,b){var c=b.source,d=b.stack;null===d&&null!==c&&(d=Bd(c));null!==c&&na(c.type);b=b.value;null!==a&&1===a.tag&&
na(a.type);try{console.error(b)}catch(e){setTimeout(function(){throw e;})}}function mj(a,b){try{b.props=a.memoizedProps,b.state=a.memoizedState,b.componentWillUnmount()}catch(c){Za(a,c)}}function zh(a){var b=a.ref;if(null!==b)if("function"===typeof b)try{b(null)}catch(c){Za(a,c)}else b.current=null}function nj(a,b){switch(b.tag){case 0:case 11:case 15:case 22:return;case 1:if(b.effectTag&256&&null!==a){var c=a.memoizedProps,d=a.memoizedState;a=b.stateNode;b=a.getSnapshotBeforeUpdate(b.elementType===
b.type?c:aa(b.type,c),d);a.__reactInternalSnapshotBeforeUpdate=b}return;case 3:case 5:case 6:case 4:case 17:return}throw Error(k(163));}function Ah(a,b){b=b.updateQueue;b=null!==b?b.lastEffect:null;if(null!==b){var c=b=b.next;do{if((c.tag&a)===a){var d=c.destroy;c.destroy=void 0;void 0!==d&&d()}c=c.next}while(c!==b)}}function Bh(a,b){b=b.updateQueue;b=null!==b?b.lastEffect:null;if(null!==b){var c=b=b.next;do{if((c.tag&a)===a){var d=c.create;c.destroy=d()}c=c.next}while(c!==b)}}function oj(a,b,c,d){switch(c.tag){case 0:case 11:case 15:case 22:Bh(3,
c);return;case 1:a=c.stateNode;c.effectTag&4&&(null===b?a.componentDidMount():(d=c.elementType===c.type?b.memoizedProps:aa(c.type,b.memoizedProps),a.componentDidUpdate(d,b.memoizedState,a.__reactInternalSnapshotBeforeUpdate)));b=c.updateQueue;null!==b&&Wg(c,b,a);return;case 3:b=c.updateQueue;if(null!==b){a=null;if(null!==c.child)switch(c.child.tag){case 5:a=c.child.stateNode;break;case 1:a=c.child.stateNode}Wg(c,b,a)}return;case 5:a=c.stateNode;null===b&&c.effectTag&4&&lg(c.type,c.memoizedProps)&&
a.focus();return;case 6:return;case 4:return;case 12:return;case 13:null===c.memoizedState&&(c=c.alternate,null!==c&&(c=c.memoizedState,null!==c&&(c=c.dehydrated,null!==c&&bg(c))));return;case 19:case 17:case 20:case 21:return}throw Error(k(163));}function Ch(a,b,c){"function"===typeof Ne&&Ne(b);switch(b.tag){case 0:case 11:case 14:case 15:case 22:a=b.updateQueue;if(null!==a&&(a=a.lastEffect,null!==a)){var d=a.next;Da(97<c?97:c,function(){var a=d;do{var c=a.destroy;if(void 0!==c){var g=b;try{c()}catch(h){Za(g,
h)}}a=a.next}while(a!==d)})}break;case 1:zh(b);c=b.stateNode;"function"===typeof c.componentWillUnmount&&mj(b,c);break;case 5:zh(b);break;case 4:Dh(a,b,c)}}function Eh(a){var b=a.alternate;a.return=null;a.child=null;a.memoizedState=null;a.updateQueue=null;a.dependencies=null;a.alternate=null;a.firstEffect=null;a.lastEffect=null;a.pendingProps=null;a.memoizedProps=null;a.stateNode=null;null!==b&&Eh(b)}function Fh(a){return 5===a.tag||3===a.tag||4===a.tag}function Gh(a){a:{for(var b=a.return;null!==
b;){if(Fh(b)){var c=b;break a}b=b.return}throw Error(k(160));}b=c.stateNode;switch(c.tag){case 5:var d=!1;break;case 3:b=b.containerInfo;d=!0;break;case 4:b=b.containerInfo;d=!0;break;default:throw Error(k(161));}c.effectTag&16&&(Wb(b,""),c.effectTag&=-17);a:b:for(c=a;;){for(;null===c.sibling;){if(null===c.return||Fh(c.return)){c=null;break a}c=c.return}c.sibling.return=c.return;for(c=c.sibling;5!==c.tag&&6!==c.tag&&18!==c.tag;){if(c.effectTag&2)continue b;if(null===c.child||4===c.tag)continue b;
else c.child.return=c,c=c.child}if(!(c.effectTag&2)){c=c.stateNode;break a}}d?Oe(a,c,b):Pe(a,c,b)}function Oe(a,b,c){var d=a.tag,e=5===d||6===d;if(e)a=e?a.stateNode:a.stateNode.instance,b?8===c.nodeType?c.parentNode.insertBefore(a,b):c.insertBefore(a,b):(8===c.nodeType?(b=c.parentNode,b.insertBefore(a,c)):(b=c,b.appendChild(a)),c=c._reactRootContainer,null!==c&&void 0!==c||null!==b.onclick||(b.onclick=uc));else if(4!==d&&(a=a.child,null!==a))for(Oe(a,b,c),a=a.sibling;null!==a;)Oe(a,b,c),a=a.sibling}
function Pe(a,b,c){var d=a.tag,e=5===d||6===d;if(e)a=e?a.stateNode:a.stateNode.instance,b?c.insertBefore(a,b):c.appendChild(a);else if(4!==d&&(a=a.child,null!==a))for(Pe(a,b,c),a=a.sibling;null!==a;)Pe(a,b,c),a=a.sibling}function Dh(a,b,c){for(var d=b,e=!1,f,g;;){if(!e){e=d.return;a:for(;;){if(null===e)throw Error(k(160));f=e.stateNode;switch(e.tag){case 5:g=!1;break a;case 3:f=f.containerInfo;g=!0;break a;case 4:f=f.containerInfo;g=!0;break a}e=e.return}e=!0}if(5===d.tag||6===d.tag){a:for(var h=
a,m=d,n=c,l=m;;)if(Ch(h,l,n),null!==l.child&&4!==l.tag)l.child.return=l,l=l.child;else{if(l===m)break a;for(;null===l.sibling;){if(null===l.return||l.return===m)break a;l=l.return}l.sibling.return=l.return;l=l.sibling}g?(h=f,m=d.stateNode,8===h.nodeType?h.parentNode.removeChild(m):h.removeChild(m)):f.removeChild(d.stateNode)}else if(4===d.tag){if(null!==d.child){f=d.stateNode.containerInfo;g=!0;d.child.return=d;d=d.child;continue}}else if(Ch(a,d,c),null!==d.child){d.child.return=d;d=d.child;continue}if(d===
b)break;for(;null===d.sibling;){if(null===d.return||d.return===b)return;d=d.return;4===d.tag&&(e=!1)}d.sibling.return=d.return;d=d.sibling}}function Qe(a,b){switch(b.tag){case 0:case 11:case 14:case 15:case 22:Ah(3,b);return;case 1:return;case 5:var c=b.stateNode;if(null!=c){var d=b.memoizedProps,e=null!==a?a.memoizedProps:d;a=b.type;var f=b.updateQueue;b.updateQueue=null;if(null!==f){c[vc]=d;"input"===a&&"radio"===d.type&&null!=d.name&&If(c,d);Vd(a,e);b=Vd(a,d);for(e=0;e<f.length;e+=2){var g=f[e],
h=f[e+1];"style"===g?gg(c,h):"dangerouslySetInnerHTML"===g?xh(c,h):"children"===g?Wb(c,h):xd(c,g,h,b)}switch(a){case "input":Dd(c,d);break;case "textarea":Lf(c,d);break;case "select":b=c._wrapperState.wasMultiple,c._wrapperState.wasMultiple=!!d.multiple,a=d.value,null!=a?hb(c,!!d.multiple,a,!1):b!==!!d.multiple&&(null!=d.defaultValue?hb(c,!!d.multiple,d.defaultValue,!0):hb(c,!!d.multiple,d.multiple?[]:"",!1))}}}return;case 6:if(null===b.stateNode)throw Error(k(162));b.stateNode.nodeValue=b.memoizedProps;
return;case 3:b=b.stateNode;b.hydrate&&(b.hydrate=!1,bg(b.containerInfo));return;case 12:return;case 13:c=b;null===b.memoizedState?d=!1:(d=!0,c=b.child,Re=Y());if(null!==c)a:for(a=c;;){if(5===a.tag)f=a.stateNode,d?(f=f.style,"function"===typeof f.setProperty?f.setProperty("display","none","important"):f.display="none"):(f=a.stateNode,e=a.memoizedProps.style,e=void 0!==e&&null!==e&&e.hasOwnProperty("display")?e.display:null,f.style.display=fg("display",e));else if(6===a.tag)a.stateNode.nodeValue=d?
"":a.memoizedProps;else if(13===a.tag&&null!==a.memoizedState&&null===a.memoizedState.dehydrated){f=a.child.sibling;f.return=a;a=f;continue}else if(null!==a.child){a.child.return=a;a=a.child;continue}if(a===c)break;for(;null===a.sibling;){if(null===a.return||a.return===c)break a;a=a.return}a.sibling.return=a.return;a=a.sibling}Hh(b);return;case 19:Hh(b);return;case 17:return}throw Error(k(163));}function Hh(a){var b=a.updateQueue;if(null!==b){a.updateQueue=null;var c=a.stateNode;null===c&&(c=a.stateNode=
new pj);b.forEach(function(b){var d=qj.bind(null,a,b);c.has(b)||(c.add(b),b.then(d,d))})}}function Ih(a,b,c){c=Ea(c,null);c.tag=3;c.payload={element:null};var d=b.value;c.callback=function(){cd||(cd=!0,Se=d);Me(a,b)};return c}function Jh(a,b,c){c=Ea(c,null);c.tag=3;var d=a.type.getDerivedStateFromError;if("function"===typeof d){var e=b.value;c.payload=function(){Me(a,b);return d(e)}}var f=a.stateNode;null!==f&&"function"===typeof f.componentDidCatch&&(c.callback=function(){"function"!==typeof d&&
(null===La?La=new Set([this]):La.add(this),Me(a,b));var c=b.stack;this.componentDidCatch(b.value,{componentStack:null!==c?c:""})});return c}function ka(){return(p&(ca|ma))!==H?1073741821-(Y()/10|0):0!==dd?dd:dd=1073741821-(Y()/10|0)}function Va(a,b,c){b=b.mode;if(0===(b&2))return 1073741823;var d=Cc();if(0===(b&4))return 99===d?1073741823:1073741822;if((p&ca)!==H)return P;if(null!==c)a=Fc(a,c.timeoutMs|0||5E3,250);else switch(d){case 99:a=1073741823;break;case 98:a=Fc(a,150,100);break;case 97:case 96:a=
Fc(a,5E3,250);break;case 95:a=2;break;default:throw Error(k(326));}null!==U&&a===P&&--a;return a}function ed(a,b){a.expirationTime<b&&(a.expirationTime=b);var c=a.alternate;null!==c&&c.expirationTime<b&&(c.expirationTime=b);var d=a.return,e=null;if(null===d&&3===a.tag)e=a.stateNode;else for(;null!==d;){c=d.alternate;d.childExpirationTime<b&&(d.childExpirationTime=b);null!==c&&c.childExpirationTime<b&&(c.childExpirationTime=b);if(null===d.return&&3===d.tag){e=d.stateNode;break}d=d.return}null!==e&&
(U===e&&(Kc(b),F===bd&&Ya(e,P)),yh(e,b));return e}function fd(a){var b=a.lastExpiredTime;if(0!==b)return b;b=a.firstPendingTime;if(!Kh(a,b))return b;var c=a.lastPingedTime;a=a.nextKnownPendingLevel;a=c>a?c:a;return 2>=a&&b!==a?0:a}function V(a){if(0!==a.lastExpiredTime)a.callbackExpirationTime=1073741823,a.callbackPriority=99,a.callbackNode=Og(Te.bind(null,a));else{var b=fd(a),c=a.callbackNode;if(0===b)null!==c&&(a.callbackNode=null,a.callbackExpirationTime=0,a.callbackPriority=90);else{var d=ka();
1073741823===b?d=99:1===b||2===b?d=95:(d=10*(1073741821-b)-10*(1073741821-d),d=0>=d?99:250>=d?98:5250>=d?97:95);if(null!==c){var e=a.callbackPriority;if(a.callbackExpirationTime===b&&e>=d)return;c!==Qg&&Rg(c)}a.callbackExpirationTime=b;a.callbackPriority=d;b=1073741823===b?Og(Te.bind(null,a)):Ng(d,Lh.bind(null,a),{timeout:10*(1073741821-b)-Y()});a.callbackNode=b}}}function Lh(a,b){dd=0;if(b)return b=ka(),Ue(a,b),V(a),null;var c=fd(a);if(0!==c){b=a.callbackNode;if((p&(ca|ma))!==H)throw Error(k(327));
xb();a===U&&c===P||$a(a,c);if(null!==t){var d=p;p|=ca;var e=Mh();do try{rj();break}catch(h){Nh(a,h)}while(1);le();p=d;gd.current=e;if(F===hd)throw b=id,$a(a,c),Ya(a,c),V(a),b;if(null===t)switch(e=a.finishedWork=a.current.alternate,a.finishedExpirationTime=c,d=F,U=null,d){case Xa:case hd:throw Error(k(345));case Oh:Ue(a,2<c?2:c);break;case ad:Ya(a,c);d=a.lastSuspendedTime;c===d&&(a.nextKnownPendingLevel=Ve(e));if(1073741823===ta&&(e=Re+Ph-Y(),10<e)){if(jd){var f=a.lastPingedTime;if(0===f||f>=c){a.lastPingedTime=
c;$a(a,c);break}}f=fd(a);if(0!==f&&f!==c)break;if(0!==d&&d!==c){a.lastPingedTime=d;break}a.timeoutHandle=We(ab.bind(null,a),e);break}ab(a);break;case bd:Ya(a,c);d=a.lastSuspendedTime;c===d&&(a.nextKnownPendingLevel=Ve(e));if(jd&&(e=a.lastPingedTime,0===e||e>=c)){a.lastPingedTime=c;$a(a,c);break}e=fd(a);if(0!==e&&e!==c)break;if(0!==d&&d!==c){a.lastPingedTime=d;break}1073741823!==Yb?d=10*(1073741821-Yb)-Y():1073741823===ta?d=0:(d=10*(1073741821-ta)-5E3,e=Y(),c=10*(1073741821-c)-e,d=e-d,0>d&&(d=0),d=
(120>d?120:480>d?480:1080>d?1080:1920>d?1920:3E3>d?3E3:4320>d?4320:1960*sj(d/1960))-d,c<d&&(d=c));if(10<d){a.timeoutHandle=We(ab.bind(null,a),d);break}ab(a);break;case Xe:if(1073741823!==ta&&null!==kd){f=ta;var g=kd;d=g.busyMinDurationMs|0;0>=d?d=0:(e=g.busyDelayMs|0,f=Y()-(10*(1073741821-f)-(g.timeoutMs|0||5E3)),d=f<=e?0:e+d-f);if(10<d){Ya(a,c);a.timeoutHandle=We(ab.bind(null,a),d);break}}ab(a);break;default:throw Error(k(329));}V(a);if(a.callbackNode===b)return Lh.bind(null,a)}}return null}function Te(a){var b=
a.lastExpiredTime;b=0!==b?b:1073741823;if((p&(ca|ma))!==H)throw Error(k(327));xb();a===U&&b===P||$a(a,b);if(null!==t){var c=p;p|=ca;var d=Mh();do try{tj();break}catch(e){Nh(a,e)}while(1);le();p=c;gd.current=d;if(F===hd)throw c=id,$a(a,b),Ya(a,b),V(a),c;if(null!==t)throw Error(k(261));a.finishedWork=a.current.alternate;a.finishedExpirationTime=b;U=null;ab(a);V(a)}return null}function uj(){if(null!==bb){var a=bb;bb=null;a.forEach(function(a,c){Ue(c,a);V(c)});ha()}}function Qh(a,b){var c=p;p|=1;try{return a(b)}finally{p=
c,p===H&&ha()}}function Rh(a,b){var c=p;p&=-2;p|=Ye;try{return a(b)}finally{p=c,p===H&&ha()}}function $a(a,b){a.finishedWork=null;a.finishedExpirationTime=0;var c=a.timeoutHandle;-1!==c&&(a.timeoutHandle=-1,vj(c));if(null!==t)for(c=t.return;null!==c;){var d=c;switch(d.tag){case 1:d=d.type.childContextTypes;null!==d&&void 0!==d&&(q(G),q(B));break;case 3:tb();q(G);q(B);break;case 5:te(d);break;case 4:tb();break;case 13:q(D);break;case 19:q(D);break;case 10:me(d)}c=c.return}U=a;t=Sa(a.current,null);
P=b;F=Xa;id=null;Yb=ta=1073741823;kd=null;Xb=0;jd=!1}function Nh(a,b){do{try{le();Sc.current=Tc;if(Uc)for(var c=z.memoizedState;null!==c;){var d=c.queue;null!==d&&(d.pending=null);c=c.next}Ia=0;J=K=z=null;Uc=!1;if(null===t||null===t.return)return F=hd,id=b,t=null;a:{var e=a,f=t.return,g=t,h=b;b=P;g.effectTag|=2048;g.firstEffect=g.lastEffect=null;if(null!==h&&"object"===typeof h&&"function"===typeof h.then){var m=h;if(0===(g.mode&2)){var n=g.alternate;n?(g.updateQueue=n.updateQueue,g.memoizedState=
n.memoizedState,g.expirationTime=n.expirationTime):(g.updateQueue=null,g.memoizedState=null)}var l=0!==(D.current&1),k=f;do{var p;if(p=13===k.tag){var q=k.memoizedState;if(null!==q)p=null!==q.dehydrated?!0:!1;else{var w=k.memoizedProps;p=void 0===w.fallback?!1:!0!==w.unstable_avoidThisFallback?!0:l?!1:!0}}if(p){var y=k.updateQueue;if(null===y){var r=new Set;r.add(m);k.updateQueue=r}else y.add(m);if(0===(k.mode&2)){k.effectTag|=64;g.effectTag&=-2981;if(1===g.tag)if(null===g.alternate)g.tag=17;else{var O=
Ea(1073741823,null);O.tag=Jc;Fa(g,O)}g.expirationTime=1073741823;break a}h=void 0;g=b;var v=e.pingCache;null===v?(v=e.pingCache=new wj,h=new Set,v.set(m,h)):(h=v.get(m),void 0===h&&(h=new Set,v.set(m,h)));if(!h.has(g)){h.add(g);var x=xj.bind(null,e,m,g);m.then(x,x)}k.effectTag|=4096;k.expirationTime=b;break a}k=k.return}while(null!==k);h=Error((na(g.type)||"A React component")+" suspended while rendering, but no fallback UI was specified.\n\nAdd a <Suspense fallback=...> component higher in the tree to provide a loading indicator or placeholder to display."+
Bd(g))}F!==Xe&&(F=Oh);h=Le(h,g);k=f;do{switch(k.tag){case 3:m=h;k.effectTag|=4096;k.expirationTime=b;var A=Ih(k,m,b);Ug(k,A);break a;case 1:m=h;var u=k.type,B=k.stateNode;if(0===(k.effectTag&64)&&("function"===typeof u.getDerivedStateFromError||null!==B&&"function"===typeof B.componentDidCatch&&(null===La||!La.has(B)))){k.effectTag|=4096;k.expirationTime=b;var H=Jh(k,m,b);Ug(k,H);break a}}k=k.return}while(null!==k)}t=Sh(t)}catch(cj){b=cj;continue}break}while(1)}function Mh(a){a=gd.current;gd.current=
Tc;return null===a?Tc:a}function Vg(a,b){a<ta&&2<a&&(ta=a);null!==b&&a<Yb&&2<a&&(Yb=a,kd=b)}function Kc(a){a>Xb&&(Xb=a)}function tj(){for(;null!==t;)t=Th(t)}function rj(){for(;null!==t&&!yj();)t=Th(t)}function Th(a){var b=zj(a.alternate,a,P);a.memoizedProps=a.pendingProps;null===b&&(b=Sh(a));Uh.current=null;return b}function Sh(a){t=a;do{var b=t.alternate;a=t.return;if(0===(t.effectTag&2048)){b=hj(b,t,P);if(1===P||1!==t.childExpirationTime){for(var c=0,d=t.child;null!==d;){var e=d.expirationTime,
f=d.childExpirationTime;e>c&&(c=e);f>c&&(c=f);d=d.sibling}t.childExpirationTime=c}if(null!==b)return b;null!==a&&0===(a.effectTag&2048)&&(null===a.firstEffect&&(a.firstEffect=t.firstEffect),null!==t.lastEffect&&(null!==a.lastEffect&&(a.lastEffect.nextEffect=t.firstEffect),a.lastEffect=t.lastEffect),1<t.effectTag&&(null!==a.lastEffect?a.lastEffect.nextEffect=t:a.firstEffect=t,a.lastEffect=t))}else{b=lj(t);if(null!==b)return b.effectTag&=2047,b;null!==a&&(a.firstEffect=a.lastEffect=null,a.effectTag|=
2048)}b=t.sibling;if(null!==b)return b;t=a}while(null!==t);F===Xa&&(F=Xe);return null}function Ve(a){var b=a.expirationTime;a=a.childExpirationTime;return b>a?b:a}function ab(a){var b=Cc();Da(99,Aj.bind(null,a,b));return null}function Aj(a,b){do xb();while(null!==Zb);if((p&(ca|ma))!==H)throw Error(k(327));var c=a.finishedWork,d=a.finishedExpirationTime;if(null===c)return null;a.finishedWork=null;a.finishedExpirationTime=0;if(c===a.current)throw Error(k(177));a.callbackNode=null;a.callbackExpirationTime=
0;a.callbackPriority=90;a.nextKnownPendingLevel=0;var e=Ve(c);a.firstPendingTime=e;d<=a.lastSuspendedTime?a.firstSuspendedTime=a.lastSuspendedTime=a.nextKnownPendingLevel=0:d<=a.firstSuspendedTime&&(a.firstSuspendedTime=d-1);d<=a.lastPingedTime&&(a.lastPingedTime=0);d<=a.lastExpiredTime&&(a.lastExpiredTime=0);a===U&&(t=U=null,P=0);1<c.effectTag?null!==c.lastEffect?(c.lastEffect.nextEffect=c,e=c.firstEffect):e=c:e=c.firstEffect;if(null!==e){var f=p;p|=ma;Uh.current=null;Ze=tc;var g=kg();if(Xd(g)){if("selectionStart"in
g)var h={start:g.selectionStart,end:g.selectionEnd};else a:{h=(h=g.ownerDocument)&&h.defaultView||window;var m=h.getSelection&&h.getSelection();if(m&&0!==m.rangeCount){h=m.anchorNode;var n=m.anchorOffset,q=m.focusNode;m=m.focusOffset;try{h.nodeType,q.nodeType}catch(sb){h=null;break a}var ba=0,w=-1,y=-1,B=0,D=0,r=g,z=null;b:for(;;){for(var v;;){r!==h||0!==n&&3!==r.nodeType||(w=ba+n);r!==q||0!==m&&3!==r.nodeType||(y=ba+m);3===r.nodeType&&(ba+=r.nodeValue.length);if(null===(v=r.firstChild))break;z=r;
r=v}for(;;){if(r===g)break b;z===h&&++B===n&&(w=ba);z===q&&++D===m&&(y=ba);if(null!==(v=r.nextSibling))break;r=z;z=r.parentNode}r=v}h=-1===w||-1===y?null:{start:w,end:y}}else h=null}h=h||{start:0,end:0}}else h=null;$e={activeElementDetached:null,focusedElem:g,selectionRange:h};tc=!1;l=e;do try{Bj()}catch(sb){if(null===l)throw Error(k(330));Za(l,sb);l=l.nextEffect}while(null!==l);l=e;do try{for(g=a,h=b;null!==l;){var x=l.effectTag;x&16&&Wb(l.stateNode,"");if(x&128){var A=l.alternate;if(null!==A){var u=
A.ref;null!==u&&("function"===typeof u?u(null):u.current=null)}}switch(x&1038){case 2:Gh(l);l.effectTag&=-3;break;case 6:Gh(l);l.effectTag&=-3;Qe(l.alternate,l);break;case 1024:l.effectTag&=-1025;break;case 1028:l.effectTag&=-1025;Qe(l.alternate,l);break;case 4:Qe(l.alternate,l);break;case 8:n=l,Dh(g,n,h),Eh(n)}l=l.nextEffect}}catch(sb){if(null===l)throw Error(k(330));Za(l,sb);l=l.nextEffect}while(null!==l);u=$e;A=kg();x=u.focusedElem;h=u.selectionRange;if(A!==x&&x&&x.ownerDocument&&jg(x.ownerDocument.documentElement,
x)){null!==h&&Xd(x)&&(A=h.start,u=h.end,void 0===u&&(u=A),"selectionStart"in x?(x.selectionStart=A,x.selectionEnd=Math.min(u,x.value.length)):(u=(A=x.ownerDocument||document)&&A.defaultView||window,u.getSelection&&(u=u.getSelection(),n=x.textContent.length,g=Math.min(h.start,n),h=void 0===h.end?g:Math.min(h.end,n),!u.extend&&g>h&&(n=h,h=g,g=n),n=ig(x,g),q=ig(x,h),n&&q&&(1!==u.rangeCount||u.anchorNode!==n.node||u.anchorOffset!==n.offset||u.focusNode!==q.node||u.focusOffset!==q.offset)&&(A=A.createRange(),
A.setStart(n.node,n.offset),u.removeAllRanges(),g>h?(u.addRange(A),u.extend(q.node,q.offset)):(A.setEnd(q.node,q.offset),u.addRange(A))))));A=[];for(u=x;u=u.parentNode;)1===u.nodeType&&A.push({element:u,left:u.scrollLeft,top:u.scrollTop});"function"===typeof x.focus&&x.focus();for(x=0;x<A.length;x++)u=A[x],u.element.scrollLeft=u.left,u.element.scrollTop=u.top}tc=!!Ze;$e=Ze=null;a.current=c;l=e;do try{for(x=a;null!==l;){var F=l.effectTag;F&36&&oj(x,l.alternate,l);if(F&128){A=void 0;var E=l.ref;if(null!==
E){var G=l.stateNode;switch(l.tag){case 5:A=G;break;default:A=G}"function"===typeof E?E(A):E.current=A}}l=l.nextEffect}}catch(sb){if(null===l)throw Error(k(330));Za(l,sb);l=l.nextEffect}while(null!==l);l=null;Cj();p=f}else a.current=c;if(ld)ld=!1,Zb=a,$b=b;else for(l=e;null!==l;)b=l.nextEffect,l.nextEffect=null,l=b;b=a.firstPendingTime;0===b&&(La=null);1073741823===b?a===af?ac++:(ac=0,af=a):ac=0;"function"===typeof bf&&bf(c.stateNode,d);V(a);if(cd)throw cd=!1,a=Se,Se=null,a;if((p&Ye)!==H)return null;
ha();return null}function Bj(){for(;null!==l;){var a=l.effectTag;0!==(a&256)&&nj(l.alternate,l);0===(a&512)||ld||(ld=!0,Ng(97,function(){xb();return null}));l=l.nextEffect}}function xb(){if(90!==$b){var a=97<$b?97:$b;$b=90;return Da(a,Dj)}}function Dj(){if(null===Zb)return!1;var a=Zb;Zb=null;if((p&(ca|ma))!==H)throw Error(k(331));var b=p;p|=ma;for(a=a.current.firstEffect;null!==a;){try{var c=a;if(0!==(c.effectTag&512))switch(c.tag){case 0:case 11:case 15:case 22:Ah(5,c),Bh(5,c)}}catch(d){if(null===
a)throw Error(k(330));Za(a,d)}c=a.nextEffect;a.nextEffect=null;a=c}p=b;ha();return!0}function Vh(a,b,c){b=Le(c,b);b=Ih(a,b,1073741823);Fa(a,b);a=ed(a,1073741823);null!==a&&V(a)}function Za(a,b){if(3===a.tag)Vh(a,a,b);else for(var c=a.return;null!==c;){if(3===c.tag){Vh(c,a,b);break}else if(1===c.tag){var d=c.stateNode;if("function"===typeof c.type.getDerivedStateFromError||"function"===typeof d.componentDidCatch&&(null===La||!La.has(d))){a=Le(b,a);a=Jh(c,a,1073741823);Fa(c,a);c=ed(c,1073741823);null!==
c&&V(c);break}}c=c.return}}function xj(a,b,c){var d=a.pingCache;null!==d&&d.delete(b);U===a&&P===c?F===bd||F===ad&&1073741823===ta&&Y()-Re<Ph?$a(a,P):jd=!0:Kh(a,c)&&(b=a.lastPingedTime,0!==b&&b<c||(a.lastPingedTime=c,V(a)))}function qj(a,b){var c=a.stateNode;null!==c&&c.delete(b);b=0;0===b&&(b=ka(),b=Va(b,a,null));a=ed(a,b);null!==a&&V(a)}function Ej(a){if("undefined"===typeof __REACT_DEVTOOLS_GLOBAL_HOOK__)return!1;var b=__REACT_DEVTOOLS_GLOBAL_HOOK__;if(b.isDisabled||!b.supportsFiber)return!0;try{var c=
b.inject(a);bf=function(a,e){try{b.onCommitFiberRoot(c,a,void 0,64===(a.current.effectTag&64))}catch(f){}};Ne=function(a){try{b.onCommitFiberUnmount(c,a)}catch(e){}}}catch(d){}return!0}function Fj(a,b,c,d){this.tag=a;this.key=c;this.sibling=this.child=this.return=this.stateNode=this.type=this.elementType=null;this.index=0;this.ref=null;this.pendingProps=b;this.dependencies=this.memoizedState=this.updateQueue=this.memoizedProps=null;this.mode=d;this.effectTag=0;this.lastEffect=this.firstEffect=this.nextEffect=
null;this.childExpirationTime=this.expirationTime=0;this.alternate=null}function Ge(a){a=a.prototype;return!(!a||!a.isReactComponent)}function Gj(a){if("function"===typeof a)return Ge(a)?1:0;if(void 0!==a&&null!==a){a=a.$$typeof;if(a===zd)return 11;if(a===Ad)return 14}return 2}function Sa(a,b){var c=a.alternate;null===c?(c=la(a.tag,b,a.key,a.mode),c.elementType=a.elementType,c.type=a.type,c.stateNode=a.stateNode,c.alternate=a,a.alternate=c):(c.pendingProps=b,c.effectTag=0,c.nextEffect=null,c.firstEffect=
null,c.lastEffect=null);c.childExpirationTime=a.childExpirationTime;c.expirationTime=a.expirationTime;c.child=a.child;c.memoizedProps=a.memoizedProps;c.memoizedState=a.memoizedState;c.updateQueue=a.updateQueue;b=a.dependencies;c.dependencies=null===b?null:{expirationTime:b.expirationTime,firstContext:b.firstContext,responders:b.responders};c.sibling=a.sibling;c.index=a.index;c.ref=a.ref;return c}function Oc(a,b,c,d,e,f){var g=2;d=a;if("function"===typeof a)Ge(a)&&(g=1);else if("string"===typeof a)g=
5;else a:switch(a){case Ma:return Ha(c.children,e,f,b);case Hj:g=8;e|=7;break;case Af:g=8;e|=1;break;case kc:return a=la(12,c,b,e|8),a.elementType=kc,a.type=kc,a.expirationTime=f,a;case lc:return a=la(13,c,b,e),a.type=lc,a.elementType=lc,a.expirationTime=f,a;case yd:return a=la(19,c,b,e),a.elementType=yd,a.expirationTime=f,a;default:if("object"===typeof a&&null!==a)switch(a.$$typeof){case Cf:g=10;break a;case Bf:g=9;break a;case zd:g=11;break a;case Ad:g=14;break a;case Ef:g=16;d=null;break a;case Df:g=
22;break a}throw Error(k(130,null==a?a:typeof a,""));}b=la(g,c,b,e);b.elementType=a;b.type=d;b.expirationTime=f;return b}function Ha(a,b,c,d){a=la(7,a,d,b);a.expirationTime=c;return a}function qe(a,b,c){a=la(6,a,null,b);a.expirationTime=c;return a}function re(a,b,c){b=la(4,null!==a.children?a.children:[],a.key,b);b.expirationTime=c;b.stateNode={containerInfo:a.containerInfo,pendingChildren:null,implementation:a.implementation};return b}function Ij(a,b,c){this.tag=b;this.current=null;this.containerInfo=
a;this.pingCache=this.pendingChildren=null;this.finishedExpirationTime=0;this.finishedWork=null;this.timeoutHandle=-1;this.pendingContext=this.context=null;this.hydrate=c;this.callbackNode=null;this.callbackPriority=90;this.lastExpiredTime=this.lastPingedTime=this.nextKnownPendingLevel=this.lastSuspendedTime=this.firstSuspendedTime=this.firstPendingTime=0}function Kh(a,b){var c=a.firstSuspendedTime;a=a.lastSuspendedTime;return 0!==c&&c>=b&&a<=b}function Ya(a,b){var c=a.firstSuspendedTime,d=a.lastSuspendedTime;
c<b&&(a.firstSuspendedTime=b);if(d>b||0===c)a.lastSuspendedTime=b;b<=a.lastPingedTime&&(a.lastPingedTime=0);b<=a.lastExpiredTime&&(a.lastExpiredTime=0)}function yh(a,b){b>a.firstPendingTime&&(a.firstPendingTime=b);var c=a.firstSuspendedTime;0!==c&&(b>=c?a.firstSuspendedTime=a.lastSuspendedTime=a.nextKnownPendingLevel=0:b>=a.lastSuspendedTime&&(a.lastSuspendedTime=b+1),b>a.nextKnownPendingLevel&&(a.nextKnownPendingLevel=b))}function Ue(a,b){var c=a.lastExpiredTime;if(0===c||c>b)a.lastExpiredTime=b}
function md(a,b,c,d){var e=b.current,f=ka(),g=Vb.suspense;f=Va(f,e,g);a:if(c){c=c._reactInternalFiber;b:{if(Na(c)!==c||1!==c.tag)throw Error(k(170));var h=c;do{switch(h.tag){case 3:h=h.stateNode.context;break b;case 1:if(N(h.type)){h=h.stateNode.__reactInternalMemoizedMergedChildContext;break b}}h=h.return}while(null!==h);throw Error(k(171));}if(1===c.tag){var m=c.type;if(N(m)){c=Gg(c,m,h);break a}}c=h}else c=Ca;null===b.context?b.context=c:b.pendingContext=c;b=Ea(f,g);b.payload={element:a};d=void 0===
d?null:d;null!==d&&(b.callback=d);Fa(e,b);Ja(e,f);return f}function cf(a){a=a.current;if(!a.child)return null;switch(a.child.tag){case 5:return a.child.stateNode;default:return a.child.stateNode}}function Wh(a,b){a=a.memoizedState;null!==a&&null!==a.dehydrated&&a.retryTime<b&&(a.retryTime=b)}function df(a,b){Wh(a,b);(a=a.alternate)&&Wh(a,b)}function ef(a,b,c){c=null!=c&&!0===c.hydrate;var d=new Ij(a,b,c),e=la(3,null,null,2===b?7:1===b?3:0);d.current=e;e.stateNode=d;ne(e);a[Lb]=d.current;c&&0!==b&&
xi(a,9===a.nodeType?a:a.ownerDocument);this._internalRoot=d}function bc(a){return!(!a||1!==a.nodeType&&9!==a.nodeType&&11!==a.nodeType&&(8!==a.nodeType||" react-mount-point-unstable "!==a.nodeValue))}function Jj(a,b){b||(b=a?9===a.nodeType?a.documentElement:a.firstChild:null,b=!(!b||1!==b.nodeType||!b.hasAttribute("data-reactroot")));if(!b)for(var c;c=a.lastChild;)a.removeChild(c);return new ef(a,0,b?{hydrate:!0}:void 0)}function nd(a,b,c,d,e){var f=c._reactRootContainer;if(f){var g=f._internalRoot;
if("function"===typeof e){var h=e;e=function(){var a=cf(g);h.call(a)}}md(b,g,a,e)}else{f=c._reactRootContainer=Jj(c,d);g=f._internalRoot;if("function"===typeof e){var m=e;e=function(){var a=cf(g);m.call(a)}}Rh(function(){md(b,g,a,e)})}return cf(g)}function Kj(a,b,c){var d=3<arguments.length&&void 0!==arguments[3]?arguments[3]:null;return{$$typeof:gb,key:null==d?null:""+d,children:a,containerInfo:b,implementation:c}}function Xh(a,b){var c=2<arguments.length&&void 0!==arguments[2]?arguments[2]:null;
if(!bc(b))throw Error(k(200));return Kj(a,b,null,c)}if(!ea)throw Error(k(227));var ki=function(a,b,c,d,e,f,g,h,m){var n=Array.prototype.slice.call(arguments,3);try{b.apply(c,n)}catch(C){this.onError(C)}},yb=!1,gc=null,hc=!1,pd=null,li={onError:function(a){yb=!0;gc=a}},td=null,rf=null,mf=null,ic=null,cb={},jc=[],qd={},db={},rd={},wa=!("undefined"===typeof window||"undefined"===typeof window.document||"undefined"===typeof window.document.createElement),M=ea.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED.assign,
sd=null,eb=null,fb=null,ee=function(a,b){return a(b)},eg=function(a,b,c,d,e){return a(b,c,d,e)},vd=function(){},vf=ee,Oa=!1,wd=!1,Z=ea.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED.Scheduler,Lj=Z.unstable_cancelCallback,ff=Z.unstable_now,$f=Z.unstable_scheduleCallback,Mj=Z.unstable_shouldYield,Yh=Z.unstable_requestPaint,Pd=Z.unstable_runWithPriority,Nj=Z.unstable_getCurrentPriorityLevel,Oj=Z.unstable_ImmediatePriority,Zh=Z.unstable_UserBlockingPriority,ag=Z.unstable_NormalPriority,Pj=Z.unstable_LowPriority,
Qj=Z.unstable_IdlePriority,oi=/^[:A-Z_a-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD][:A-Z_a-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD\-.0-9\u00B7\u0300-\u036F\u203F-\u2040]*$/,wf=Object.prototype.hasOwnProperty,yf={},xf={},E={};"children dangerouslySetInnerHTML defaultValue defaultChecked innerHTML suppressContentEditableWarning suppressHydrationWarning style".split(" ").forEach(function(a){E[a]=
new L(a,0,!1,a,null,!1)});[["acceptCharset","accept-charset"],["className","class"],["htmlFor","for"],["httpEquiv","http-equiv"]].forEach(function(a){var b=a[0];E[b]=new L(b,1,!1,a[1],null,!1)});["contentEditable","draggable","spellCheck","value"].forEach(function(a){E[a]=new L(a,2,!1,a.toLowerCase(),null,!1)});["autoReverse","externalResourcesRequired","focusable","preserveAlpha"].forEach(function(a){E[a]=new L(a,2,!1,a,null,!1)});"allowFullScreen async autoFocus autoPlay controls default defer disabled disablePictureInPicture formNoValidate hidden loop noModule noValidate open playsInline readOnly required reversed scoped seamless itemScope".split(" ").forEach(function(a){E[a]=
new L(a,3,!1,a.toLowerCase(),null,!1)});["checked","multiple","muted","selected"].forEach(function(a){E[a]=new L(a,3,!0,a,null,!1)});["capture","download"].forEach(function(a){E[a]=new L(a,4,!1,a,null,!1)});["cols","rows","size","span"].forEach(function(a){E[a]=new L(a,6,!1,a,null,!1)});["rowSpan","start"].forEach(function(a){E[a]=new L(a,5,!1,a.toLowerCase(),null,!1)});var gf=/[\-:]([a-z])/g,hf=function(a){return a[1].toUpperCase()};"accent-height alignment-baseline arabic-form baseline-shift cap-height clip-path clip-rule color-interpolation color-interpolation-filters color-profile color-rendering dominant-baseline enable-background fill-opacity fill-rule flood-color flood-opacity font-family font-size font-size-adjust font-stretch font-style font-variant font-weight glyph-name glyph-orientation-horizontal glyph-orientation-vertical horiz-adv-x horiz-origin-x image-rendering letter-spacing lighting-color marker-end marker-mid marker-start overline-position overline-thickness paint-order panose-1 pointer-events rendering-intent shape-rendering stop-color stop-opacity strikethrough-position strikethrough-thickness stroke-dasharray stroke-dashoffset stroke-linecap stroke-linejoin stroke-miterlimit stroke-opacity stroke-width text-anchor text-decoration text-rendering underline-position underline-thickness unicode-bidi unicode-range units-per-em v-alphabetic v-hanging v-ideographic v-mathematical vector-effect vert-adv-y vert-origin-x vert-origin-y word-spacing writing-mode xmlns:xlink x-height".split(" ").forEach(function(a){var b=
a.replace(gf,hf);E[b]=new L(b,1,!1,a,null,!1)});"xlink:actuate xlink:arcrole xlink:role xlink:show xlink:title xlink:type".split(" ").forEach(function(a){var b=a.replace(gf,hf);E[b]=new L(b,1,!1,a,"http://www.w3.org/1999/xlink",!1)});["xml:base","xml:lang","xml:space"].forEach(function(a){var b=a.replace(gf,hf);E[b]=new L(b,1,!1,a,"http://www.w3.org/XML/1998/namespace",!1)});["tabIndex","crossOrigin"].forEach(function(a){E[a]=new L(a,1,!1,a.toLowerCase(),null,!1)});E.xlinkHref=new L("xlinkHref",1,
!1,"xlink:href","http://www.w3.org/1999/xlink",!0);["src","href","action","formAction"].forEach(function(a){E[a]=new L(a,1,!1,a.toLowerCase(),null,!0)});var da=ea.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED;da.hasOwnProperty("ReactCurrentDispatcher")||(da.ReactCurrentDispatcher={current:null});da.hasOwnProperty("ReactCurrentBatchConfig")||(da.ReactCurrentBatchConfig={suspense:null});var si=/^(.*)[\\\/]/,Q="function"===typeof Symbol&&Symbol.for,Pc=Q?Symbol.for("react.element"):60103,gb=Q?Symbol.for("react.portal"):
60106,Ma=Q?Symbol.for("react.fragment"):60107,Af=Q?Symbol.for("react.strict_mode"):60108,kc=Q?Symbol.for("react.profiler"):60114,Cf=Q?Symbol.for("react.provider"):60109,Bf=Q?Symbol.for("react.context"):60110,Hj=Q?Symbol.for("react.concurrent_mode"):60111,zd=Q?Symbol.for("react.forward_ref"):60112,lc=Q?Symbol.for("react.suspense"):60113,yd=Q?Symbol.for("react.suspense_list"):60120,Ad=Q?Symbol.for("react.memo"):60115,Ef=Q?Symbol.for("react.lazy"):60116,Df=Q?Symbol.for("react.block"):60121,zf="function"===
typeof Symbol&&Symbol.iterator,od,xh=function(a){return"undefined"!==typeof MSApp&&MSApp.execUnsafeLocalFunction?function(b,c,d,e){MSApp.execUnsafeLocalFunction(function(){return a(b,c,d,e)})}:a}(function(a,b){if("http://www.w3.org/2000/svg"!==a.namespaceURI||"innerHTML"in a)a.innerHTML=b;else{od=od||document.createElement("div");od.innerHTML="<svg>"+b.valueOf().toString()+"</svg>";for(b=od.firstChild;a.firstChild;)a.removeChild(a.firstChild);for(;b.firstChild;)a.appendChild(b.firstChild)}}),Wb=function(a,
b){if(b){var c=a.firstChild;if(c&&c===a.lastChild&&3===c.nodeType){c.nodeValue=b;return}}a.textContent=b},ib={animationend:nc("Animation","AnimationEnd"),animationiteration:nc("Animation","AnimationIteration"),animationstart:nc("Animation","AnimationStart"),transitionend:nc("Transition","TransitionEnd")},Id={},Of={};wa&&(Of=document.createElement("div").style,"AnimationEvent"in window||(delete ib.animationend.animation,delete ib.animationiteration.animation,delete ib.animationstart.animation),"TransitionEvent"in
window||delete ib.transitionend.transition);var $h=oc("animationend"),ai=oc("animationiteration"),bi=oc("animationstart"),ci=oc("transitionend"),Db="abort canplay canplaythrough durationchange emptied encrypted ended error loadeddata loadedmetadata loadstart pause play playing progress ratechange seeked seeking stalled suspend timeupdate volumechange waiting".split(" "),Pf=new ("function"===typeof WeakMap?WeakMap:Map),Ab=null,wi=function(a){if(a){var b=a._dispatchListeners,c=a._dispatchInstances;
if(Array.isArray(b))for(var d=0;d<b.length&&!a.isPropagationStopped();d++)lf(a,b[d],c[d]);else b&&lf(a,b,c);a._dispatchListeners=null;a._dispatchInstances=null;a.isPersistent()||a.constructor.release(a)}},qc=[],Rd=!1,fa=[],xa=null,ya=null,za=null,Eb=new Map,Fb=new Map,Jb=[],Nd="mousedown mouseup touchcancel touchend touchstart auxclick dblclick pointercancel pointerdown pointerup dragend dragstart drop compositionend compositionstart keydown keypress keyup input textInput close cancel copy cut paste click change contextmenu reset submit".split(" "),
yi="focus blur dragenter dragleave mouseover mouseout pointerover pointerout gotpointercapture lostpointercapture".split(" "),dg={},cg=new Map,Td=new Map,Rj=["abort","abort",$h,"animationEnd",ai,"animationIteration",bi,"animationStart","canplay","canPlay","canplaythrough","canPlayThrough","durationchange","durationChange","emptied","emptied","encrypted","encrypted","ended","ended","error","error","gotpointercapture","gotPointerCapture","load","load","loadeddata","loadedData","loadedmetadata","loadedMetadata",
"loadstart","loadStart","lostpointercapture","lostPointerCapture","playing","playing","progress","progress","seeking","seeking","stalled","stalled","suspend","suspend","timeupdate","timeUpdate",ci,"transitionEnd","waiting","waiting"];Sd("blur blur cancel cancel click click close close contextmenu contextMenu copy copy cut cut auxclick auxClick dblclick doubleClick dragend dragEnd dragstart dragStart drop drop focus focus input input invalid invalid keydown keyDown keypress keyPress keyup keyUp mousedown mouseDown mouseup mouseUp paste paste pause pause play play pointercancel pointerCancel pointerdown pointerDown pointerup pointerUp ratechange rateChange reset reset seeked seeked submit submit touchcancel touchCancel touchend touchEnd touchstart touchStart volumechange volumeChange".split(" "),
0);Sd("drag drag dragenter dragEnter dragexit dragExit dragleave dragLeave dragover dragOver mousemove mouseMove mouseout mouseOut mouseover mouseOver pointermove pointerMove pointerout pointerOut pointerover pointerOver scroll scroll toggle toggle touchmove touchMove wheel wheel".split(" "),1);Sd(Rj,2);(function(a,b){for(var c=0;c<a.length;c++)Td.set(a[c],b)})("change selectionchange textInput compositionstart compositionend compositionupdate".split(" "),0);var Hi=Zh,Gi=Pd,tc=!0,Kb={animationIterationCount:!0,
borderImageOutset:!0,borderImageSlice:!0,borderImageWidth:!0,boxFlex:!0,boxFlexGroup:!0,boxOrdinalGroup:!0,columnCount:!0,columns:!0,flex:!0,flexGrow:!0,flexPositive:!0,flexShrink:!0,flexNegative:!0,flexOrder:!0,gridArea:!0,gridRow:!0,gridRowEnd:!0,gridRowSpan:!0,gridRowStart:!0,gridColumn:!0,gridColumnEnd:!0,gridColumnSpan:!0,gridColumnStart:!0,fontWeight:!0,lineClamp:!0,lineHeight:!0,opacity:!0,order:!0,orphans:!0,tabSize:!0,widows:!0,zIndex:!0,zoom:!0,fillOpacity:!0,floodOpacity:!0,stopOpacity:!0,
strokeDasharray:!0,strokeDashoffset:!0,strokeMiterlimit:!0,strokeOpacity:!0,strokeWidth:!0},Sj=["Webkit","ms","Moz","O"];Object.keys(Kb).forEach(function(a){Sj.forEach(function(b){b=b+a.charAt(0).toUpperCase()+a.substring(1);Kb[b]=Kb[a]})});var Ii=M({menuitem:!0},{area:!0,base:!0,br:!0,col:!0,embed:!0,hr:!0,img:!0,input:!0,keygen:!0,link:!0,meta:!0,param:!0,source:!0,track:!0,wbr:!0}),ng="$",og="/$",$d="$?",Zd="$!",Ze=null,$e=null,We="function"===typeof setTimeout?setTimeout:void 0,vj="function"===
typeof clearTimeout?clearTimeout:void 0,jf=Math.random().toString(36).slice(2),Aa="__reactInternalInstance$"+jf,vc="__reactEventHandlers$"+jf,Lb="__reactContainere$"+jf,Ba=null,ce=null,wc=null;M(R.prototype,{preventDefault:function(){this.defaultPrevented=!0;var a=this.nativeEvent;a&&(a.preventDefault?a.preventDefault():"unknown"!==typeof a.returnValue&&(a.returnValue=!1),this.isDefaultPrevented=xc)},stopPropagation:function(){var a=this.nativeEvent;a&&(a.stopPropagation?a.stopPropagation():"unknown"!==
typeof a.cancelBubble&&(a.cancelBubble=!0),this.isPropagationStopped=xc)},persist:function(){this.isPersistent=xc},isPersistent:yc,destructor:function(){var a=this.constructor.Interface,b;for(b in a)this[b]=null;this.nativeEvent=this._targetInst=this.dispatchConfig=null;this.isPropagationStopped=this.isDefaultPrevented=yc;this._dispatchInstances=this._dispatchListeners=null}});R.Interface={type:null,target:null,currentTarget:function(){return null},eventPhase:null,bubbles:null,cancelable:null,timeStamp:function(a){return a.timeStamp||
Date.now()},defaultPrevented:null,isTrusted:null};R.extend=function(a){function b(){return c.apply(this,arguments)}var c=this,d=function(){};d.prototype=c.prototype;d=new d;M(d,b.prototype);b.prototype=d;b.prototype.constructor=b;b.Interface=M({},c.Interface,a);b.extend=c.extend;sg(b);return b};sg(R);var Tj=R.extend({data:null}),Uj=R.extend({data:null}),Ni=[9,13,27,32],de=wa&&"CompositionEvent"in window,cc=null;wa&&"documentMode"in document&&(cc=document.documentMode);var Vj=wa&&"TextEvent"in window&&
!cc,xg=wa&&(!de||cc&&8<cc&&11>=cc),wg=String.fromCharCode(32),ua={beforeInput:{phasedRegistrationNames:{bubbled:"onBeforeInput",captured:"onBeforeInputCapture"},dependencies:["compositionend","keypress","textInput","paste"]},compositionEnd:{phasedRegistrationNames:{bubbled:"onCompositionEnd",captured:"onCompositionEndCapture"},dependencies:"blur compositionend keydown keypress keyup mousedown".split(" ")},compositionStart:{phasedRegistrationNames:{bubbled:"onCompositionStart",captured:"onCompositionStartCapture"},
dependencies:"blur compositionstart keydown keypress keyup mousedown".split(" ")},compositionUpdate:{phasedRegistrationNames:{bubbled:"onCompositionUpdate",captured:"onCompositionUpdateCapture"},dependencies:"blur compositionupdate keydown keypress keyup mousedown".split(" ")}},vg=!1,mb=!1,Wj={eventTypes:ua,extractEvents:function(a,b,c,d,e){var f;if(de)b:{switch(a){case "compositionstart":var g=ua.compositionStart;break b;case "compositionend":g=ua.compositionEnd;break b;case "compositionupdate":g=
ua.compositionUpdate;break b}g=void 0}else mb?tg(a,c)&&(g=ua.compositionEnd):"keydown"===a&&229===c.keyCode&&(g=ua.compositionStart);g?(xg&&"ko"!==c.locale&&(mb||g!==ua.compositionStart?g===ua.compositionEnd&&mb&&(f=rg()):(Ba=d,ce="value"in Ba?Ba.value:Ba.textContent,mb=!0)),e=Tj.getPooled(g,b,c,d),f?e.data=f:(f=ug(c),null!==f&&(e.data=f)),lb(e),f=e):f=null;(a=Vj?Oi(a,c):Pi(a,c))?(b=Uj.getPooled(ua.beforeInput,b,c,d),b.data=a,lb(b)):b=null;return null===f?b:null===b?f:[f,b]}},Qi={color:!0,date:!0,
datetime:!0,"datetime-local":!0,email:!0,month:!0,number:!0,password:!0,range:!0,search:!0,tel:!0,text:!0,time:!0,url:!0,week:!0},Ag={change:{phasedRegistrationNames:{bubbled:"onChange",captured:"onChangeCapture"},dependencies:"blur change click focus input keydown keyup selectionchange".split(" ")}},Mb=null,Nb=null,kf=!1;wa&&(kf=Tf("input")&&(!document.documentMode||9<document.documentMode));var Xj={eventTypes:Ag,_isInputEventSupported:kf,extractEvents:function(a,b,c,d,e){e=b?Pa(b):window;var f=
e.nodeName&&e.nodeName.toLowerCase();if("select"===f||"input"===f&&"file"===e.type)var g=Si;else if(yg(e))if(kf)g=Wi;else{g=Ui;var h=Ti}else(f=e.nodeName)&&"input"===f.toLowerCase()&&("checkbox"===e.type||"radio"===e.type)&&(g=Vi);if(g&&(g=g(a,b)))return zg(g,c,d);h&&h(a,e,b);"blur"===a&&(a=e._wrapperState)&&a.controlled&&"number"===e.type&&Ed(e,"number",e.value)}},dc=R.extend({view:null,detail:null}),Yi={Alt:"altKey",Control:"ctrlKey",Meta:"metaKey",Shift:"shiftKey"},di=0,ei=0,fi=!1,gi=!1,ec=dc.extend({screenX:null,
screenY:null,clientX:null,clientY:null,pageX:null,pageY:null,ctrlKey:null,shiftKey:null,altKey:null,metaKey:null,getModifierState:fe,button:null,buttons:null,relatedTarget:function(a){return a.relatedTarget||(a.fromElement===a.srcElement?a.toElement:a.fromElement)},movementX:function(a){if("movementX"in a)return a.movementX;var b=di;di=a.screenX;return fi?"mousemove"===a.type?a.screenX-b:0:(fi=!0,0)},movementY:function(a){if("movementY"in a)return a.movementY;var b=ei;ei=a.screenY;return gi?"mousemove"===
a.type?a.screenY-b:0:(gi=!0,0)}}),hi=ec.extend({pointerId:null,width:null,height:null,pressure:null,tangentialPressure:null,tiltX:null,tiltY:null,twist:null,pointerType:null,isPrimary:null}),fc={mouseEnter:{registrationName:"onMouseEnter",dependencies:["mouseout","mouseover"]},mouseLeave:{registrationName:"onMouseLeave",dependencies:["mouseout","mouseover"]},pointerEnter:{registrationName:"onPointerEnter",dependencies:["pointerout","pointerover"]},pointerLeave:{registrationName:"onPointerLeave",dependencies:["pointerout",
"pointerover"]}},Yj={eventTypes:fc,extractEvents:function(a,b,c,d,e){var f="mouseover"===a||"pointerover"===a,g="mouseout"===a||"pointerout"===a;if(f&&0===(e&32)&&(c.relatedTarget||c.fromElement)||!g&&!f)return null;f=d.window===d?d:(f=d.ownerDocument)?f.defaultView||f.parentWindow:window;if(g){if(g=b,b=(b=c.relatedTarget||c.toElement)?Bb(b):null,null!==b){var h=Na(b);if(b!==h||5!==b.tag&&6!==b.tag)b=null}}else g=null;if(g===b)return null;if("mouseout"===a||"mouseover"===a){var m=ec;var n=fc.mouseLeave;
var l=fc.mouseEnter;var k="mouse"}else if("pointerout"===a||"pointerover"===a)m=hi,n=fc.pointerLeave,l=fc.pointerEnter,k="pointer";a=null==g?f:Pa(g);f=null==b?f:Pa(b);n=m.getPooled(n,g,c,d);n.type=k+"leave";n.target=a;n.relatedTarget=f;c=m.getPooled(l,b,c,d);c.type=k+"enter";c.target=f;c.relatedTarget=a;d=g;k=b;if(d&&k)a:{m=d;l=k;g=0;for(a=m;a;a=pa(a))g++;a=0;for(b=l;b;b=pa(b))a++;for(;0<g-a;)m=pa(m),g--;for(;0<a-g;)l=pa(l),a--;for(;g--;){if(m===l||m===l.alternate)break a;m=pa(m);l=pa(l)}m=null}else m=
null;l=m;for(m=[];d&&d!==l;){g=d.alternate;if(null!==g&&g===l)break;m.push(d);d=pa(d)}for(d=[];k&&k!==l;){g=k.alternate;if(null!==g&&g===l)break;d.push(k);k=pa(k)}for(k=0;k<m.length;k++)be(m[k],"bubbled",n);for(k=d.length;0<k--;)be(d[k],"captured",c);return 0===(e&64)?[n]:[n,c]}},Qa="function"===typeof Object.is?Object.is:Zi,$i=Object.prototype.hasOwnProperty,Zj=wa&&"documentMode"in document&&11>=document.documentMode,Eg={select:{phasedRegistrationNames:{bubbled:"onSelect",captured:"onSelectCapture"},
dependencies:"blur contextmenu dragend focus keydown keyup mousedown mouseup selectionchange".split(" ")}},nb=null,he=null,Pb=null,ge=!1,ak={eventTypes:Eg,extractEvents:function(a,b,c,d,e,f){e=f||(d.window===d?d.document:9===d.nodeType?d:d.ownerDocument);if(!(f=!e)){a:{e=Jd(e);f=rd.onSelect;for(var g=0;g<f.length;g++)if(!e.has(f[g])){e=!1;break a}e=!0}f=!e}if(f)return null;e=b?Pa(b):window;switch(a){case "focus":if(yg(e)||"true"===e.contentEditable)nb=e,he=b,Pb=null;break;case "blur":Pb=he=nb=null;
break;case "mousedown":ge=!0;break;case "contextmenu":case "mouseup":case "dragend":return ge=!1,Dg(c,d);case "selectionchange":if(Zj)break;case "keydown":case "keyup":return Dg(c,d)}return null}},bk=R.extend({animationName:null,elapsedTime:null,pseudoElement:null}),ck=R.extend({clipboardData:function(a){return"clipboardData"in a?a.clipboardData:window.clipboardData}}),dk=dc.extend({relatedTarget:null}),ek={Esc:"Escape",Spacebar:" ",Left:"ArrowLeft",Up:"ArrowUp",Right:"ArrowRight",Down:"ArrowDown",
Del:"Delete",Win:"OS",Menu:"ContextMenu",Apps:"ContextMenu",Scroll:"ScrollLock",MozPrintableKey:"Unidentified"},fk={8:"Backspace",9:"Tab",12:"Clear",13:"Enter",16:"Shift",17:"Control",18:"Alt",19:"Pause",20:"CapsLock",27:"Escape",32:" ",33:"PageUp",34:"PageDown",35:"End",36:"Home",37:"ArrowLeft",38:"ArrowUp",39:"ArrowRight",40:"ArrowDown",45:"Insert",46:"Delete",112:"F1",113:"F2",114:"F3",115:"F4",116:"F5",117:"F6",118:"F7",119:"F8",120:"F9",121:"F10",122:"F11",123:"F12",144:"NumLock",145:"ScrollLock",
224:"Meta"},gk=dc.extend({key:function(a){if(a.key){var b=ek[a.key]||a.key;if("Unidentified"!==b)return b}return"keypress"===a.type?(a=Ac(a),13===a?"Enter":String.fromCharCode(a)):"keydown"===a.type||"keyup"===a.type?fk[a.keyCode]||"Unidentified":""},location:null,ctrlKey:null,shiftKey:null,altKey:null,metaKey:null,repeat:null,locale:null,getModifierState:fe,charCode:function(a){return"keypress"===a.type?Ac(a):0},keyCode:function(a){return"keydown"===a.type||"keyup"===a.type?a.keyCode:0},which:function(a){return"keypress"===
a.type?Ac(a):"keydown"===a.type||"keyup"===a.type?a.keyCode:0}}),hk=ec.extend({dataTransfer:null}),ik=dc.extend({touches:null,targetTouches:null,changedTouches:null,altKey:null,metaKey:null,ctrlKey:null,shiftKey:null,getModifierState:fe}),jk=R.extend({propertyName:null,elapsedTime:null,pseudoElement:null}),kk=ec.extend({deltaX:function(a){return"deltaX"in a?a.deltaX:"wheelDeltaX"in a?-a.wheelDeltaX:0},deltaY:function(a){return"deltaY"in a?a.deltaY:"wheelDeltaY"in a?-a.wheelDeltaY:"wheelDelta"in a?
-a.wheelDelta:0},deltaZ:null,deltaMode:null}),lk={eventTypes:dg,extractEvents:function(a,b,c,d,e){e=cg.get(a);if(!e)return null;switch(a){case "keypress":if(0===Ac(c))return null;case "keydown":case "keyup":a=gk;break;case "blur":case "focus":a=dk;break;case "click":if(2===c.button)return null;case "auxclick":case "dblclick":case "mousedown":case "mousemove":case "mouseup":case "mouseout":case "mouseover":case "contextmenu":a=ec;break;case "drag":case "dragend":case "dragenter":case "dragexit":case "dragleave":case "dragover":case "dragstart":case "drop":a=
hk;break;case "touchcancel":case "touchend":case "touchmove":case "touchstart":a=ik;break;case $h:case ai:case bi:a=bk;break;case ci:a=jk;break;case "scroll":a=dc;break;case "wheel":a=kk;break;case "copy":case "cut":case "paste":a=ck;break;case "gotpointercapture":case "lostpointercapture":case "pointercancel":case "pointerdown":case "pointermove":case "pointerout":case "pointerover":case "pointerup":a=hi;break;default:a=R}b=a.getPooled(e,b,c,d);lb(b);return b}};(function(a){if(ic)throw Error(k(101));
ic=Array.prototype.slice.call(a);nf()})("ResponderEventPlugin SimpleEventPlugin EnterLeaveEventPlugin ChangeEventPlugin SelectEventPlugin BeforeInputEventPlugin".split(" "));(function(a,b,c){td=a;rf=b;mf=c})(ae,Hb,Pa);pf({SimpleEventPlugin:lk,EnterLeaveEventPlugin:Yj,ChangeEventPlugin:Xj,SelectEventPlugin:ak,BeforeInputEventPlugin:Wj});var ie=[],ob=-1,Ca={},B={current:Ca},G={current:!1},Ra=Ca,bj=Pd,je=$f,Rg=Lj,aj=Nj,Dc=Oj,Ig=Zh,Jg=ag,Kg=Pj,Lg=Qj,Qg={},yj=Mj,Cj=void 0!==Yh?Yh:function(){},qa=null,
Ec=null,ke=!1,ii=ff(),Y=1E4>ii?ff:function(){return ff()-ii},Ic={current:null},Hc=null,qb=null,Gc=null,Tg=0,Jc=2,Ga=!1,Vb=da.ReactCurrentBatchConfig,$g=(new ea.Component).refs,Mc={isMounted:function(a){return(a=a._reactInternalFiber)?Na(a)===a:!1},enqueueSetState:function(a,b,c){a=a._reactInternalFiber;var d=ka(),e=Vb.suspense;d=Va(d,a,e);e=Ea(d,e);e.payload=b;void 0!==c&&null!==c&&(e.callback=c);Fa(a,e);Ja(a,d)},enqueueReplaceState:function(a,b,c){a=a._reactInternalFiber;var d=ka(),e=Vb.suspense;
d=Va(d,a,e);e=Ea(d,e);e.tag=1;e.payload=b;void 0!==c&&null!==c&&(e.callback=c);Fa(a,e);Ja(a,d)},enqueueForceUpdate:function(a,b){a=a._reactInternalFiber;var c=ka(),d=Vb.suspense;c=Va(c,a,d);d=Ea(c,d);d.tag=Jc;void 0!==b&&null!==b&&(d.callback=b);Fa(a,d);Ja(a,c)}},Qc=Array.isArray,wb=ah(!0),Fe=ah(!1),Sb={},ja={current:Sb},Ub={current:Sb},Tb={current:Sb},D={current:0},Sc=da.ReactCurrentDispatcher,X=da.ReactCurrentBatchConfig,Ia=0,z=null,K=null,J=null,Uc=!1,Tc={readContext:W,useCallback:S,useContext:S,
useEffect:S,useImperativeHandle:S,useLayoutEffect:S,useMemo:S,useReducer:S,useRef:S,useState:S,useDebugValue:S,useResponder:S,useDeferredValue:S,useTransition:S},dj={readContext:W,useCallback:ih,useContext:W,useEffect:eh,useImperativeHandle:function(a,b,c){c=null!==c&&void 0!==c?c.concat([a]):null;return ze(4,2,gh.bind(null,b,a),c)},useLayoutEffect:function(a,b){return ze(4,2,a,b)},useMemo:function(a,b){var c=ub();b=void 0===b?null:b;a=a();c.memoizedState=[a,b];return a},useReducer:function(a,b,c){var d=
ub();b=void 0!==c?c(b):b;d.memoizedState=d.baseState=b;a=d.queue={pending:null,dispatch:null,lastRenderedReducer:a,lastRenderedState:b};a=a.dispatch=ch.bind(null,z,a);return[d.memoizedState,a]},useRef:function(a){var b=ub();a={current:a};return b.memoizedState=a},useState:xe,useDebugValue:Be,useResponder:ue,useDeferredValue:function(a,b){var c=xe(a),d=c[0],e=c[1];eh(function(){var c=X.suspense;X.suspense=void 0===b?null:b;try{e(a)}finally{X.suspense=c}},[a,b]);return d},useTransition:function(a){var b=
xe(!1),c=b[0];b=b[1];return[ih(Ce.bind(null,b,a),[b,a]),c]}},ej={readContext:W,useCallback:Yc,useContext:W,useEffect:Xc,useImperativeHandle:hh,useLayoutEffect:fh,useMemo:jh,useReducer:Vc,useRef:dh,useState:function(a){return Vc(Ua)},useDebugValue:Be,useResponder:ue,useDeferredValue:function(a,b){var c=Vc(Ua),d=c[0],e=c[1];Xc(function(){var c=X.suspense;X.suspense=void 0===b?null:b;try{e(a)}finally{X.suspense=c}},[a,b]);return d},useTransition:function(a){var b=Vc(Ua),c=b[0];b=b[1];return[Yc(Ce.bind(null,
b,a),[b,a]),c]}},fj={readContext:W,useCallback:Yc,useContext:W,useEffect:Xc,useImperativeHandle:hh,useLayoutEffect:fh,useMemo:jh,useReducer:Wc,useRef:dh,useState:function(a){return Wc(Ua)},useDebugValue:Be,useResponder:ue,useDeferredValue:function(a,b){var c=Wc(Ua),d=c[0],e=c[1];Xc(function(){var c=X.suspense;X.suspense=void 0===b?null:b;try{e(a)}finally{X.suspense=c}},[a,b]);return d},useTransition:function(a){var b=Wc(Ua),c=b[0];b=b[1];return[Yc(Ce.bind(null,b,a),[b,a]),c]}},ra=null,Ka=null,Wa=
!1,gj=da.ReactCurrentOwner,ia=!1,Je={dehydrated:null,retryTime:0};var jj=function(a,b,c,d){for(c=b.child;null!==c;){if(5===c.tag||6===c.tag)a.appendChild(c.stateNode);else if(4!==c.tag&&null!==c.child){c.child.return=c;c=c.child;continue}if(c===b)break;for(;null===c.sibling;){if(null===c.return||c.return===b)return;c=c.return}c.sibling.return=c.return;c=c.sibling}};var wh=function(a){};var ij=function(a,b,c,d,e){var f=a.memoizedProps;if(f!==d){var g=b.stateNode;Ta(ja.current);a=null;switch(c){case "input":f=
Cd(g,f);d=Cd(g,d);a=[];break;case "option":f=Fd(g,f);d=Fd(g,d);a=[];break;case "select":f=M({},f,{value:void 0});d=M({},d,{value:void 0});a=[];break;case "textarea":f=Gd(g,f);d=Gd(g,d);a=[];break;default:"function"!==typeof f.onClick&&"function"===typeof d.onClick&&(g.onclick=uc)}Ud(c,d);var h,m;c=null;for(h in f)if(!d.hasOwnProperty(h)&&f.hasOwnProperty(h)&&null!=f[h])if("style"===h)for(m in g=f[h],g)g.hasOwnProperty(m)&&(c||(c={}),c[m]="");else"dangerouslySetInnerHTML"!==h&&"children"!==h&&"suppressContentEditableWarning"!==
h&&"suppressHydrationWarning"!==h&&"autoFocus"!==h&&(db.hasOwnProperty(h)?a||(a=[]):(a=a||[]).push(h,null));for(h in d){var k=d[h];g=null!=f?f[h]:void 0;if(d.hasOwnProperty(h)&&k!==g&&(null!=k||null!=g))if("style"===h)if(g){for(m in g)!g.hasOwnProperty(m)||k&&k.hasOwnProperty(m)||(c||(c={}),c[m]="");for(m in k)k.hasOwnProperty(m)&&g[m]!==k[m]&&(c||(c={}),c[m]=k[m])}else c||(a||(a=[]),a.push(h,c)),c=k;else"dangerouslySetInnerHTML"===h?(k=k?k.__html:void 0,g=g?g.__html:void 0,null!=k&&g!==k&&(a=a||
[]).push(h,k)):"children"===h?g===k||"string"!==typeof k&&"number"!==typeof k||(a=a||[]).push(h,""+k):"suppressContentEditableWarning"!==h&&"suppressHydrationWarning"!==h&&(db.hasOwnProperty(h)?(null!=k&&oa(e,h),a||g===k||(a=[])):(a=a||[]).push(h,k))}c&&(a=a||[]).push("style",c);e=a;if(b.updateQueue=e)b.effectTag|=4}};var kj=function(a,b,c,d){c!==d&&(b.effectTag|=4)};var pj="function"===typeof WeakSet?WeakSet:Set,wj="function"===typeof WeakMap?WeakMap:Map,sj=Math.ceil,gd=da.ReactCurrentDispatcher,
Uh=da.ReactCurrentOwner,H=0,Ye=8,ca=16,ma=32,Xa=0,hd=1,Oh=2,ad=3,bd=4,Xe=5,p=H,U=null,t=null,P=0,F=Xa,id=null,ta=1073741823,Yb=1073741823,kd=null,Xb=0,jd=!1,Re=0,Ph=500,l=null,cd=!1,Se=null,La=null,ld=!1,Zb=null,$b=90,bb=null,ac=0,af=null,dd=0,Ja=function(a,b){if(50<ac)throw ac=0,af=null,Error(k(185));a=ed(a,b);if(null!==a){var c=Cc();1073741823===b?(p&Ye)!==H&&(p&(ca|ma))===H?Te(a):(V(a),p===H&&ha()):V(a);(p&4)===H||98!==c&&99!==c||(null===bb?bb=new Map([[a,b]]):(c=bb.get(a),(void 0===c||c>b)&&bb.set(a,
b)))}};var zj=function(a,b,c){var d=b.expirationTime;if(null!==a){var e=b.pendingProps;if(a.memoizedProps!==e||G.current)ia=!0;else{if(d<c){ia=!1;switch(b.tag){case 3:sh(b);Ee();break;case 5:bh(b);if(b.mode&4&&1!==c&&e.hidden)return b.expirationTime=b.childExpirationTime=1,null;break;case 1:N(b.type)&&Bc(b);break;case 4:se(b,b.stateNode.containerInfo);break;case 10:d=b.memoizedProps.value;e=b.type._context;y(Ic,e._currentValue);e._currentValue=d;break;case 13:if(null!==b.memoizedState){d=b.child.childExpirationTime;
if(0!==d&&d>=c)return th(a,b,c);y(D,D.current&1);b=sa(a,b,c);return null!==b?b.sibling:null}y(D,D.current&1);break;case 19:d=b.childExpirationTime>=c;if(0!==(a.effectTag&64)){if(d)return vh(a,b,c);b.effectTag|=64}e=b.memoizedState;null!==e&&(e.rendering=null,e.tail=null);y(D,D.current);if(!d)return null}return sa(a,b,c)}ia=!1}}else ia=!1;b.expirationTime=0;switch(b.tag){case 2:d=b.type;null!==a&&(a.alternate=null,b.alternate=null,b.effectTag|=2);a=b.pendingProps;e=pb(b,B.current);rb(b,c);e=we(null,
b,d,a,e,c);b.effectTag|=1;if("object"===typeof e&&null!==e&&"function"===typeof e.render&&void 0===e.$$typeof){b.tag=1;b.memoizedState=null;b.updateQueue=null;if(N(d)){var f=!0;Bc(b)}else f=!1;b.memoizedState=null!==e.state&&void 0!==e.state?e.state:null;ne(b);var g=d.getDerivedStateFromProps;"function"===typeof g&&Lc(b,d,g,a);e.updater=Mc;b.stateNode=e;e._reactInternalFiber=b;pe(b,d,a,c);b=Ie(null,b,d,!0,f,c)}else b.tag=0,T(null,b,e,c),b=b.child;return b;case 16:a:{e=b.elementType;null!==a&&(a.alternate=
null,b.alternate=null,b.effectTag|=2);a=b.pendingProps;ri(e);if(1!==e._status)throw e._result;e=e._result;b.type=e;f=b.tag=Gj(e);a=aa(e,a);switch(f){case 0:b=He(null,b,e,a,c);break a;case 1:b=rh(null,b,e,a,c);break a;case 11:b=nh(null,b,e,a,c);break a;case 14:b=oh(null,b,e,aa(e.type,a),d,c);break a}throw Error(k(306,e,""));}return b;case 0:return d=b.type,e=b.pendingProps,e=b.elementType===d?e:aa(d,e),He(a,b,d,e,c);case 1:return d=b.type,e=b.pendingProps,e=b.elementType===d?e:aa(d,e),rh(a,b,d,e,c);
case 3:sh(b);d=b.updateQueue;if(null===a||null===d)throw Error(k(282));d=b.pendingProps;e=b.memoizedState;e=null!==e?e.element:null;oe(a,b);Qb(b,d,null,c);d=b.memoizedState.element;if(d===e)Ee(),b=sa(a,b,c);else{if(e=b.stateNode.hydrate)Ka=kb(b.stateNode.containerInfo.firstChild),ra=b,e=Wa=!0;if(e)for(c=Fe(b,null,d,c),b.child=c;c;)c.effectTag=c.effectTag&-3|1024,c=c.sibling;else T(a,b,d,c),Ee();b=b.child}return b;case 5:return bh(b),null===a&&De(b),d=b.type,e=b.pendingProps,f=null!==a?a.memoizedProps:
null,g=e.children,Yd(d,e)?g=null:null!==f&&Yd(d,f)&&(b.effectTag|=16),qh(a,b),b.mode&4&&1!==c&&e.hidden?(b.expirationTime=b.childExpirationTime=1,b=null):(T(a,b,g,c),b=b.child),b;case 6:return null===a&&De(b),null;case 13:return th(a,b,c);case 4:return se(b,b.stateNode.containerInfo),d=b.pendingProps,null===a?b.child=wb(b,null,d,c):T(a,b,d,c),b.child;case 11:return d=b.type,e=b.pendingProps,e=b.elementType===d?e:aa(d,e),nh(a,b,d,e,c);case 7:return T(a,b,b.pendingProps,c),b.child;case 8:return T(a,
b,b.pendingProps.children,c),b.child;case 12:return T(a,b,b.pendingProps.children,c),b.child;case 10:a:{d=b.type._context;e=b.pendingProps;g=b.memoizedProps;f=e.value;var h=b.type._context;y(Ic,h._currentValue);h._currentValue=f;if(null!==g)if(h=g.value,f=Qa(h,f)?0:("function"===typeof d._calculateChangedBits?d._calculateChangedBits(h,f):1073741823)|0,0===f){if(g.children===e.children&&!G.current){b=sa(a,b,c);break a}}else for(h=b.child,null!==h&&(h.return=b);null!==h;){var m=h.dependencies;if(null!==
m){g=h.child;for(var l=m.firstContext;null!==l;){if(l.context===d&&0!==(l.observedBits&f)){1===h.tag&&(l=Ea(c,null),l.tag=Jc,Fa(h,l));h.expirationTime<c&&(h.expirationTime=c);l=h.alternate;null!==l&&l.expirationTime<c&&(l.expirationTime=c);Sg(h.return,c);m.expirationTime<c&&(m.expirationTime=c);break}l=l.next}}else g=10===h.tag?h.type===b.type?null:h.child:h.child;if(null!==g)g.return=h;else for(g=h;null!==g;){if(g===b){g=null;break}h=g.sibling;if(null!==h){h.return=g.return;g=h;break}g=g.return}h=
g}T(a,b,e.children,c);b=b.child}return b;case 9:return e=b.type,f=b.pendingProps,d=f.children,rb(b,c),e=W(e,f.unstable_observedBits),d=d(e),b.effectTag|=1,T(a,b,d,c),b.child;case 14:return e=b.type,f=aa(e,b.pendingProps),f=aa(e.type,f),oh(a,b,e,f,d,c);case 15:return ph(a,b,b.type,b.pendingProps,d,c);case 17:return d=b.type,e=b.pendingProps,e=b.elementType===d?e:aa(d,e),null!==a&&(a.alternate=null,b.alternate=null,b.effectTag|=2),b.tag=1,N(d)?(a=!0,Bc(b)):a=!1,rb(b,c),Yg(b,d,e),pe(b,d,e,c),Ie(null,
b,d,!0,a,c);case 19:return vh(a,b,c)}throw Error(k(156,b.tag));};var bf=null,Ne=null,la=function(a,b,c,d){return new Fj(a,b,c,d)};ef.prototype.render=function(a){md(a,this._internalRoot,null,null)};ef.prototype.unmount=function(){var a=this._internalRoot,b=a.containerInfo;md(null,a,null,function(){b[Lb]=null})};var Di=function(a){if(13===a.tag){var b=Fc(ka(),150,100);Ja(a,b);df(a,b)}};var Yf=function(a){13===a.tag&&(Ja(a,3),df(a,3))};var Bi=function(a){if(13===a.tag){var b=ka();b=Va(b,a,null);Ja(a,
b);df(a,b)}};sd=function(a,b,c){switch(b){case "input":Dd(a,c);b=c.name;if("radio"===c.type&&null!=b){for(c=a;c.parentNode;)c=c.parentNode;c=c.querySelectorAll("input[name="+JSON.stringify(""+b)+'][type="radio"]');for(b=0;b<c.length;b++){var d=c[b];if(d!==a&&d.form===a.form){var e=ae(d);if(!e)throw Error(k(90));Gf(d);Dd(d,e)}}}break;case "textarea":Lf(a,c);break;case "select":b=c.value,null!=b&&hb(a,!!c.multiple,b,!1)}};(function(a,b,c,d){ee=a;eg=b;vd=c;vf=d})(Qh,function(a,b,c,d,e){var f=p;p|=4;
try{return Da(98,a.bind(null,b,c,d,e))}finally{p=f,p===H&&ha()}},function(){(p&(1|ca|ma))===H&&(uj(),xb())},function(a,b){var c=p;p|=2;try{return a(b)}finally{p=c,p===H&&ha()}});var mk={Events:[Hb,Pa,ae,pf,qd,lb,function(a){Kd(a,Ki)},sf,tf,sc,pc,xb,{current:!1}]};(function(a){var b=a.findFiberByHostInstance;return Ej(M({},a,{overrideHookState:null,overrideProps:null,setSuspenseHandler:null,scheduleUpdate:null,currentDispatcherRef:da.ReactCurrentDispatcher,findHostInstanceByFiber:function(a){a=Sf(a);
return null===a?null:a.stateNode},findFiberByHostInstance:function(a){return b?b(a):null},findHostInstancesForRefresh:null,scheduleRefresh:null,scheduleRoot:null,setRefreshHandler:null,getCurrentFiber:null}))})({findFiberByHostInstance:Bb,bundleType:0,version:"16.13.1",rendererPackageName:"react-dom"});I.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED=mk;I.createPortal=Xh;I.findDOMNode=function(a){if(null==a)return null;if(1===a.nodeType)return a;var b=a._reactInternalFiber;if(void 0===
b){if("function"===typeof a.render)throw Error(k(188));throw Error(k(268,Object.keys(a)));}a=Sf(b);a=null===a?null:a.stateNode;return a};I.flushSync=function(a,b){if((p&(ca|ma))!==H)throw Error(k(187));var c=p;p|=1;try{return Da(99,a.bind(null,b))}finally{p=c,ha()}};I.hydrate=function(a,b,c){if(!bc(b))throw Error(k(200));return nd(null,a,b,!0,c)};I.render=function(a,b,c){if(!bc(b))throw Error(k(200));return nd(null,a,b,!1,c)};I.unmountComponentAtNode=function(a){if(!bc(a))throw Error(k(40));return a._reactRootContainer?
(Rh(function(){nd(null,null,a,!1,function(){a._reactRootContainer=null;a[Lb]=null})}),!0):!1};I.unstable_batchedUpdates=Qh;I.unstable_createPortal=function(a,b){return Xh(a,b,2<arguments.length&&void 0!==arguments[2]?arguments[2]:null)};I.unstable_renderSubtreeIntoContainer=function(a,b,c,d){if(!bc(c))throw Error(k(200));if(null==a||void 0===a._reactInternalFiber)throw Error(k(38));return nd(a,b,c,!1,d)};I.version="16.13.1"});
</script>
    <script>const e = React.createElement;

function pathToString(path) {
  if (path[0] === '/') {
    return '/' + path.slice(1).join('/');
  } else {
    return path.join('/');
  }
}

function findCommonPath(files) {
  if (!files || !files.length) {
    return [];
  }

  function isPrefix(arr, prefix) {
    if (arr.length < prefix.length) {
      return false;
    }
    for (let i = prefix.length - 1; i >= 0; --i) {
      if (arr[i] !== prefix[i]) {
        return false;
      }
    }
    return true;
  }

  let commonPath = files[0].path.slice(0, -1);
  while (commonPath.length) {
    if (files.every(file => isPrefix(file.path, commonPath))) {
      break;
    }
    commonPath.pop();
  }
  return commonPath;
}

function findFolders(files) {
  if (!files || !files.length) {
    return [];
  }

  let folders = files.filter(file => file.path.length > 1).map(file => file.path[0]);
  folders = [...new Set(folders)]; // unique
  folders.sort();

  folders = folders.map(folder => {
    let filesInFolder = files
      .filter(file => file.path[0] === folder)
      .map(file => ({
        ...file,
        path: file.path.slice(1),
        parent: [...file.parent, file.path[0]],
      }));

    const children = findFolders(filesInFolder); // recursion

    return {
      is_folder: true,
      path: [folder],
      parent: files[0].parent,
      children,
      covered: children.reduce((sum, file) => sum + file.covered, 0),
      coverable: children.reduce((sum, file) => sum + file.coverable, 0),
      prevRun: {
        covered: children.reduce((sum, file) => sum + file.prevRun.covered, 0),
        coverable: children.reduce((sum, file) => sum + file.prevRun.coverable, 0),
      }
    };
  });

  return [
    ...folders,
    ...files.filter(file => file.path.length === 1),
  ];
}

class App extends React.Component {
  constructor(...args) {
    super(...args);

    this.state = {
      current: [],
    };
  }

  componentDidMount() {
    this.updateStateFromLocation();
    window.addEventListener("hashchange", () => this.updateStateFromLocation(), false);
  }

  updateStateFromLocation() {
    if (window.location.hash.length > 1) {
      const current = window.location.hash.substr(1).split('/');
      this.setState({current});
    } else {
      this.setState({current: []});
    }
  }

  getCurrentPath() {
    let file = this.props.root;
    let path = [file];
    for (let p of this.state.current) {
      file = file.children.find(file => file.path[0] === p);
      if (!file) {
        return path;
      }
      path.push(file);
    }
    return path;
  }

  render() {
    const path = this.getCurrentPath();
    const file = path[path.length - 1];

    let w = null;
    if (file.is_folder) {
      w = e(FilesList, {
        folder: file,
        onSelectFile: this.selectFile.bind(this),
        onBack: path.length > 1 ? this.back.bind(this) : null,
      });
    } else {
      w = e(DisplayFile, {
        file,
        onBack: this.back.bind(this),
      });
    }

    return e('div', {className: 'app'}, w);
  }

  selectFile(file) {
    this.setState(({current}) => {
      return {current: [...current, file.path[0]]};
    }, () => this.updateHash());
  }

  back(file) {
    this.setState(({current}) => {
      return {current: current.slice(0, current.length - 1)};
    }, () => this.updateHash());
  }

  updateHash() {
    if (!this.state.current || !this.state.current.length) {
      window.location = '#';
    } else {
      window.location = '#' + this.state.current.join('/');
    }
  }
}

function FilesList({folder, onSelectFile, onBack}) {
  let files = folder.children;
  return e('div', {className: 'display-folder'},
    e(FileHeader, {file: folder, onBack}),
    e('table', {className: 'files-list'},
      e('thead', {className: 'files-list__head'},
        e('tr', null,
          e('th', null, "Path"),
          e('th', null, "Coverage")
        )
      ),
      e('tbody', {className: 'files-list__body'},
        files.map(file => e(File, {file, onClick: onSelectFile}))
      )
    )
  );
}

function File({file, onClick}) {
  const coverage = file.coverable ? file.covered / file.coverable * 100 : -1;
  const coverageDelta = file.prevRun &&
    (file.covered / file.coverable * 100 - file.prevRun.covered / file.prevRun.coverable * 100);

  return e('tr', {
      className: 'files-list__file'
        + (coverage >= 0 && coverage < 50 ? ' files-list__file_low': '')
        + (coverage >= 50 && coverage < 80 ? ' files-list__file_medium': '')
        + (coverage >= 80 ? ' files-list__file_high': '')
        + (file.is_folder ? ' files-list__file_folder': ''),
      onClick: () => onClick(file),
    },
    e('td', null, e('a', null, pathToString(file.path))),
    e('td', null,
      file.covered + ' / ' + file.coverable +
      (coverage >= 0 ? ' (' + coverage.toFixed(2) + '%)' : ''),
      e('span', {title: 'Change from the previous run'},
        (coverageDelta ? ` (${coverageDelta > 0 ? '+' : ''}${coverageDelta.toFixed(2)}%)` : ''))
    )
  );
}

function DisplayFile({file, onBack}) {
  return e('div', {className: 'display-file'},
    e(FileHeader, {file, onBack}),
    e(FileContent, {file})
  );
}

function FileHeader({file, onBack}) {
  const coverage = file.covered / file.coverable * 100;
  const coverageDelta = file.prevRun && (coverage - file.prevRun.covered / file.prevRun.coverable * 100);

  return e('div', {className: 'file-header'},
    onBack ? e('a', {className: 'file-header__back', onClick: onBack}, 'Back') : null,
    e('div', {className: 'file-header__name'}, pathToString([...file.parent, ...file.path])),
    e('div', {className: 'file-header__stat'},
      'Covered: ' + file.covered + ' of ' + file.coverable +
      (file.coverable ? ' (' + coverage.toFixed(2) + '%)' : ''),
      e('span', {title: 'Change from the previous run'},
        (coverageDelta ? ` (${coverageDelta > 0 ? '+' : ''}${coverageDelta.toFixed(2)}%)` : ''))
    )
  );
}

function FileContent({file}) {
  return e('pre', {className: 'file-content'},
    file.content.split(/\r?\n/).map((line, index) => {
      const trace = file.traces.find(trace => trace.line === index + 1);
      const covered = trace && trace.stats.Line;
      const uncovered = trace && !trace.stats.Line;
      return e('code', {
          className: 'code-line'
            + (covered ? ' code-line_covered' : '')
            + (uncovered ? ' code-line_uncovered' : ''),
          title: trace ? JSON.stringify(trace.stats, null, 2) : null,
        }, line);
    })
  );
}

(function(){
  const commonPath = findCommonPath(data.files);
  const prevFilesMap = new Map();

  previousData && previousData.files.forEach((file) => {
    const path = file.path.slice(commonPath.length).join('/');
    prevFilesMap.set(path, file);
  });

  const files = data.files.map((file) => {
    const path = file.path.slice(commonPath.length);
    const { covered = 0, coverable = 0 } = prevFilesMap.get(path.join('/')) || {};
    return {
      ...file,
      path,
      parent: commonPath,
      prevRun: { covered, coverable },
    };
  });

  const children = findFolders(files);

  const root = {
    is_folder: true,
    children,
    path: commonPath,
    parent: [],
    covered: children.reduce((sum, file) => sum + file.covered, 0),
    coverable: children.reduce((sum, file) => sum + file.coverable, 0),
    prevRun: {
      covered: children.reduce((sum, file) => sum + file.prevRun.covered, 0),
      coverable: children.reduce((sum, file) => sum + file.prevRun.coverable, 0),
    }
  };

  ReactDOM.render(e(App, {root, prevFilesMap}), document.getElementById('root'));
}());
</script>
</body>
</html>